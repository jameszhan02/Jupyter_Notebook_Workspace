{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e25f62-77d7-4e0d-aa2b-5f5347596c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1+cu117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn ## nn stand for nerual network\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17874a-3831-407c-b510-f225275f6832",
   "metadata": {},
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "Data can be almost anything ... in machine learning;\n",
    "* Excel speadsheet\n",
    "* Image of any kind \n",
    "* Videos \n",
    "* Audio like songs or podcasts\n",
    "* DNA\n",
    "* Text\n",
    "\n",
    "Machione learning is a game of two parts: \n",
    "1. Get data into a numberical representation ---> Convert data into a numerical\n",
    "2. Build a model to learn patterns in that numerical representation. ---> use the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9794bd-5975-4ed3-ab3b-9cb4db966354",
   "metadata": {},
   "source": [
    "### Linear regression Formula.\n",
    "to showcase this , lets's create some *known* data using the linear regression formula.\n",
    "\n",
    "we'll use a linear regression formula to make a straight line with known parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398a7bce-51d1-46a9-beab-f5fe164e9962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000],\n",
       "         [0.0200],\n",
       "         [0.0400],\n",
       "         [0.0600],\n",
       "         [0.0800],\n",
       "         [0.1000],\n",
       "         [0.1200],\n",
       "         [0.1400],\n",
       "         [0.1600],\n",
       "         [0.1800]]),\n",
       " tensor([[0.3000],\n",
       "         [0.3140],\n",
       "         [0.3280],\n",
       "         [0.3420],\n",
       "         [0.3560],\n",
       "         [0.3700],\n",
       "         [0.3840],\n",
       "         [0.3980],\n",
       "         [0.4120],\n",
       "         [0.4260]]),\n",
       " 50,\n",
       " 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create *known* parameter s\n",
    "weight = 0.7 \n",
    "bias = 0.3\n",
    "\n",
    "#Create \n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02 \n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "# Commonly upper case in the machine learning represent a matrix or  a tensor, and lowwer case letter will represent a vector\n",
    "X[:10] , y[:10], len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706ba9a9-1442-4a08-85fa-ca625dc036a8",
   "metadata": {},
   "source": [
    "# split date in to different set\n",
    "1. Training set\n",
    "2. Testing set\n",
    "3. Validation set [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf9d834-8195-43f6-80f6-619efc068325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 10, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a train/ test split\n",
    "train_split_len = int(0.8 * len(X))\n",
    "X_train, y_train = X[:train_split_len], y[:train_split_len]\n",
    "X_test, y_test = X[train_split_len:], y[train_split_len:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3238927d-a0c9-4f9e-b9df-060877091f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "want_eight = 8\n",
    "test_arr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "split_one = test_arr[:want_eight]\n",
    "split_two = test_arr[want_eight:]\n",
    "\n",
    "split_one, split_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "390e0fa3-d074-4406-84be-da5b3fa91d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data = X_train, \n",
    "                    train_labels = y_train,\n",
    "                    test_data = X_test,\n",
    "                    test_labels = y_test,\n",
    "                    predictions=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    #plot training dat in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    #Are there predictionsï¼Ÿ\n",
    "    if predictions is not None:\n",
    "        #plot the predictions if they exist\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label =\"Predictions\")\n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94b6e5a9-708b-4e76-bc79-ad0dbd110eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAJGCAYAAACTJvC6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABKxElEQVR4nO3de3xU9Z3/8fdkyAWEhAoSbilBrSgtgoJkgxdmajRtXc7Q2hXrym0rXSxqd2JLoQoBraJbS1NHrJaCeFkLVqNzHuJSSjrBVWPpgnTVQixyFUmAijMYJYHJ+f0xPyamSSATkszMmdfz8ZjHab5zzpnPJCc0b7/fOR+HZVmWAAAAAMBG0uJdAAAAAAB0NoIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwnR7xLqA9Ghsb9eGHH6pPnz5yOBzxLgcAAABAnFiWpaNHj2rw4MFKS2t73iYpgs6HH36ovLy8eJcBAAAAIEHs27dPQ4cObfP5pAg6ffr0kRR5M9nZ2XGuBgAAAEC8hEIh5eXlRTNCW5Ii6JxcrpadnU3QAQAAAHDaj7RwMwIAAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAAAGA7SXF76Y44fvy4wuFwvMsA4iI9PV1OpzPeZQAAAMSN7YJOKBTS4cOHVV9fH+9SgLhxOBzKycnRwIEDT3uPeQAAADuKOei8+uqr+tnPfqbNmzfrwIEDevHFFzV58uRTHlNZWamSkhK9++67ysvL0913360ZM2Z0sOS2hUIh7d+/X71791b//v2Vnp7OH3lIOZZlqa6uTocOHVLPnj3Vt2/feJcEAADQ7WIOOnV1dRo9erT+7d/+Td/61rdOu/+uXbt03XXXafbs2fqv//ovVVRU6JZbbtGgQYNUXFzcoaLbcvjwYfXu3VtDhw4l4CCl9ezZU/X19Tp48KBycnL4fQAAACkn5qDz9a9/XV//+tfbvf9jjz2m4cOH6+c//7kk6aKLLtJrr72mX/ziF50adI4fP676+nr179+fP+oASdnZ2QqFQgqHw+rRw3arVAEAAE6py++6VlVVpaKiomZjxcXFqqqqavOY+vp6hUKhZo/TOXnjgfT09DMrGLCJk+HmxIkTca4EAACg+3V50KmpqVFubm6zsdzcXIVCIX322WetHrNkyRLl5OREH3l5ee1+PWZzgAh+FwAAQCpLyD468+fPVzAYjD727dsX75IAAAAAJJEuX7g/cOBA1dbWNhurra1Vdna2evbs2eoxmZmZyszM7OrSAAAAANhUl8/oFBYWqqKiotnYH/7wBxUWFnb1S6ObOBwOuVyuMzpHZWWlHA6HFi1a1Ck1dbX8/Hzl5+fHuwwAAAC0Ieag88knn2jr1q3aunWrpMjto7du3aq9e/dKiiw7mzZtWnT/2bNna+fOnZo7d662b9+uRx99VM8995y8Xm/nvANIioSNWB6IP5fLxc8CAACgi8S8dO1///d/5Xa7o1+XlJRIkqZPn65Vq1bpwIED0dAjScOHD9fatWvl9Xr1y1/+UkOHDtVvfvObTu+hk+pKS0tbjJWVlSkYDLb6XGfatm2bevXqdUbnGD9+vLZt26b+/ft3UlUAAABIZQ7Lsqx4F3E6oVBIOTk5CgaDys7ObnWfY8eOadeuXRo+fLiysrK6ucLElJ+frz179igJfsRJ5+Sytd27d3f4HC6XSxs3buyynw+/EwAAwI7akw2kBL3rGrrO7t275XA4NGPGDG3btk3f/OY31a9fPzkcjugf7S+++KK+853v6Pzzz1evXr2Uk5OjK6+8Ui+88EKr52ztMzozZsyQw+HQrl279PDDD+vCCy9UZmamhg0bpsWLF6uxsbHZ/m19RufkZ2E++eQT/eAHP9DgwYOVmZmpiy++WM8//3yb73HKlCk6++yz1bt3b02cOFGvvvqqFi1aJIfDocrKynZ/v/x+vy677DL17NlTubm5mjVrlo4cOdLqvu+9957mzp2rSy+9VP369VNWVpYuuOACzZs3T5988kmL79nGjRuj//vkY8aMGdF9Vq5cKY/Ho/z8fGVlZenss89WcXGxAoFAu+sHAABIVbRLT1E7duzQP/3TP2nUqFGaMWOG/v73vysjI0NS5HNWGRkZuuKKKzRo0CAdOnRIpmnq29/+th5++GHdfvvt7X6dH/3oR9q4caP++Z//WcXFxXrppZe0aNEiNTQ06L777mvXOY4fP65rr71WR44c0fXXX69PP/1Uq1ev1g033KB169bp2muvje67f/9+TZgwQQcOHNDXvvY1XXLJJaqurtY111yjr371qzF9j5566ilNnz5d2dnZmjp1qvr27auXX35ZRUVFamhoiH6/TiovL9eKFSvkdrvlcrnU2NioN998Uw8++KA2btyoV199NdrQtrS0VKtWrdKePXuaLS0cM2ZM9H/PmTNHo0ePVlFRkc455xzt379fL730koqKilReXi6PxxPT+wEAAOgIs9pUYFdA7uFuGSOMeJfTflYSCAaDliQrGAy2uc9nn31m/fWvf7U+++yzbqwssQ0bNsz6xx/xrl27LEmWJGvhwoWtHvf++++3GDt69Kg1atQoKycnx6qrq2v2nCRr4sSJzcamT59uSbKGDx9uffjhh9HxQ4cOWX379rX69Olj1dfXR8cDgYAlySotLW31PXg8nmb7b9iwwZJkFRcXN9v/5ptvtiRZ9913X7PxFStWRN93IBBo9X1/XjAYtLKzs62zzjrLqq6ujo43NDRYV111lSXJGjZsWLNjPvjgg2Y1nrR48WJLkvXMM880G584cWKLn8/n7dy5s8XYhx9+aA0ePNj60pe+dNr3wO8EAAA4U/7tfkuLZDkXOy0tkuXf7o93Se3KBpZlWSxdS1EDBw7UXXfd1epz5557boux3r17a8aMGQoGg/rzn//c7tdZsGCBBg0aFP26f//+8ng8Onr0qKqrq9t9nl/84hfNZlCuvvpqDRs2rFkt9fX1+t3vfqcBAwbozjvvbHb8zJkzNWLEiHa/3ksvvaRQKKR/+7d/0wUXXBAdT09Pb3MmasiQIS1meSTptttukyRt2LCh3a8vRW7k8Y8GDRqk66+/Xn/729+0Z8+emM4HAAAQq8CugJwOp8JWWE6HU5W7K+NdUrsRdDrINCWvN7JNRqNHj271j3JJOnjwoEpKSnTRRRepV69e0c+PnAwPH374YbtfZ+zYsS3Ghg4dKkn6+OOP23WOvn37tvpH/9ChQ5udo7q6WvX19Ro3blyLhrMOh0MTJkxod91/+ctfJElXXnlli+cKCwvVo0fLVZ+WZWnlypW66qqrdPbZZ8vpdMrhcKhfv36SYvu+SdLOnTs1a9YsnXfeecrKyor+HHw+X4fOBwAAECv3cHc05IStsFz5rniX1G58RqcDTFPyeCSnUyork/x+yUii5YqSlJub2+r4Rx99pMsuu0x79+7V5ZdfrqKiIvXt21dOp1Nbt26V3+9XfX19u1+ntTthnAwJ4XC4XefIyclpdbxHjx7NbmoQCoUkSQMGDGh1/7bec2uCwWCb53I6ndHw8nl33HGHHnnkEeXl5ckwDA0aNCgauBYvXhzT923Hjh0aP368QqGQ3G63Jk2apOzsbKWlpamyslIbN26M6XwAAAAdYYww5L/Rr8rdlXLlu5LqMzoEnQ4IBCIhJxyObCsrky/otNWocsWKFdq7d6/uvfde3X333c2ee+CBB+T3+7ujvA45GaoOHjzY6vO1tbXtPtfJcNXaucLhsP7+979ryJAh0bGDBw9q2bJluvjii1VVVdWsr1BNTY0WL17c7teWIkv1jhw5oqefflo333xzs+dmz54dvWMbAABAVzNGGEkVcE5i6VoHuN1NIScclv7hzspJ7f3335ekVu/o9T//8z/dXU5MRowYoczMTG3evLnFbIdlWaqqqmr3uUaPHi2p9fdcVVWlEydONBvbuXOnLMtSUVFRi+apbX3fnE6npNZnttr6OViWpddff72d7wIAACB1EXQ6wDAiy9XuuCM5l62dyrBhwyRJr732WrPxZ599Vq+88ko8Smq3zMxMffvb31Ztba3KysqaPffUU09p+/bt7T6Xx+NRdna2Vq5cqffeey86fvz48RYzXVLT9+2NN95otpzugw8+0Pz581t9jbPPPluStG/fvjbP948/hwceeEDvvPNOu98HAABAqmLpWgcZhr0CzklTp07Vgw8+qNtvv12BQEDDhg3TX/7yF1VUVOhb3/qWysvL413iKS1ZskQbNmzQvHnztHHjxmgfnZdffllf+9rXtG7dOqWlnT7f5+Tk6OGHH9aMGTN02WWX6cYbb1ROTo5efvll9ezZs9md5KSmu6G98MILGjdunK6++mrV1tbq5Zdf1tVXXx2dofm8r371q3r++ed1/fXX6+tf/7qysrI0evRoTZo0SbNnz9YTTzyh66+/XjfccIP69eunN998U1u2bNF1112ntWvXdtr3DAAAwI6Y0UEzQ4cO1caNG3X11Vdrw4YNevzxx9XQ0KD169dr0qRJ8S7vtPLy8lRVVaV/+Zd/0RtvvKGysjIdPHhQ69ev1/nnny+p9RsktGb69Ol68cUX9aUvfUlPPvmknnzySV1++eXasGFDq3esW7Vqle68804dOXJEPp9Pb775pkpKSvTss8+2ev5Zs2Zp7ty5Onz4sB588EEtWLBAL7zwgiTpkksu0fr163XppZeqvLxcK1euVN++ffX6669r3LhxHfzuAAAApA6HZVlWvIs4nVAopJycHAWDwTb/SD127Jh27dql4cOHKysrq5srRDK44oorVFVVpWAwqN69e8e7nC7H7wQAAPg8s9pUYFdA7uHupLy5wEntyQYSMzqwoQMHDrQYe+aZZ/T666+rqKgoJUIOAADA55nVpjyrPfJt8smz2iOzOkmbQcaAz+jAdr7yla/okksu0ciRI6P9fyorK9WnTx899NBD8S4PAACg2wV2BaJNP50Opyp3Vyb1rE57MKMD25k9e7YOHjyop556So888oiqq6t10003adOmTRo1alS8ywMAAOh27uHuaMgJW2G58l3xLqnL8RkdwKb4nQAAAJ9nVpuq3F0pV74rqWdz2vsZHZauAQAAACnAGGEkdcCJFUvXAAAAANgOQQcAAACA7RB0AAAAANgOQQcAAACA7RB0AAAAgCRiVpvyrvOmRNPPM0HQAQAAAJKEWW3Ks9oj3yafPKs9hJ1TIOgAAAAASSKwKxBt+ul0OFW5uzLeJSUsgg4AAACQJNzD3dGQE7bCcuW74l1SwiLooFu4XC45HI54l9Euq1atksPh0KpVq+JdCgAAQDPGCEP+G/26o+AO+W/0p1QD0FgRdGzC4XDE9OhsixYtksPhUGVlZaefOxlVVlbK4XBo0aJF8S4FAADYjDHC0NLipYSc0+gR7wLQOUpLS1uMlZWVKRgMtvpcd3vqqaf06aefxrsMAAAApAiCjk20NnOwatUqBYPBhJhV+OIXvxjvEgAAAJBCWLqWghoaGrR06VJdeumlOuuss9SnTx9deeWVMs2WtycMBoNauHChRo4cqd69eys7O1vnn3++pk+frj179kiKfP5m8eLFkiS32x1dHpefnx89T2uf0fn8Z2HWr1+vCRMmqFevXurXr5+mT5+uv//9763W//jjj+vLX/6ysrKylJeXp7lz5+rYsWNyOBxyuVzt/j589NFHmj17tnJzc9WrVy9ddtllevHFF9vcf+XKlfJ4PMrPz1dWVpbOPvtsFRcXKxAINNtv0aJFcrvdkqTFixc3WzK4e/duSdJ7772nuXPn6tJLL1W/fv2UlZWlCy64QPPmzdMnn3zS7vcAAACA1jGjk2Lq6+v1ta99TZWVlRozZoy++93v6vjx41q7dq08Ho98Pp9uu+02SZJlWSouLtaf/vQnXX755fra176mtLQ07dmzR6ZpaurUqRo2bJhmzJghSdq4caOmT58eDTh9+/ZtV02maWrt2rWaNGmSJkyYoFdffVVPPfWU3n//fb322mvN9l24cKHuvfde5ebmatasWUpPT9dzzz2n7du3x/R9+PTTT+VyufT222+rsLBQEydO1L59+zRlyhRde+21rR4zZ84cjR49WkVFRTrnnHO0f/9+vfTSSyoqKlJ5ebk8Ho+kSKjbvXu3nnzySU2cOLFZ+Dr5PSkvL9eKFSvkdrvlcrnU2NioN998Uw8++KA2btyoV199Venp6TG9JwAAAHyOlQSCwaAlyQoGg23u89lnn1l//etfrc8++6wbK0tsw4YNs/7xR/yTn/zEkmQtWLDAamxsjI6HQiFr3LhxVkZGhrV//37Lsizr//7v/yxJ1uTJk1uc+9ixY9bRo0ejX5eWllqSrEAg0GotEydObFHLE088YUmyevToYb322mvR8RMnTlgul8uSZFVVVUXHq6urLafTaQ0ZMsSqra1tVvvIkSMtSdbEiRNP/435XL2zZs1qNr5u3TpLkiXJeuKJJ5o9t3Pnzhbn+fDDD63BgwdbX/rSl5qNBwIBS5JVWlra6ut/8MEHVn19fYvxxYsXW5KsZ555pl3v41T4nQAAIHH5t/ut//jv/7D82/3xLiXptCcbWJZlsXStg8xqU9513qTqRtvY2Khf/epXOu+886JLqk7q06ePFi5cqIaGBpWXlzc7rmfPni3OlZmZqd69e3dKXTfddJMuv/zy6NdOp1PTp0+XJP35z3+Ojv/2t79VOBzWnXfeqQEDBjSr/e67747pNZ966illZGTonnvuaTZeXFysq6++utVjhg8f3mJs0KBBuv766/W3v/0tupSvPYYMGaKMjIwW4ydn0zZs2NDucwEAgORiVpvyrPbIt8knz2pPUv09mUxYutYBJy9Op8Opsj+VJc09zKurq3XkyBENHjw4+pmazzt06JAkRZeBXXTRRbr44ov129/+Vh988IEmT54sl8ulMWPGKC2t8zLy2LFjW4wNHTpUkvTxxx9Hx/7yl79Ikq644ooW+38+KJ1OKBTSrl27NHLkSA0cOLDF81deeaUqKipajO/cuVNLlizRH//4R+3fv1/19fXNnv/www81bNiwdtVgWZaeeOIJrVq1Su+8846CwaAaGxubnQsAANhTYFcg2vDT6XCqcndlUvwtmWwIOh2QrBfnRx99JEl699139e6777a5X11dnSSpR48e+uMf/6hFixbphRde0J133ilJOuecc3TbbbfprrvuktPpPOO6srOzW4z16BG5NMPhcHQsFApJUrPZnJNyc3Pb/XqnOk9b59qxY4fGjx+vUCgkt9utSZMmKTs7W2lpaaqsrNTGjRtbBJ9TueOOO/TII48oLy9PhmFo0KBByszMlBS5gUEs5wIAAMnFPdytsj+VRf+edOW74l2SLRF0OiBZL86TgeL666/X888/365j+vXrJ5/Pp4cffljbt2/XH//4R/l8PpWWlio9PV3z58/vypKbOVn/wYMHW8yc1NbWdug8rWntXL/4xS905MgRPf3007r55pubPTd79mxt3Lix3a9/8OBBLVu2TBdffLGqqqrUq1ev6HM1NTWtzrYBAAD7MEYY8t/oV+XuSrnyXUnxH8yTEZ/R6YCTF+cdBXckzbI1KbIULTs7W//7v/+r48ePx3Ssw+HQRRddpDlz5ugPf/iDJDW7HfXJmZ3Pz8B0ttGjR0uSXn/99RbPvfHGG+0+T3Z2toYPH64dO3aopqamxfP/8z//02Ls/fffl6TondVOsiyr1XpO9f3YuXOnLMtSUVFRs5DT1msDAAD7MUYYWlq8NGn+jkxGBJ0OSsaLs0ePHrr11lu1Z88e/fCHP2w17LzzzjvRmY7du3dH+7583skZj6ysrOjY2WefLUnat29fF1QeceONNyotLU0///nPdfjw4eh4XV2d7rvvvpjONXXqVDU0NGjhwoXNxtevX9/q53NOziD94+2uH3jgAb3zzjst9j/V9+Pkud54441mn8v54IMPunWGDAAAwM5YupZiFi9erC1btujhhx/W2rVrddVVV2nAgAHav3+/3n77bf3lL39RVVWVBgwYoK1bt+pb3/qWxo8fH/3g/sneMWlpafJ6vdHznmwU+pOf/ETvvvuucnJy1Ldv3+hdxDrDiBEjNG/ePN1///0aNWqUbrjhBvXo0UPl5eUaNWqU3nnnnXbfJGHu3LkqLy/X8uXL9e677+qqq67Svn379Nxzz+m6667T2rVrm+0/e/ZsPfHEE7r++ut1ww03qF+/fnrzzTe1ZcuWVve/8MILNXjwYK1evVqZmZkaOnSoHA6Hbr/99uid2l544QWNGzdOV199tWpra/Xyyy/r6quvjs4eAQAAoOOY0UkxmZmZ+u///m89/vjjGjhwoF544QWVlZXp1Vdf1aBBg/SrX/1Ko0aNkiSNGzdOP/7xj+VwOLR27Vr9/Oc/V2VlpYqKivT666/LMJpms0aOHKknnnhC/fv3l8/n04IFC/TQQw91ev333XefHn30UX3hC1/QY489pueee07f/va39eijj0pq/cYGrTnrrLO0ceNGfe9739Pf/vY3lZWVafv27VqzZo2+/e1vt9j/kksu0fr163XppZeqvLxcK1euVN++ffX6669r3LhxLfZ3Op0qLy/XP/3TP+m3v/2tFi5cqAULFujIkSOSpFWrVunOO+/UkSNH5PP59Oabb6qkpETPPvvsGXx3AAAAcJLDsiwr3kWcTigUUk5OjoLBYJt/yB47dky7du3S8OHDmy2pQmrYsGGDrrnmGs2dO1cPPvhgvMtJCPxOAAAAO2pPNpCY0UGSOXToUIsP+H/88cfRz7ZMnjw5DlUBAIBUlYxN5FMFn9FBUvmv//ovPfTQQ/rqV7+qwYMH68CBA1q3bp0OHjyoGTNmqLCwMN4lAgCAFJGsTeRTBUEHSWXChAkaO3asNmzYoI8++khOp1MXXXSRFixYoO9///vxLg8AAKSQZG0inyoIOkgq48ePl9/vj3cZAAAASdtEPlUQdAAAAIAOONlEvnJ3pVz5LmZzEgxBBwAAAOggY4RBwElQtrvrWhLcLRvoFvwuAACAVGaboON0OiVJx48fj3MlQGI4ceKEJKlHDyZuAQBA6rFN0ElPT1dmZqaCwSD/JRtQpJmW0+mM/kcAAACAVGKr/9Tbv39/7d+/Xx988IFycnKUnp4uh8MR77KAbmVZlurq6hQKhTRo0CB+BwAAQEqyVdDJzs6WJB0+fFj79++PczVA/DgcDvXt21c5OTnxLgUAgKRgVpsK7ArIPdzNzQVswmElwTqvUCiknJwcBYPBaJg5nePHjyscDndxZUBiSk9PZ8kaAADtZFab8qz2RPvh+G/0E3YSWHuzga1mdD4vPT1d6enp8S4DAAAACS6wKxANOU6HU5W7Kwk6NmCbmxEAAAAAHeEe7o6GnLAVlivfFe+S0AlsO6MDAAAAtIcxwpD/Rr8qd1fKle9iNscmbPsZHQAAAAD2095swNI1AAAAALZD0AEAAABgOwQdAAAAALbToaCzbNky5efnKysrSwUFBdq0aVOb+x4/flz33HOPzjvvPGVlZWn06NFat25dhwsGAAAAgNOJOeisWbNGJSUlKi0t1ZYtWzR69GgVFxfr4MGDre5/99136/HHH5fP59Nf//pXzZ49W9/85jf11ltvnXHxAAAAwElmtSnvOq/MajPepSABxHzXtYKCAl122WV65JFHJEmNjY3Ky8vT7bffrnnz5rXYf/Dgwbrrrrs0Z86c6Nj111+vnj176plnnmnXa3LXNQAAAJyKWW3Ks9oT7YXjv9HPbaJtqkvuutbQ0KDNmzerqKio6QRpaSoqKlJVVVWrx9TX1ysrK6vZWM+ePfXaa6+1+Tr19fUKhULNHgAAAEBbArsC0ZDjdDhVubsy3iUhzmIKOocPH1Y4HFZubm6z8dzcXNXU1LR6THFxsZYuXaq//e1vamxs1B/+8AeVl5frwIEDbb7OkiVLlJOTE33k5eXFUiYAAABSjHu4OxpywlZYrnxXvEtCnHX5Xdd++ctf6ktf+pIuvPBCZWRk6LbbbtPMmTOVltb2S8+fP1/BYDD62LdvX1eXCQAAgCRmjDDkv9GvOwruYNkaJEk9Ytm5f//+cjqdqq2tbTZeW1urgQMHtnrMOeeco5deeknHjh3T3//+dw0ePFjz5s3Tueee2+brZGZmKjMzM5bSAAAAkOKMEQYBB1ExzehkZGRo7NixqqioiI41NjaqoqJChYWFpzw2KytLQ4YM0YkTJ/TCCy/I4/F0rGIAAAAAOI2YZnQkqaSkRNOnT9e4ceM0fvx4lZWVqa6uTjNnzpQkTZs2TUOGDNGSJUskSX/605+0f/9+jRkzRvv379eiRYvU2NiouXPndu47AQAAAID/L+agM2XKFB06dEgLFy5UTU2NxowZo3Xr1kVvULB3795mn785duyY7r77bu3cuVO9e/fWN77xDT399NPq27dvp70JAAAAAPi8mPvoxAN9dAAAAABIXdRHBwAAAOhqZrUp7zqvzGoz3qUgiRF0AAAAkDDMalOe1R75NvnkWe0h7KDDCDoAAABIGIFdgWjTT6fDqcrdlfEuCUmKoAMAAICE4R7ujoacsBWWK98V75KQpGK+6xoAAADQVYwRhvw3+lW5u1KufBcNQNFh3HUNAAAAQNLgrmsAAAAAUhZBBwAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAADQ6cxqU951Xhp+Im4IOgAAAOhUZrUpz2qPfJt88qz2EHYQFwQdAAAAdKrArkC04afT4VTl7sp4l4QURNABAABAp3IPd0dDTtgKy5XvindJSEE94l0AAAAA7MUYYch/o1+VuyvlynfJGGHEuySkIIdlWVa8izid9nY/BQAAAGBv7c0GLF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAABAm8xqU951Xpp+IukQdAAAANAqs9qUZ7VHvk0+eVZ7CDtIKgQdAAAAtCqwKxBt+ul0OFW5uzLeJQHtRtABAABAq9zD3dGQE7bCcuW74l0S0G494l0AAAAAEpMxwpD/Rr8qd1fKle+SMcKId0lAuzksy7LiXcTptLf7KQAAAAB7a282YOkaAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAABACjBNyeuNbIFUQNABAACwOdOUPB7J54tsCTtIBQQdAAAAmwsEJKdTCocj28rKeFcEdD2CDgAAgM253U0hJxyWXK54VwR0vR7xLgAAAABdyzAkvz8yk+NyRb4G7I6gAwAAkAIMg4CD1MLSNQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAgCRhmpLXS8NPoD0IOgAAAEnANCWPR/L5IlvCDnBqBB0AAIAkEAg0Nfx0OiM9cQC0jaADAACQBNzuppATDkcafwJoGw1DAQAAkoBhSH5/ZCbH5aL5J3A6BB0AAIAkYRgEHKC9WLoGAAAAwHYIOgAAAABsh6ADAAAAwHYIOgAAAABsh6ADAADQzUxT8npp+gl0JYIOAABANzJNyeORfL7IlrADdA2CDgAAQDcKBJqafjqdkb44ADofQQcAAKAbud1NISccjjT/BND5aBgKAADQjQxD8vsjMzkuFw1Aga5C0AEAAOhmhkHAAboaS9cAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAAA6yDQlr5emn0Ai6lDQWbZsmfLz85WVlaWCggJt2rTplPuXlZVpxIgR6tmzp/Ly8uT1enXs2LEOFQwAAJAITFPyeCSfL7Il7ACJJeags2bNGpWUlKi0tFRbtmzR6NGjVVxcrIMHD7a6/7PPPqt58+aptLRU27Zt04oVK7RmzRr95Cc/OePiAQAA4iUQaGr66XRG+uIASBwxB52lS5dq1qxZmjlzpkaOHKnHHntMvXr10sqVK1vd/4033tDll1+um266Sfn5+br22mv1ne9857SzQAAAAInM7W4KOeFwpPkngMQRU9BpaGjQ5s2bVVRU1HSCtDQVFRWpqqqq1WMmTJigzZs3R4PNzp079corr+gb3/hGm69TX1+vUCjU7AEAAJBIDEPy+6U77ohsaQAKJJYesex8+PBhhcNh5ebmNhvPzc3V9u3bWz3mpptu0uHDh3XFFVfIsiydOHFCs2fPPuXStSVLlmjx4sWxlAYAANDtDIOAAySqLr/rWmVlpe6//349+uij2rJli8rLy7V27Vrde++9bR4zf/58BYPB6GPfvn1dXSYAAAAAG4lpRqd///5yOp2qra1tNl5bW6uBAwe2esyCBQs0depU3XLLLZKkUaNGqa6uTt/73vd01113KS2tZdbKzMxUZmZmLKUBAAAAQFRMMzoZGRkaO3asKioqomONjY2qqKhQYWFhq8d8+umnLcKM0+mUJFmWFWu9AAAAAHBaMc3oSFJJSYmmT5+ucePGafz48SorK1NdXZ1mzpwpSZo2bZqGDBmiJUuWSJImTZqkpUuX6pJLLlFBQYF27NihBQsWaNKkSdHAAwAAAACdKeagM2XKFB06dEgLFy5UTU2NxowZo3Xr1kVvULB3795mMzh33323HA6H7r77bu3fv1/nnHOOJk2apPvuu6/z3gUAAEAHmWakJ47bzY0FADtxWEmwfiwUCiknJ0fBYFDZ2dnxLgcAANiEaUoeT1MvHG4TDSS+9maDLr/rGgAAQKIKBJpCjtMpVVbGuyIAnYWgAwAAUpbb3RRywmHJ5Yp3RQA6S8yf0QEAALALw4gsV6usjIQclq0B9kHQAQAAKc0wCDiAHbF0DQAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAA2IJpSl5vZAsABB0AAJD0TFPyeCSfL7Il7AAg6AAAgKQXCDQ1/XQ6I31xAKQ2gg4AAEh6bndTyAmHI80/AaQ2GoYCAICkZxiS3x+ZyXG5aAAKgKADAABswjAIOACasHQNAAAAgO0QdAAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAkDNOUvF4afgI4cwQdAACQEExT8ngkny+yJewAOBMEHQAAkBACgaaGn05npCcOAHQUQQcAACQEt7sp5ITDkcafANBRNAwFAAAJwTAkvz8yk+Ny0fwTwJkh6AAAgIRhGAQcAJ2DpWsAAAAAbIegAwAAAMB2CDoAAAAAbIegAwAAAMB2CDoAAKDTmabk9dL0E0D8EHQAAECnMk3J45F8vsiWsAMgHgg6AACgUwUCTU0/nc5IXxwA6G4EHQAA0Knc7qaQEw5Hmn8CQHejYSgAAOhUhiH5/ZGZHJeLBqAA4oOgAwAAOp1hEHAAxBdL1wAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAAgO0QdAAAQJtMU/J6afoJIPkQdAAAQKtMU/J4JJ8vsiXsAEgmBB0AANCqQKCp6afTGemLAwDJgqADAABa5XY3hZxwONL8EwCSBQ1DAQBAqwxD8vsjMzkuFw1AASQXgg4AAGiTYRBwACQnlq4BAAAAsB2CDgAAAADbIegAAAAAsB2CDgAAAADbIegAAGBzpil5vTT8BJBaCDoAANiYaUoej+TzRbaEHQCpgqADAICNBQJNDT+dzkhPHABIBQQdAABszO1uCjnhcKTxJwCkAhqGAgBgY4Yh+f2RmRyXi+afAFIHQQcAAJszDAIOgNTD0jUAAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAJKEaUpeL00/AaA9CDoAACQB05Q8Hsnni2wJOwBwah0KOsuWLVN+fr6ysrJUUFCgTZs2tbmvy+WSw+Fo8bjuuus6XDQAAKkmEGhq+ul0RvriAADaFnPQWbNmjUpKSlRaWqotW7Zo9OjRKi4u1sGDB1vdv7y8XAcOHIg+3nnnHTmdTv3Lv/zLGRcPAECqcLubQk44HGn+CQBom8OyLCuWAwoKCnTZZZfpkUcekSQ1NjYqLy9Pt99+u+bNm3fa48vKyrRw4UIdOHBAZ511VrteMxQKKScnR8FgUNnZ2bGUCwCAbZhmZCbH5aIBKIDU1d5s0COWkzY0NGjz5s2aP39+dCwtLU1FRUWqqqpq1zlWrFihG2+88ZQhp76+XvX19dGvQ6FQLGUCAGBLhkHAAYD2imnp2uHDhxUOh5Wbm9tsPDc3VzU1Nac9ftOmTXrnnXd0yy23nHK/JUuWKCcnJ/rIy8uLpUwAAAAAKa5b77q2YsUKjRo1SuPHjz/lfvPnz1cwGIw+9u3b100VAgAAALCDmJau9e/fX06nU7W1tc3Ga2trNXDgwFMeW1dXp9WrV+uee+457etkZmYqMzMzltIAAAAAICqmGZ2MjAyNHTtWFRUV0bHGxkZVVFSosLDwlMf+7ne/U319vW6++eaOVQoAAAAA7RTz0rWSkhItX75cTz75pLZt26Zbb71VdXV1mjlzpiRp2rRpzW5WcNKKFSs0efJk9evX78yrBgAgiZmm5PXS9BMAulJMS9ckacqUKTp06JAWLlyompoajRkzRuvWrYveoGDv3r1KS2uen6qrq/Xaa69p/fr1nVM1AABJyjQljyfSD6esTPL7uZMaAHSFmPvoxAN9dAAAduH1Sj5fU/PPO+6Qli6Nd1UAkDzamw269a5rAACkOre7KeSEw5HmnwCAzhfz0jUAANBxhhFZrlZZGQk5LFsDgK5B0AEAoJsZBgEHALoaS9cAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAAOgA04z0xDHNeFcCAGgNQQcAgBiZpuTxRBp/ejyEHQBIRAQdAABiFAg0Nfx0OiM9cQAAiYWgAwBAjNzuppATDkcafwIAEgsNQwEAiJFhSH5/ZCbH5aL5JwAkIoIOAAAdYBgEHABIZCxdAwAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAQCkNNOUvF6afgKA3RB0AAApyzQlj0fy+SJbwg4A2AdBBwCQsgKBpqafTmekLw4AwB4IOgCAlOV2N4WccDjS/BMAYA80DAUApCzDkPz+yEyOy0UDUACwE4IOACClGQYBBwDsiKVrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AICkZ5qS10vDTwBAE4IOACCpmabk8Ug+X2RL2AEASAQdAECSCwSaGn46nZGeOAAAEHQAAEnN7W4KOeFwpPEnAAA0DAUAJDXDkPz+yEyOy0XzTwBABEEHAJD0DIOAAwBojqVrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6AICEYZqS10vTTwDAmSPoAAASgmlKHo/k80W2hB0AwJkg6AAAEkIg0NT00+mM9MUBAKCjCDoAgITgdjeFnHA40vwTAICOomEoACAhGIbk90dmclwuGoACAM4MQQcAkDAMg4ADAOgcLF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAHQ605S8Xpp+AgDih6ADAOhUpil5PJLPF9kSdgAA8UDQAQB0qkCgqemn0xnpiwMAQHcj6AAAOpXb3RRywuFI808AALobDUMBAJ3KMCS/PzKT43LRABQAEB8EHQBApzMMAg4AIL5YugYAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAaJVpSl4vDT8BAMmJoAMAaME0JY9H8vkiW8IOACDZEHQAAC0EAk0NP53OSE8cAACSCUEHANCC290UcsLhSONPAACSSYeCzrJly5Sfn6+srCwVFBRo06ZNp9z/448/1pw5czRo0CBlZmbqggsu0CuvvNKhggEAXc8wJL9fuuOOyJbmnwCAZNMj1gPWrFmjkpISPfbYYyooKFBZWZmKi4tVXV2tAQMGtNi/oaFB11xzjQYMGKDnn39eQ4YM0Z49e9S3b9/OqB8A0EUMg4ADAEheDsuyrFgOKCgo0GWXXaZHHnlEktTY2Ki8vDzdfvvtmjdvXov9H3vsMf3sZz/T9u3blZ6e3q7XqK+vV319ffTrUCikvLw8BYNBZWdnx1IuAAAAABsJhULKyck5bTaIaelaQ0ODNm/erKKioqYTpKWpqKhIVVVVrR5jmqYKCws1Z84c5ebm6itf+Yruv/9+hcPhNl9nyZIlysnJiT7y8vJiKRMAAABAiosp6Bw+fFjhcFi5ubnNxnNzc1VTU9PqMTt37tTzzz+vcDisV155RQsWLNDPf/5z/fSnP23zdebPn69gMBh97Nu3L5YyAQAAAKS4mD+jE6vGxkYNGDBAv/71r+V0OjV27Fjt379fP/vZz1RaWtrqMZmZmcrMzOzq0gAAAADYVExBp3///nI6naqtrW02Xltbq4EDB7Z6zKBBg5Seni6n0xkdu+iii1RTU6OGhgZlZGR0oGwAQHuZZqQvjtvNzQUAAKkjpqVrGRkZGjt2rCoqKqJjjY2NqqioUGFhYavHXH755dqxY4caGxujY++9954GDRpEyAGALmaakscj+XyRrWnGuyIAALpHzH10SkpKtHz5cj355JPatm2bbr31VtXV1WnmzJmSpGnTpmn+/PnR/W+99VZ99NFH+sEPfqD33ntPa9eu1f333685c+Z03rsAALQqEGhq+ul0SpWV8a4IAIDuEfNndKZMmaJDhw5p4cKFqqmp0ZgxY7Ru3broDQr27t2rtLSm/JSXl6ff//738nq9uvjiizVkyBD94Ac/0I9//OPOexcAgFa53VJZWVPYcbniXREAAN0j5j468dDee2UDAFoyzchMjsvFZ3QAAMmvvdmgy++6BgCIL8Mg4AAAUk/Mn9EBAAAAgERH0AEAAABgOwQdAAAAALZD0AEAAABgOwQdAEgSpil5vTT9BACgPQg6AJAETFPyeCSfL7Il7AAAcGoEHQBIAoFAU9NPpzPSFwcAALSNoAMAScDtbgo54XCk+ScAAGgbDUMBIAkYhuT3R2ZyXC4agAIAcDoEHQBIEoZBwAEAoL1YugYAAADAdgg6AAAAAGyHoAMAAADAdgg6AAAAAGyHoAMA3cg0Ja+Xhp8AAHQ1gg4AdBPTlDweyeeLbAk7AAB0HYIOAHSTQKCp4afTGemJAwAAugZBBwC6idvdFHLC4UjjTwAA0DVoGAoA3cQwJL8/MpPjctH8EwCArkTQAYBuZBgEHAAAugNL1wAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAAgO0QdACgA0xT8npp+gkAQKIi6ABAjExT8ngkny+yJewAAJB4CDoAEKNAoKnpp9MZ6YsDAAASC0EHAGLkdjeFnHA40vwTAAAkFhqGAkCMDEPy+yMzOS4XDUABAEhEBB0A6ADDIOAAAJDIWLoGAAAAwHYIOgAAAABsh6ADAAAAwHYIOgAAAABsh6ADIGWZpuT10vATAAA7IugASEmmKXk8ks8X2RJ2AACwF4IOgJQUCDQ1/HQ6Iz1xAACAfRB0AKQkt7sp5ITDkcafAADAPmgYCiAlGYbk90dmclwumn8CAGA3BB0AKcswCDgAANgVS9cAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAJD3TlLxemn4CAIAmBB0ASc00JY9H8vkiW8IOAACQCDoAklwg0NT00+mM9MUBAAAg6ABIam53U8gJhyPNPwEAAGgYCiCpGYbk90dmclwuGoACAIAIgg6ApGcYBBwAANAcS9cAAAAA2A5BBwAAAIDtEHQAAAAA2A5BBwAAAIDtEHQAJAzTlLxemn4CAIAzR9ABkBBMU/J4JJ8vsiXsAACAM0HQAZAQAoGmpp9OZ6QvDgAAQEcRdAAkBLe7KeSEw5HmnwAAAB1Fw1AACcEwJL8/MpPjctEAFAAAnJkOzegsW7ZM+fn5ysrKUkFBgTZt2tTmvqtWrZLD4Wj2yMrK6nDBAOzLMKSlSwk5AADgzMUcdNasWaOSkhKVlpZqy5YtGj16tIqLi3Xw4ME2j8nOztaBAweijz179pxR0QAAAABwKjEHnaVLl2rWrFmaOXOmRo4cqccee0y9evXSypUr2zzG4XBo4MCB0Udubu4ZFQ0AAAAApxJT0GloaNDmzZtVVFTUdIK0NBUVFamqqqrN4z755BMNGzZMeXl58ng8evfdd0/5OvX19QqFQs0eAAAAANBeMQWdw4cPKxwOt5iRyc3NVU1NTavHjBgxQitXrpTf79czzzyjxsZGTZgwQR988EGbr7NkyRLl5OREH3l5ebGUCQAAACDFdfntpQsLCzVt2jSNGTNGEydOVHl5uc455xw9/vjjbR4zf/58BYPB6GPfvn1dXSaATmKaktdLw08AABBfMd1eun///nI6naqtrW02Xltbq4EDB7brHOnp6brkkku0Y8eONvfJzMxUZmZmLKUBSACmKXk8kV44ZWWR20VzBzUAABAPMc3oZGRkaOzYsaqoqIiONTY2qqKiQoWFhe06Rzgc1ttvv61BgwbFVimAhBcINDX8dDojPXEAAADiIealayUlJVq+fLmefPJJbdu2Tbfeeqvq6uo0c+ZMSdK0adM0f/786P733HOP1q9fr507d2rLli26+eabtWfPHt1yyy2d9y4AJAS3uynkhMORxp8AAADxENPSNUmaMmWKDh06pIULF6qmpkZjxozRunXrojco2Lt3r9LSmvLTkSNHNGvWLNXU1OgLX/iCxo4dqzfeeEMjR47svHcBICEYRmS5WmVlJOSwbA0AAMSLw7IsK95FnE4oFFJOTo6CwaCys7PjXQ4AAACAOGlvNujyu64BAAAAQHcj6AAAAACwHYIOAAAAANsh6AAAAACwHYIOgFaZpuT1RrYAAADJhqADoAXTlDweyeeLbAk7AAAg2RB0ALQQCDQ1/XQ6I31xAAAAkglBB0ALbndTyAmHI80/AQAAkkmPeBcAIPEYhuT3R2ZyXK7I1wAAAMmEoAOgVYZBwAEAAMmLpWsAAAAAbIegAwAAAMB2CDoAAAAAbIegAwAAAMB2CDqAjZmm5PXS8BMAAKQegg5gU6YpeTySzxfZEnYAAEAqIegANhUINDX8dDojPXEAAABSBUEHsCm3uynkhMORxp8AAACpgoahgE0ZhuT3R2ZyXC6afwIAgNRC0AFszDAIOAAAIDWxdA0AAACA7RB0AAAAANgOQQcAAACA7RB0AAAAANgOQQdIAqYpeb00/QQAAGgvgg6Q4ExT8ngkny+yJewAAACcHkEHSHCBQFPTT6cz0hcHAAAAp0bQARKc290UcsLhSPNPAAAAnBoNQ4EEZxiS3x+ZyXG5aAAKAADQHgQdIAkYBgEHAAAgFixdAwAAAGA7BB0AAAAAtkPQAQAAAGA7BB0AAAAAtkPQAbqRaUpeL00/AQAAuhpBB+gmpil5PJLPF9kSdgAAALoOQQfoJoFAU9NPpzPSFwcAAABdg6ADdBO3uynkhMOR5p8AAADoGjQMBbqJYUh+f2Qmx+WiASgAAEBXIugA3cgwCDgAAADdgaVrAAAAAGyHoAMAAADAdgg6AAAAAGyHoAMAAADAdgg6QIxMU/J6afgJAACQyAg6QAxMU/J4JJ8vsiXsAAAAJCaCDhCDQKCp4afTGemJAwAAgMRD0AFi4HY3hZxwONL4EwAAAImHhqFADAxD8vsjMzkuF80/AQAAEhVBB4iRYRBwAAAAEh1L1wAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAAgO0QdJCyTFPyemn6CQAAYEcEHaQk05Q8Hsnni2wJOwAAAPZC0EFKCgSamn46nZG+OAAAALAPgg5SktvdFHLC4UjzTwAAANgHDUORkgxD8vsjMzkuFw1AAQAA7Iagg5RlGAQcAAAAu2LpGgAAAADb6VDQWbZsmfLz85WVlaWCggJt2rSpXcetXr1aDodDkydP7sjLAgAAAEC7xBx01qxZo5KSEpWWlmrLli0aPXq0iouLdfDgwVMet3v3bv3whz/UlVde2eFiAQAAAKA9Yg46S5cu1axZszRz5kyNHDlSjz32mHr16qWVK1e2eUw4HNa//uu/avHixTr33HNP+xr19fUKhULNHgAAAADQXjEFnYaGBm3evFlFRUVNJ0hLU1FRkaqqqto87p577tGAAQP03e9+t12vs2TJEuXk5EQfeXl5sZSJFGOaktdL008AAAA0iSnoHD58WOFwWLm5uc3Gc3NzVVNT0+oxr732mlasWKHly5e3+3Xmz5+vYDAYfezbty+WMpFCTFPyeCSfL7Il7AAAAEDq4ruuHT16VFOnTtXy5cvVv3//dh+XmZmp7OzsZg+gNYFAU9NPpzPSFwcAAACIqY9O//795XQ6VVtb22y8trZWAwcObLH/+++/r927d2vSpEnRscbGxsgL9+ih6upqnXfeeR2pG5Akud1SWVlT2HG54l0RAAAAEkFMMzoZGRkaO3asKioqomONjY2qqKhQYWFhi/0vvPBCvf3229q6dWv0YRiG3G63tm7dymdvcMYMQ/L7pTvuiGxpAAoAAAApxhkdSSopKdH06dM1btw4jR8/XmVlZaqrq9PMmTMlSdOmTdOQIUO0ZMkSZWVl6Stf+Uqz4/v27StJLcaBjjIMAg4AAACaiznoTJkyRYcOHdLChQtVU1OjMWPGaN26ddEbFOzdu1dpaV360R8AAAAAOCWHZVlWvIs4nVAopJycHAWDQW5MAAAAAKSw9mYDpl4AAAAA2A5BBwAAAIDtEHSQEExT8npp+AkAAIDOQdBB3Jmm5PFIPl9kS9gBAADAmSLoIO4CgaaGn06nVFkZ74oAAACQ7Ag6iDu3uynkhMOSyxXvigAAAJDsYu6jA3Q2w5D8/shMjstF808AAACcOYIOEoJhEHAAAADQeVi6BgAAAMB2CDoAAAAAbIegAwAAAMB2CDoAAAAAbIegg05lmpLXS9NPAAAAxBdBB53GNCWPR/L5IlvCDgAAAOKFoINOEwg0Nf10OiN9cQAAAIB4IOig07jdTSEnHI40/wQAAADigYah6DSGIfn9kZkcl4sGoAAAAIgfgg46lWEQcAAAABB/LF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9BBC6Ypeb00/AQAAEDyIuigGdOUPB7J54tsCTsAAABIRgQdNBMINDX8dDojPXEAAACAZEPQQTNud1PICYcjjT8BAACAZEPDUDRjGJLfH5nJcblo/gkAAIDkRNBBC4ZBwAEAAEByY+kaAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYKOjZmm5PXS9BMAAACph6BjU6YpeTySzxfZEnYAAACQSgg6NhUINDX9dDojfXEAAACAVEHQsSm3uynkhMOR5p8AAABAqqBhqE0ZhuT3R2ZyXC4agAIAACC1EHRszDAIOAAAAEhNLF0DAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9BJAqYpeb00/QQAAADai6CT4ExT8ngkny+yJewAAAAAp0fQSXCBQFPTT6cz0hcHAAAAwKkRdBKc290UcsLhSPNPAAAAAKdGw9AEZxiS3x+ZyXG5aAAKAAAAtAdBJwkYBgEHAAAAiAVL1wAAAADYDkEHAAAAgO0QdAAAAADYDkEHAAAAgO0QdLqJaUpeLw0/AQAAgO5A0OkGpil5PJLPF9kSdgAAAICuRdDpBoFAU8NPpzPSEwcAAABA1yHodAO3uynkhMORxp8AAAAAug4NQ7uBYUh+f2Qmx+Wi+ScAAADQ1Qg63cQwCDgAAABAd2HpGgAAAADbIegAAAAAsJ0OBZ1ly5YpPz9fWVlZKigo0KZNm9rct7y8XOPGjVPfvn111llnacyYMXr66ac7XDAAAAAAnE7MQWfNmjUqKSlRaWmptmzZotGjR6u4uFgHDx5sdf+zzz5bd911l6qqqvR///d/mjlzpmbOnKnf//73Z1w8AAAAALTGYVmWFcsBBQUFuuyyy/TII49IkhobG5WXl6fbb79d8+bNa9c5Lr30Ul133XW6995727V/KBRSTk6OgsGgsrOzYym305lmpC+O283NBQAAAIDu1t5sENOMTkNDgzZv3qyioqKmE6SlqaioSFVVVac93rIsVVRUqLq6WldddVWb+9XX1ysUCjV7JALTlDweyeeLbE0z3hUBAAAAaE1MQefw4cMKh8PKzc1tNp6bm6uampo2jwsGg+rdu7cyMjJ03XXXyefz6Zprrmlz/yVLlignJyf6yMvLi6XMLhMINDX9dDojfXEAAAAAJJ5uuetanz59tHXrVv35z3/Wfffdp5KSElWeIiXMnz9fwWAw+ti3b193lHlabndTyAmHI80/AQAAACSemBqG9u/fX06nU7W1tc3Ga2trNXDgwDaPS0tL0/nnny9JGjNmjLZt26YlS5bI1UZSyMzMVGZmZiyldQvDkPz+yEyOy8VndAAAAIBEFdOMTkZGhsaOHauKioroWGNjoyoqKlRYWNju8zQ2Nqq+vj6Wl04YhiEtXUrIAQAAABJZTDM6klRSUqLp06dr3LhxGj9+vMrKylRXV6eZM2dKkqZNm6YhQ4ZoyZIlkiKftxk3bpzOO+881dfX65VXXtHTTz+tX/3qV537TgAAAADg/4s56EyZMkWHDh3SwoULVVNTozFjxmjdunXRGxTs3btXaWlNE0V1dXX6/ve/rw8++EA9e/bUhRdeqGeeeUZTpkzpvHcBAAAAAJ8Tcx+deEikPjoAAAAA4qdL+ugAAAAAQDIg6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwHYIOAAAAANsh6AAAAACwnR7xLqA9LMuSJIVCoThXAgAAACCeTmaCkxmhLUkRdI4ePSpJysvLi3MlAAAAABLB0aNHlZOT0+bzDut0USgBNDY26sMPP1SfPn3kcDjiWksoFFJeXp727dun7OzsuNaC5MP1gzPB9YOO4trBmeD6wZnoiuvHsiwdPXpUgwcPVlpa25/ESYoZnbS0NA0dOjTeZTSTnZ3NLzs6jOsHZ4LrBx3FtYMzwfWDM9HZ18+pZnJO4mYEAAAAAGyHoAMAAADAdgg6McrMzFRpaakyMzPjXQqSENcPzgTXDzqKawdngusHZyKe109S3IwAAAAAAGLBjA4AAAAA2yHoAAAAALAdgg4AAAAA2yHoAAAAALAdgg4AAAAA2yHotGLZsmXKz89XVlaWCgoKtGnTplPu/7vf/U4XXnihsrKyNGrUKL3yyivdVCkSUSzXz/Lly3XllVfqC1/4gr7whS+oqKjotNcb7CvWf3tOWr16tRwOhyZPnty1BSKhxXr9fPzxx5ozZ44GDRqkzMxMXXDBBfz/VwqL9fopKyvTiBEj1LNnT+Xl5cnr9erYsWPdVC0SxauvvqpJkyZp8ODBcjgceumll057TGVlpS699FJlZmbq/PPP16pVq7qsPoLOP1izZo1KSkpUWlqqLVu2aPTo0SouLtbBgwdb3f+NN97Qd77zHX33u9/VW2+9pcmTJ2vy5Ml65513urlyJIJYr5/Kykp95zvfUSAQUFVVlfLy8nTttddq//793Vw54i3Wa+ek3bt364c//KGuvPLKbqoUiSjW66ehoUHXXHONdu/ereeff17V1dVavny5hgwZ0s2VIxHEev08++yzmjdvnkpLS7Vt2zatWLFCa9as0U9+8pNurhzxVldXp9GjR2vZsmXt2n/Xrl267rrr5Ha7tXXrVv3Hf/yHbrnlFv3+97/vmgItNDN+/Hhrzpw50a/D4bA1ePBga8mSJa3uf8MNN1jXXXdds7GCggLr3//937u0TiSmWK+ff3TixAmrT58+1pNPPtlVJSJBdeTaOXHihDVhwgTrN7/5jTV9+nTL4/F0Q6VIRLFeP7/61a+sc88912poaOiuEpHAYr1+5syZY331q19tNlZSUmJdfvnlXVonEpsk68UXXzzlPnPnzrW+/OUvNxubMmWKVVxc3CU1MaPzOQ0NDdq8ebOKioqiY2lpaSoqKlJVVVWrx1RVVTXbX5KKi4vb3B/21ZHr5x99+umnOn78uM4+++yuKhMJqKPXzj333KMBAwbou9/9bneUiQTVkevHNE0VFhZqzpw5ys3N1Ve+8hXdf//9CofD3VU2EkRHrp8JEyZo8+bN0eVtO3fu1CuvvKJvfOMb3VIzkld3/93co0vOmqQOHz6scDis3NzcZuO5ubnavn17q8fU1NS0un9NTU2X1YnE1JHr5x/9+Mc/1uDBg1v8IwB768i189prr2nFihXaunVrN1SIRNaR62fnzp364x//qH/913/VK6+8oh07duj73/++jh8/rtLS0u4oGwmiI9fPTTfdpMOHD+uKK66QZVk6ceKEZs+ezdI1nFZbfzeHQiF99tln6tmzZ6e+HjM6QIJ44IEHtHr1ar344ovKysqKdzlIYEePHtXUqVO1fPly9e/fP97lIAk1NjZqwIAB+vWvf62xY8dqypQpuuuuu/TYY4/FuzQkgcrKSt1///169NFHtWXLFpWXl2vt2rW69957410a0AwzOp/Tv39/OZ1O1dbWNhuvra3VwIEDWz1m4MCBMe0P++rI9XPSQw89pAceeEAbNmzQxRdf3JVlIgHFeu28//772r17tyZNmhQda2xslCT16NFD1dXVOu+887q2aCSMjvzbM2jQIKWnp8vpdEbHLrroItXU1KihoUEZGRldWjMSR0eunwULFmjq1Km65ZZbJEmjRo1SXV2dvve97+muu+5SWhr/HR2ta+vv5uzs7E6fzZGY0WkmIyNDY8eOVUVFRXSssbFRFRUVKiwsbPWYwsLCZvtL0h/+8Ic294d9deT6kaT//M//1L333qt169Zp3Lhx3VEqEkys186FF16ot99+W1u3bo0+DMOI3sUmLy+vO8tHnHXk357LL79cO3bsiAZkSXrvvfc0aNAgQk6K6cj18+mnn7YIMydDc+Qz6UDruv3v5i65xUESW716tZWZmWmtWrXK+utf/2p973vfs/r27WvV1NRYlmVZU6dOtebNmxfd//XXX7d69OhhPfTQQ9a2bdus0tJSKz093Xr77bfj9RYQR7FePw888ICVkZFhPf/889aBAweij6NHj8brLSBOYr12/hF3XUttsV4/e/futfr06WPddtttVnV1tfXyyy9bAwYMsH7605/G6y0gjmK9fkpLS60+ffpYv/3tb62dO3da69evt8477zzrhhtuiNdbQJwcPXrUeuutt6y33nrLkmQtXbrUeuutt6w9e/ZYlmVZ8+bNs6ZOnRrdf+fOnVavXr2sH/3oR9a2bdusZcuWWU6n01q3bl2X1EfQaYXP57O++MUvWhkZGdb48eOtN998M/rcxIkTrenTpzfb/7nnnrMuuOACKyMjw/ryl79srV27tpsrRiKJ5foZNmyYJanFo7S0tPsLR9zF+m/P5xF0EOv188Ybb1gFBQVWZmamde6551r33XefdeLEiW6uGokiluvn+PHj1qJFi6zzzjvPysrKsvLy8qzvf//71pEjR7q/cMRVIBBo9e+Yk9fL9OnTrYkTJ7Y4ZsyYMVZGRoZ17rnnWk888USX1eewLOYYAQAAANgLn9EBAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDsEHQAAAAC2Q9ABAAAAYDv/D6qYlTdAYn9qAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380a6f34-6b6c-4150-9b1e-5f27b7366681",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Build model with torch\n",
    "# Create linear regression model class\n",
    "class LinearRegressionModel(nn.Module): # <- () means inherhits from nn.Module\n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize model parameters ( HINT: these could be different layers from torch.nn, single parameters, hard-coded values or functions ) \n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))  # <-- requires_grad = True mean pytorch will track the gradients of this specific parameter for use with torch.autograd\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
    "\n",
    "    #Forward method to define the computiation in the model [ this method require to be overwrite, and it defines what happens in the forward computiation ]\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # <- \"x\" is the    [Forward defines the computation performed at every call.]\n",
    "        return self.weights * x + self.bias # this is the linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb90d78e-013b-4c0a-ba99-1550a055ff0d",
   "metadata": {},
   "source": [
    "## what our model does: \n",
    "Start with random values (weight $ bias)\n",
    "Look at training data and adjust the random values to better represent (or get closer to) the ideal values (the weight & bias values we used to create the data)\n",
    "How does it do so ? \n",
    "2 Main AlgorithmsL \n",
    "1. Gradient descent\n",
    "2. Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fb4e6-0c43-49d0-9028-d10fee7e7353",
   "metadata": {},
   "source": [
    "----------\n",
    "Now we careate a model, see what's inside... \n",
    "\n",
    "So we can check our model parameters or what;s insde our model using `.parameters().`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9baca0-3b8e-4eab-ba08-001c8c0ad5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random seed \n",
    "torch.manual_seed(42)\n",
    "\n",
    "#create an instance of the model (this is a subclass of nn.Module)\n",
    "model_0 = LinearRegressionModel()\n",
    "\n",
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae311195-169c-40a8-b8a2-023b018bfe19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target is to make random seed parampter to [grow] to be the orginal weight and bias\n",
    "weight, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b300bc9-f28e-4cf5-a944-262171d6faab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68c997-ede1-4b77-ad35-b0adfef3eb92",
   "metadata": {},
   "source": [
    "### Making prediction using `torch.inference_mode()`\n",
    "To Check our model's predictive power, let's see how well it predicts `y_test` base on `X_test`\n",
    "\n",
    "When we Pass the data throught our model it's going to run it through the `forward()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2c5a94-3d10-4b18-a2af-84f3388a7044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3982],\n",
       "         [0.4049],\n",
       "         [0.4116],\n",
       "         [0.4184],\n",
       "         [0.4251],\n",
       "         [0.4318],\n",
       "         [0.4386],\n",
       "         [0.4453],\n",
       "         [0.4520],\n",
       "         [0.4588]]),\n",
       " tensor([[0.8600],\n",
       "         [0.8740],\n",
       "         [0.8880],\n",
       "         [0.9020],\n",
       "         [0.9160],\n",
       "         [0.9300],\n",
       "         [0.9440],\n",
       "         [0.9580],\n",
       "         [0.9720],\n",
       "         [0.9860]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to direct do the predict without any training?\n",
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "250023c0-d2d6-4c29-b149-191245ac3334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To visuslize this res for now\n",
    "plot_predictions(predictions=y_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613e6e7d-cb7f-4fd8-a00e-cc4ff3f10658",
   "metadata": {},
   "source": [
    "## Train model\n",
    "the whole idea of training is for a model to move from some *unknown* parameters (these may be random) to some *known* parameters.\n",
    "\n",
    "or in other words from a poor representation of the data\n",
    "\n",
    " - One way to measure how poor or how wrong your models prodiction are is to use a loss function.\n",
    "\n",
    " - * Note: loss function may also be called cost function or criterion in different areas. For our case, We're going to refer to it as losss function.\n",
    "  \n",
    "Things we need to train: \n",
    "* **Loss function:** A function to measure how wrong your model's predictions are to the ideal outputs, lower is better [https://pytorch.org/docs/stable/nn.html#loss-functions] -- for vary functions for different purpose\n",
    "* **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters (e.g. weight & bias) to improve the loss function.\n",
    "\n",
    "  And specifically for PyTorch, we need:\n",
    "  - a training loop\n",
    "  - a test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b274b9-4118-4c4d-b2c4-84ef2c315221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosse and set uo a loss function\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "#setup an optimizer (stochastic gradient descent)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr = 0.0001) # lr stand for --> learning Rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8919e73b-10f0-466d-a482-ec86a15c4e31",
   "metadata": {},
   "source": [
    "### Build up the training loop  --> [Also a testing loop] in pyTorch\n",
    "A couple of things we need in a training loop: \n",
    "0. Loop through the data\n",
    "1. Forward pass (this involves data moving through our model's `forward()` functions) to make predictions on data - also called forward propagation\n",
    "2. Calculate the loss (Compare forward pass predictions to ground truth labels)\n",
    "3. Optimizer zero grad\n",
    "4. Loss backward - move backwards through the newwork to calculate the gradients of each of the parameters of our model with respect to the loss\n",
    "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61649d4-1dcb-49d4-89fc-805529185d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | MAE Train Loss: 0.31288138031959534 | MAE Test Loss: 0.4944015145301819 \n",
      "Epoch: 10 | MAE Train Loss: 0.31172919273376465 | MAE Test Loss: 0.49305421113967896 \n",
      "Epoch: 20 | MAE Train Loss: 0.31057703495025635 | MAE Test Loss: 0.4917070269584656 \n",
      "Epoch: 30 | MAE Train Loss: 0.30942484736442566 | MAE Test Loss: 0.4903597831726074 \n",
      "Epoch: 40 | MAE Train Loss: 0.30827268958091736 | MAE Test Loss: 0.48901262879371643 \n",
      "Epoch: 50 | MAE Train Loss: 0.30712056159973145 | MAE Test Loss: 0.4876653552055359 \n",
      "Epoch: 60 | MAE Train Loss: 0.30596840381622314 | MAE Test Loss: 0.4863181710243225 \n",
      "Epoch: 70 | MAE Train Loss: 0.30481624603271484 | MAE Test Loss: 0.48497089743614197 \n",
      "Epoch: 80 | MAE Train Loss: 0.30366405844688416 | MAE Test Loss: 0.483623743057251 \n",
      "Epoch: 90 | MAE Train Loss: 0.30251190066337585 | MAE Test Loss: 0.4822765290737152 \n",
      "Epoch: 100 | MAE Train Loss: 0.30135971307754517 | MAE Test Loss: 0.4809292256832123 \n",
      "Epoch: 110 | MAE Train Loss: 0.30020755529403687 | MAE Test Loss: 0.4795820713043213 \n",
      "Epoch: 120 | MAE Train Loss: 0.29905542731285095 | MAE Test Loss: 0.4782348573207855 \n",
      "Epoch: 130 | MAE Train Loss: 0.29790323972702026 | MAE Test Loss: 0.47688764333724976 \n",
      "Epoch: 140 | MAE Train Loss: 0.29675108194351196 | MAE Test Loss: 0.4755404591560364 \n",
      "Epoch: 150 | MAE Train Loss: 0.29559892416000366 | MAE Test Loss: 0.47419318556785583 \n",
      "Epoch: 160 | MAE Train Loss: 0.29444676637649536 | MAE Test Loss: 0.47284597158432007 \n",
      "Epoch: 170 | MAE Train Loss: 0.29329460859298706 | MAE Test Loss: 0.4714987874031067 \n",
      "Epoch: 180 | MAE Train Loss: 0.29214248061180115 | MAE Test Loss: 0.4701515734195709 \n",
      "Epoch: 190 | MAE Train Loss: 0.29099029302597046 | MAE Test Loss: 0.4688042998313904 \n",
      "Epoch: 200 | MAE Train Loss: 0.28983813524246216 | MAE Test Loss: 0.467457115650177 \n",
      "Epoch: 210 | MAE Train Loss: 0.28868597745895386 | MAE Test Loss: 0.46610990166664124 \n",
      "Epoch: 220 | MAE Train Loss: 0.28753381967544556 | MAE Test Loss: 0.46476268768310547 \n",
      "Epoch: 230 | MAE Train Loss: 0.28638166189193726 | MAE Test Loss: 0.4634154438972473 \n",
      "Epoch: 240 | MAE Train Loss: 0.28522950410842896 | MAE Test Loss: 0.46206825971603394 \n",
      "Epoch: 250 | MAE Train Loss: 0.28407734632492065 | MAE Test Loss: 0.4607210159301758 \n",
      "Epoch: 260 | MAE Train Loss: 0.28292518854141235 | MAE Test Loss: 0.4593738615512848 \n",
      "Epoch: 270 | MAE Train Loss: 0.28177303075790405 | MAE Test Loss: 0.45802658796310425 \n",
      "Epoch: 280 | MAE Train Loss: 0.28062087297439575 | MAE Test Loss: 0.4566793441772461 \n",
      "Epoch: 290 | MAE Train Loss: 0.27946868538856506 | MAE Test Loss: 0.4553321897983551 \n",
      "Epoch: 300 | MAE Train Loss: 0.27831655740737915 | MAE Test Loss: 0.45398491621017456 \n",
      "Epoch: 310 | MAE Train Loss: 0.27716436982154846 | MAE Test Loss: 0.45263776183128357 \n",
      "Epoch: 320 | MAE Train Loss: 0.2760121822357178 | MAE Test Loss: 0.4512905180454254 \n",
      "Epoch: 330 | MAE Train Loss: 0.27486005425453186 | MAE Test Loss: 0.44994330406188965 \n",
      "Epoch: 340 | MAE Train Loss: 0.27370789647102356 | MAE Test Loss: 0.4485960900783539 \n",
      "Epoch: 350 | MAE Train Loss: 0.27255573868751526 | MAE Test Loss: 0.4472488760948181 \n",
      "Epoch: 360 | MAE Train Loss: 0.27140355110168457 | MAE Test Loss: 0.44590163230895996 \n",
      "Epoch: 370 | MAE Train Loss: 0.27025142312049866 | MAE Test Loss: 0.4445544183254242 \n",
      "Epoch: 380 | MAE Train Loss: 0.26909923553466797 | MAE Test Loss: 0.4432072043418884 \n",
      "Epoch: 390 | MAE Train Loss: 0.26794707775115967 | MAE Test Loss: 0.44186002016067505 \n",
      "Epoch: 400 | MAE Train Loss: 0.26679491996765137 | MAE Test Loss: 0.4405128061771393 \n",
      "Epoch: 410 | MAE Train Loss: 0.26564276218414307 | MAE Test Loss: 0.43916553258895874 \n",
      "Epoch: 420 | MAE Train Loss: 0.26449060440063477 | MAE Test Loss: 0.43781834840774536 \n",
      "Epoch: 430 | MAE Train Loss: 0.26333844661712646 | MAE Test Loss: 0.4364711344242096 \n",
      "Epoch: 440 | MAE Train Loss: 0.26218628883361816 | MAE Test Loss: 0.43512392044067383 \n",
      "Epoch: 450 | MAE Train Loss: 0.2610341012477875 | MAE Test Loss: 0.4337766766548157 \n",
      "Epoch: 460 | MAE Train Loss: 0.2598819434642792 | MAE Test Loss: 0.4324294924736023 \n",
      "Epoch: 470 | MAE Train Loss: 0.2587297856807709 | MAE Test Loss: 0.43108224868774414 \n",
      "Epoch: 480 | MAE Train Loss: 0.2575775980949402 | MAE Test Loss: 0.4297350347042084 \n",
      "Epoch: 490 | MAE Train Loss: 0.2564254701137543 | MAE Test Loss: 0.4283878207206726 \n",
      "Epoch: 500 | MAE Train Loss: 0.2552732825279236 | MAE Test Loss: 0.42704063653945923 \n",
      "Epoch: 510 | MAE Train Loss: 0.25412115454673767 | MAE Test Loss: 0.4256933629512787 \n",
      "Epoch: 520 | MAE Train Loss: 0.252968966960907 | MAE Test Loss: 0.4243461489677429 \n",
      "Epoch: 530 | MAE Train Loss: 0.25181683897972107 | MAE Test Loss: 0.42299899458885193 \n",
      "Epoch: 540 | MAE Train Loss: 0.2506646513938904 | MAE Test Loss: 0.4216517508029938 \n",
      "Epoch: 550 | MAE Train Loss: 0.24951250851154327 | MAE Test Loss: 0.420304536819458 \n",
      "Epoch: 560 | MAE Train Loss: 0.24836035072803497 | MAE Test Loss: 0.41895729303359985 \n",
      "Epoch: 570 | MAE Train Loss: 0.24720819294452667 | MAE Test Loss: 0.4176101088523865 \n",
      "Epoch: 580 | MAE Train Loss: 0.24605603516101837 | MAE Test Loss: 0.4162628650665283 \n",
      "Epoch: 590 | MAE Train Loss: 0.24490387737751007 | MAE Test Loss: 0.41491565108299255 \n",
      "Epoch: 600 | MAE Train Loss: 0.24375171959400177 | MAE Test Loss: 0.4135684370994568 \n",
      "Epoch: 610 | MAE Train Loss: 0.24259953200817108 | MAE Test Loss: 0.41222119331359863 \n",
      "Epoch: 620 | MAE Train Loss: 0.24144737422466278 | MAE Test Loss: 0.41087397933006287 \n",
      "Epoch: 630 | MAE Train Loss: 0.24029521644115448 | MAE Test Loss: 0.4095267653465271 \n",
      "Epoch: 640 | MAE Train Loss: 0.23914304375648499 | MAE Test Loss: 0.4081795811653137 \n",
      "Epoch: 650 | MAE Train Loss: 0.23799090087413788 | MAE Test Loss: 0.40683236718177795 \n",
      "Epoch: 660 | MAE Train Loss: 0.23683874309062958 | MAE Test Loss: 0.4054851531982422 \n",
      "Epoch: 670 | MAE Train Loss: 0.23568658530712128 | MAE Test Loss: 0.4041379392147064 \n",
      "Epoch: 680 | MAE Train Loss: 0.23453441262245178 | MAE Test Loss: 0.40279069542884827 \n",
      "Epoch: 690 | MAE Train Loss: 0.23338226974010468 | MAE Test Loss: 0.4014434814453125 \n",
      "Epoch: 700 | MAE Train Loss: 0.23223009705543518 | MAE Test Loss: 0.40009626746177673 \n",
      "Epoch: 710 | MAE Train Loss: 0.23107793927192688 | MAE Test Loss: 0.39874905347824097 \n",
      "Epoch: 720 | MAE Train Loss: 0.22992578148841858 | MAE Test Loss: 0.3974018096923828 \n",
      "Epoch: 730 | MAE Train Loss: 0.22877362370491028 | MAE Test Loss: 0.39605459570884705 \n",
      "Epoch: 740 | MAE Train Loss: 0.2276214361190796 | MAE Test Loss: 0.3947073817253113 \n",
      "Epoch: 750 | MAE Train Loss: 0.2264692783355713 | MAE Test Loss: 0.3933602273464203 \n",
      "Epoch: 760 | MAE Train Loss: 0.225317120552063 | MAE Test Loss: 0.39201295375823975 \n",
      "Epoch: 770 | MAE Train Loss: 0.2241649627685547 | MAE Test Loss: 0.39066576957702637 \n",
      "Epoch: 780 | MAE Train Loss: 0.2230128049850464 | MAE Test Loss: 0.3893185257911682 \n",
      "Epoch: 790 | MAE Train Loss: 0.22186064720153809 | MAE Test Loss: 0.38797131180763245 \n",
      "Epoch: 800 | MAE Train Loss: 0.2207084596157074 | MAE Test Loss: 0.3866240978240967 \n",
      "Epoch: 810 | MAE Train Loss: 0.21955633163452148 | MAE Test Loss: 0.3852768540382385 \n",
      "Epoch: 820 | MAE Train Loss: 0.21840420365333557 | MAE Test Loss: 0.38392966985702515 \n",
      "Epoch: 830 | MAE Train Loss: 0.21725201606750488 | MAE Test Loss: 0.3825824558734894 \n",
      "Epoch: 840 | MAE Train Loss: 0.2160998284816742 | MAE Test Loss: 0.3812352120876312 \n",
      "Epoch: 850 | MAE Train Loss: 0.21494770050048828 | MAE Test Loss: 0.37988802790641785 \n",
      "Epoch: 860 | MAE Train Loss: 0.2137955129146576 | MAE Test Loss: 0.3785407841205597 \n",
      "Epoch: 870 | MAE Train Loss: 0.2126433551311493 | MAE Test Loss: 0.3771935999393463 \n",
      "Epoch: 880 | MAE Train Loss: 0.211491197347641 | MAE Test Loss: 0.37584635615348816 \n",
      "Epoch: 890 | MAE Train Loss: 0.2103390395641327 | MAE Test Loss: 0.37449911236763 \n",
      "Epoch: 900 | MAE Train Loss: 0.2091868668794632 | MAE Test Loss: 0.373151957988739 \n",
      "Epoch: 910 | MAE Train Loss: 0.2080347239971161 | MAE Test Loss: 0.37180468440055847 \n",
      "Epoch: 920 | MAE Train Loss: 0.2068825662136078 | MAE Test Loss: 0.3704574704170227 \n",
      "Epoch: 930 | MAE Train Loss: 0.2057303935289383 | MAE Test Loss: 0.3691102862358093 \n",
      "Epoch: 940 | MAE Train Loss: 0.20457823574543 | MAE Test Loss: 0.36776304244995117 \n",
      "Epoch: 950 | MAE Train Loss: 0.2034260779619217 | MAE Test Loss: 0.3664158582687378 \n",
      "Epoch: 960 | MAE Train Loss: 0.20227393507957458 | MAE Test Loss: 0.3650686740875244 \n",
      "Epoch: 970 | MAE Train Loss: 0.2011217623949051 | MAE Test Loss: 0.36372143030166626 \n",
      "Epoch: 980 | MAE Train Loss: 0.1999696046113968 | MAE Test Loss: 0.3623741865158081 \n",
      "Epoch: 990 | MAE Train Loss: 0.1988174170255661 | MAE Test Loss: 0.36102694272994995 \n",
      "Epoch: 1000 | MAE Train Loss: 0.1976652592420578 | MAE Test Loss: 0.3596797585487366 \n",
      "Epoch: 1010 | MAE Train Loss: 0.1965131163597107 | MAE Test Loss: 0.3583325445652008 \n",
      "Epoch: 1020 | MAE Train Loss: 0.1953609734773636 | MAE Test Loss: 0.35698533058166504 \n",
      "Epoch: 1030 | MAE Train Loss: 0.1942088007926941 | MAE Test Loss: 0.3556380867958069 \n",
      "Epoch: 1040 | MAE Train Loss: 0.1930566281080246 | MAE Test Loss: 0.3542909026145935 \n",
      "Epoch: 1050 | MAE Train Loss: 0.1919044703245163 | MAE Test Loss: 0.35294368863105774 \n",
      "Epoch: 1060 | MAE Train Loss: 0.1907522976398468 | MAE Test Loss: 0.351596474647522 \n",
      "Epoch: 1070 | MAE Train Loss: 0.1896001547574997 | MAE Test Loss: 0.3502492308616638 \n",
      "Epoch: 1080 | MAE Train Loss: 0.1884479969739914 | MAE Test Loss: 0.34890201687812805 \n",
      "Epoch: 1090 | MAE Train Loss: 0.1872958242893219 | MAE Test Loss: 0.3475547730922699 \n",
      "Epoch: 1100 | MAE Train Loss: 0.1861436665058136 | MAE Test Loss: 0.34620755910873413 \n",
      "Epoch: 1110 | MAE Train Loss: 0.1849915087223053 | MAE Test Loss: 0.34486037492752075 \n",
      "Epoch: 1120 | MAE Train Loss: 0.183839350938797 | MAE Test Loss: 0.3435131311416626 \n",
      "Epoch: 1130 | MAE Train Loss: 0.1826871931552887 | MAE Test Loss: 0.3421659469604492 \n",
      "Epoch: 1140 | MAE Train Loss: 0.1815350204706192 | MAE Test Loss: 0.34081873297691345 \n",
      "Epoch: 1150 | MAE Train Loss: 0.1803828626871109 | MAE Test Loss: 0.3394715189933777 \n",
      "Epoch: 1160 | MAE Train Loss: 0.1792306900024414 | MAE Test Loss: 0.3381243348121643 \n",
      "Epoch: 1170 | MAE Train Loss: 0.1780785471200943 | MAE Test Loss: 0.33677709102630615 \n",
      "Epoch: 1180 | MAE Train Loss: 0.176926389336586 | MAE Test Loss: 0.335429847240448 \n",
      "Epoch: 1190 | MAE Train Loss: 0.1757742166519165 | MAE Test Loss: 0.33408263325691223 \n",
      "Epoch: 1200 | MAE Train Loss: 0.174622043967247 | MAE Test Loss: 0.33273541927337646 \n",
      "Epoch: 1210 | MAE Train Loss: 0.1734698861837387 | MAE Test Loss: 0.3313881754875183 \n",
      "Epoch: 1220 | MAE Train Loss: 0.17231786251068115 | MAE Test Loss: 0.3300411105155945 \n",
      "Epoch: 1230 | MAE Train Loss: 0.1711658537387848 | MAE Test Loss: 0.32869404554367065 \n",
      "Epoch: 1240 | MAE Train Loss: 0.17001384496688843 | MAE Test Loss: 0.3273469805717468 \n",
      "Epoch: 1250 | MAE Train Loss: 0.16886183619499207 | MAE Test Loss: 0.3259999454021454 \n",
      "Epoch: 1260 | MAE Train Loss: 0.1677098125219345 | MAE Test Loss: 0.32465288043022156 \n",
      "Epoch: 1270 | MAE Train Loss: 0.16655781865119934 | MAE Test Loss: 0.32330575585365295 \n",
      "Epoch: 1280 | MAE Train Loss: 0.16540579497814178 | MAE Test Loss: 0.3219586908817291 \n",
      "Epoch: 1290 | MAE Train Loss: 0.16425378620624542 | MAE Test Loss: 0.3206116557121277 \n",
      "Epoch: 1300 | MAE Train Loss: 0.16310177743434906 | MAE Test Loss: 0.31926456093788147 \n",
      "Epoch: 1310 | MAE Train Loss: 0.1619497537612915 | MAE Test Loss: 0.31791752576828003 \n",
      "Epoch: 1320 | MAE Train Loss: 0.16079774498939514 | MAE Test Loss: 0.3165704607963562 \n",
      "Epoch: 1330 | MAE Train Loss: 0.15964575111865997 | MAE Test Loss: 0.3152233958244324 \n",
      "Epoch: 1340 | MAE Train Loss: 0.15849372744560242 | MAE Test Loss: 0.31387633085250854 \n",
      "Epoch: 1350 | MAE Train Loss: 0.15734171867370605 | MAE Test Loss: 0.3125292658805847 \n",
      "Epoch: 1360 | MAE Train Loss: 0.1561896950006485 | MAE Test Loss: 0.3111822009086609 \n",
      "Epoch: 1370 | MAE Train Loss: 0.15503768622875214 | MAE Test Loss: 0.30983513593673706 \n",
      "Epoch: 1380 | MAE Train Loss: 0.15388567745685577 | MAE Test Loss: 0.30848804116249084 \n",
      "Epoch: 1390 | MAE Train Loss: 0.1527336686849594 | MAE Test Loss: 0.307140976190567 \n",
      "Epoch: 1400 | MAE Train Loss: 0.15158167481422424 | MAE Test Loss: 0.3057939112186432 \n",
      "Epoch: 1410 | MAE Train Loss: 0.1504296511411667 | MAE Test Loss: 0.304446816444397 \n",
      "Epoch: 1420 | MAE Train Loss: 0.14927762746810913 | MAE Test Loss: 0.30309978127479553 \n",
      "Epoch: 1430 | MAE Train Loss: 0.14812563359737396 | MAE Test Loss: 0.3017526865005493 \n",
      "Epoch: 1440 | MAE Train Loss: 0.1469736099243164 | MAE Test Loss: 0.3004056215286255 \n",
      "Epoch: 1450 | MAE Train Loss: 0.14582160115242004 | MAE Test Loss: 0.29905855655670166 \n",
      "Epoch: 1460 | MAE Train Loss: 0.14466959238052368 | MAE Test Loss: 0.29771149158477783 \n",
      "Epoch: 1470 | MAE Train Loss: 0.14351758360862732 | MAE Test Loss: 0.2963644564151764 \n",
      "Epoch: 1480 | MAE Train Loss: 0.14236557483673096 | MAE Test Loss: 0.29501739144325256 \n",
      "Epoch: 1490 | MAE Train Loss: 0.1412135511636734 | MAE Test Loss: 0.29367026686668396 \n",
      "Epoch: 1500 | MAE Train Loss: 0.14006154239177704 | MAE Test Loss: 0.2923232614994049 \n",
      "Epoch: 1510 | MAE Train Loss: 0.13890953361988068 | MAE Test Loss: 0.2909761369228363 \n",
      "Epoch: 1520 | MAE Train Loss: 0.13775750994682312 | MAE Test Loss: 0.2896290719509125 \n",
      "Epoch: 1530 | MAE Train Loss: 0.13660551607608795 | MAE Test Loss: 0.28828200697898865 \n",
      "Epoch: 1540 | MAE Train Loss: 0.1354534924030304 | MAE Test Loss: 0.2869349718093872 \n",
      "Epoch: 1550 | MAE Train Loss: 0.13430148363113403 | MAE Test Loss: 0.2855879068374634 \n",
      "Epoch: 1560 | MAE Train Loss: 0.13314947485923767 | MAE Test Loss: 0.28424081206321716 \n",
      "Epoch: 1570 | MAE Train Loss: 0.13199745118618011 | MAE Test Loss: 0.2828937768936157 \n",
      "Epoch: 1580 | MAE Train Loss: 0.13084545731544495 | MAE Test Loss: 0.2815466523170471 \n",
      "Epoch: 1590 | MAE Train Loss: 0.1296934336423874 | MAE Test Loss: 0.2801996171474457 \n",
      "Epoch: 1600 | MAE Train Loss: 0.12854143977165222 | MAE Test Loss: 0.27885255217552185 \n",
      "Epoch: 1610 | MAE Train Loss: 0.12738941609859467 | MAE Test Loss: 0.27750545740127563 \n",
      "Epoch: 1620 | MAE Train Loss: 0.1262374073266983 | MAE Test Loss: 0.2761583924293518 \n",
      "Epoch: 1630 | MAE Train Loss: 0.12508539855480194 | MAE Test Loss: 0.274811327457428 \n",
      "Epoch: 1640 | MAE Train Loss: 0.12393335998058319 | MAE Test Loss: 0.27346426248550415 \n",
      "Epoch: 1650 | MAE Train Loss: 0.12278135865926743 | MAE Test Loss: 0.2721172273159027 \n",
      "Epoch: 1660 | MAE Train Loss: 0.12162934243679047 | MAE Test Loss: 0.2707701623439789 \n",
      "Epoch: 1670 | MAE Train Loss: 0.1204773411154747 | MAE Test Loss: 0.2694230377674103 \n",
      "Epoch: 1680 | MAE Train Loss: 0.11932532489299774 | MAE Test Loss: 0.26807600259780884 \n",
      "Epoch: 1690 | MAE Train Loss: 0.11817331612110138 | MAE Test Loss: 0.2667289078235626 \n",
      "Epoch: 1700 | MAE Train Loss: 0.11702130734920502 | MAE Test Loss: 0.2653818726539612 \n",
      "Epoch: 1710 | MAE Train Loss: 0.11586929857730865 | MAE Test Loss: 0.26403480768203735 \n",
      "Epoch: 1720 | MAE Train Loss: 0.11479532718658447 | MAE Test Loss: 0.26273253560066223 \n",
      "Epoch: 1730 | MAE Train Loss: 0.11374060064554214 | MAE Test Loss: 0.26143524050712585 \n",
      "Epoch: 1740 | MAE Train Loss: 0.11268587410449982 | MAE Test Loss: 0.2601379454135895 \n",
      "Epoch: 1750 | MAE Train Loss: 0.1116311326622963 | MAE Test Loss: 0.2588406205177307 \n",
      "Epoch: 1760 | MAE Train Loss: 0.11057639122009277 | MAE Test Loss: 0.25754329562187195 \n",
      "Epoch: 1770 | MAE Train Loss: 0.10952164977788925 | MAE Test Loss: 0.25624600052833557 \n",
      "Epoch: 1780 | MAE Train Loss: 0.1085236445069313 | MAE Test Loss: 0.2549845278263092 \n",
      "Epoch: 1790 | MAE Train Loss: 0.10756231844425201 | MAE Test Loss: 0.2537383735179901 \n",
      "Epoch: 1800 | MAE Train Loss: 0.10660099983215332 | MAE Test Loss: 0.25249215960502625 \n",
      "Epoch: 1810 | MAE Train Loss: 0.10563969612121582 | MAE Test Loss: 0.25124603509902954 \n",
      "Epoch: 1820 | MAE Train Loss: 0.10467837005853653 | MAE Test Loss: 0.24999985098838806 \n",
      "Epoch: 1830 | MAE Train Loss: 0.10371705144643784 | MAE Test Loss: 0.24875369668006897 \n",
      "Epoch: 1840 | MAE Train Loss: 0.10276877880096436 | MAE Test Loss: 0.24751785397529602 \n",
      "Epoch: 1850 | MAE Train Loss: 0.10189647972583771 | MAE Test Loss: 0.24632331728935242 \n",
      "Epoch: 1860 | MAE Train Loss: 0.10102419555187225 | MAE Test Loss: 0.2451288253068924 \n",
      "Epoch: 1870 | MAE Train Loss: 0.1001519113779068 | MAE Test Loss: 0.24393431842327118 \n",
      "Epoch: 1880 | MAE Train Loss: 0.09927962720394135 | MAE Test Loss: 0.2427397519350052 \n",
      "Epoch: 1890 | MAE Train Loss: 0.0984073281288147 | MAE Test Loss: 0.24154527485370636 \n",
      "Epoch: 1900 | MAE Train Loss: 0.09753505140542984 | MAE Test Loss: 0.24035079777240753 \n",
      "Epoch: 1910 | MAE Train Loss: 0.09670595079660416 | MAE Test Loss: 0.2391880750656128 \n",
      "Epoch: 1920 | MAE Train Loss: 0.09591863304376602 | MAE Test Loss: 0.2380465269088745 \n",
      "Epoch: 1930 | MAE Train Loss: 0.09513132274150848 | MAE Test Loss: 0.23690500855445862 \n",
      "Epoch: 1940 | MAE Train Loss: 0.09434400498867035 | MAE Test Loss: 0.23576350510120392 \n",
      "Epoch: 1950 | MAE Train Loss: 0.09355668723583221 | MAE Test Loss: 0.23462197184562683 \n",
      "Epoch: 1960 | MAE Train Loss: 0.09276936948299408 | MAE Test Loss: 0.23348042368888855 \n",
      "Epoch: 1970 | MAE Train Loss: 0.09198205173015594 | MAE Test Loss: 0.23233893513679504 \n",
      "Epoch: 1980 | MAE Train Loss: 0.09123730659484863 | MAE Test Loss: 0.23122933506965637 \n",
      "Epoch: 1990 | MAE Train Loss: 0.09053032100200653 | MAE Test Loss: 0.23014101386070251 \n",
      "Epoch: 2000 | MAE Train Loss: 0.08982332795858383 | MAE Test Loss: 0.22905269265174866 \n",
      "Epoch: 2010 | MAE Train Loss: 0.08911634981632233 | MAE Test Loss: 0.22796443104743958 \n",
      "Epoch: 2020 | MAE Train Loss: 0.08840936422348022 | MAE Test Loss: 0.22687609493732452 \n",
      "Epoch: 2030 | MAE Train Loss: 0.08770237863063812 | MAE Test Loss: 0.22578778862953186 \n",
      "Epoch: 2040 | MAE Train Loss: 0.08699538558721542 | MAE Test Loss: 0.2246994972229004 \n",
      "Epoch: 2050 | MAE Train Loss: 0.08630740642547607 | MAE Test Loss: 0.22362756729125977 \n",
      "Epoch: 2060 | MAE Train Loss: 0.08567677438259125 | MAE Test Loss: 0.22259381413459778 \n",
      "Epoch: 2070 | MAE Train Loss: 0.08504614233970642 | MAE Test Loss: 0.22156009078025818 \n",
      "Epoch: 2080 | MAE Train Loss: 0.0844155102968216 | MAE Test Loss: 0.22052636742591858 \n",
      "Epoch: 2090 | MAE Train Loss: 0.08378488570451736 | MAE Test Loss: 0.21949262917041779 \n",
      "Epoch: 2100 | MAE Train Loss: 0.08315424621105194 | MAE Test Loss: 0.21845892071723938 \n",
      "Epoch: 2110 | MAE Train Loss: 0.08252362161874771 | MAE Test Loss: 0.2174251526594162 \n",
      "Epoch: 2120 | MAE Train Loss: 0.08189298212528229 | MAE Test Loss: 0.2163914442062378 \n",
      "Epoch: 2130 | MAE Train Loss: 0.08130882680416107 | MAE Test Loss: 0.2153964787721634 \n",
      "Epoch: 2140 | MAE Train Loss: 0.08075019717216492 | MAE Test Loss: 0.21441809833049774 \n",
      "Epoch: 2150 | MAE Train Loss: 0.08019156754016876 | MAE Test Loss: 0.21343974769115448 \n",
      "Epoch: 2160 | MAE Train Loss: 0.07963293045759201 | MAE Test Loss: 0.21246139705181122 \n",
      "Epoch: 2170 | MAE Train Loss: 0.07907428592443466 | MAE Test Loss: 0.21148303151130676 \n",
      "Epoch: 2180 | MAE Train Loss: 0.07851565629243851 | MAE Test Loss: 0.2105046808719635 \n",
      "Epoch: 2190 | MAE Train Loss: 0.07795701920986176 | MAE Test Loss: 0.20952634513378143 \n",
      "Epoch: 2200 | MAE Train Loss: 0.077398382127285 | MAE Test Loss: 0.20854797959327698 \n",
      "Epoch: 2210 | MAE Train Loss: 0.07688353955745697 | MAE Test Loss: 0.20760893821716309 \n",
      "Epoch: 2220 | MAE Train Loss: 0.07639250159263611 | MAE Test Loss: 0.20668676495552063 \n",
      "Epoch: 2230 | MAE Train Loss: 0.07590147852897644 | MAE Test Loss: 0.2057645618915558 \n",
      "Epoch: 2240 | MAE Train Loss: 0.07541044056415558 | MAE Test Loss: 0.20484237372875214 \n",
      "Epoch: 2250 | MAE Train Loss: 0.07491941750049591 | MAE Test Loss: 0.2039201706647873 \n",
      "Epoch: 2260 | MAE Train Loss: 0.07442837953567505 | MAE Test Loss: 0.20299801230430603 \n",
      "Epoch: 2270 | MAE Train Loss: 0.07393734157085419 | MAE Test Loss: 0.2020758092403412 \n",
      "Epoch: 2280 | MAE Train Loss: 0.07344631105661392 | MAE Test Loss: 0.20115363597869873 \n",
      "Epoch: 2290 | MAE Train Loss: 0.0729697197675705 | MAE Test Loss: 0.2002486288547516 \n",
      "Epoch: 2300 | MAE Train Loss: 0.0725419670343399 | MAE Test Loss: 0.19938364624977112 \n",
      "Epoch: 2310 | MAE Train Loss: 0.07211421430110931 | MAE Test Loss: 0.19851867854595184 \n",
      "Epoch: 2320 | MAE Train Loss: 0.07168644666671753 | MAE Test Loss: 0.19765372574329376 \n",
      "Epoch: 2330 | MAE Train Loss: 0.07125870883464813 | MAE Test Loss: 0.19678878784179688 \n",
      "Epoch: 2340 | MAE Train Loss: 0.07083095610141754 | MAE Test Loss: 0.1959238052368164 \n",
      "Epoch: 2350 | MAE Train Loss: 0.07040319591760635 | MAE Test Loss: 0.19505885243415833 \n",
      "Epoch: 2360 | MAE Train Loss: 0.06997544318437576 | MAE Test Loss: 0.19419388473033905 \n",
      "Epoch: 2370 | MAE Train Loss: 0.06954768300056458 | MAE Test Loss: 0.19332894682884216 \n",
      "Epoch: 2380 | MAE Train Loss: 0.06913762539625168 | MAE Test Loss: 0.19248707592487335 \n",
      "Epoch: 2390 | MAE Train Loss: 0.06876852363348007 | MAE Test Loss: 0.19167983531951904 \n",
      "Epoch: 2400 | MAE Train Loss: 0.06839941442012787 | MAE Test Loss: 0.19087259471416473 \n",
      "Epoch: 2410 | MAE Train Loss: 0.06803031265735626 | MAE Test Loss: 0.19006536900997162 \n",
      "Epoch: 2420 | MAE Train Loss: 0.06766121089458466 | MAE Test Loss: 0.1892581284046173 \n",
      "Epoch: 2430 | MAE Train Loss: 0.06729210913181305 | MAE Test Loss: 0.1884509027004242 \n",
      "Epoch: 2440 | MAE Train Loss: 0.06692300736904144 | MAE Test Loss: 0.18764367699623108 \n",
      "Epoch: 2450 | MAE Train Loss: 0.06655389070510864 | MAE Test Loss: 0.18683645129203796 \n",
      "Epoch: 2460 | MAE Train Loss: 0.06618479639291763 | MAE Test Loss: 0.18602922558784485 \n",
      "Epoch: 2470 | MAE Train Loss: 0.06581568717956543 | MAE Test Loss: 0.18522198498249054 \n",
      "Epoch: 2480 | MAE Train Loss: 0.0654863566160202 | MAE Test Loss: 0.1844620257616043 \n",
      "Epoch: 2490 | MAE Train Loss: 0.06517163664102554 | MAE Test Loss: 0.1837138831615448 \n",
      "Epoch: 2500 | MAE Train Loss: 0.06485690176486969 | MAE Test Loss: 0.1829657256603241 \n",
      "Epoch: 2510 | MAE Train Loss: 0.06454218924045563 | MAE Test Loss: 0.18221759796142578 \n",
      "Epoch: 2520 | MAE Train Loss: 0.06422744691371918 | MAE Test Loss: 0.18146945536136627 \n",
      "Epoch: 2530 | MAE Train Loss: 0.06391273438930511 | MAE Test Loss: 0.18072131276130676 \n",
      "Epoch: 2540 | MAE Train Loss: 0.06359801441431046 | MAE Test Loss: 0.17997315526008606 \n",
      "Epoch: 2550 | MAE Train Loss: 0.0632832795381546 | MAE Test Loss: 0.17922499775886536 \n",
      "Epoch: 2560 | MAE Train Loss: 0.06296855956315994 | MAE Test Loss: 0.17847685515880585 \n",
      "Epoch: 2570 | MAE Train Loss: 0.06265383213758469 | MAE Test Loss: 0.17772871255874634 \n",
      "Epoch: 2580 | MAE Train Loss: 0.062364548444747925 | MAE Test Loss: 0.1770164966583252 \n",
      "Epoch: 2590 | MAE Train Loss: 0.06209961324930191 | MAE Test Loss: 0.17632822692394257 \n",
      "Epoch: 2600 | MAE Train Loss: 0.0618346631526947 | MAE Test Loss: 0.17563997209072113 \n",
      "Epoch: 2610 | MAE Train Loss: 0.061569731682538986 | MAE Test Loss: 0.1749517023563385 \n",
      "Epoch: 2620 | MAE Train Loss: 0.06130479648709297 | MAE Test Loss: 0.17426344752311707 \n",
      "Epoch: 2630 | MAE Train Loss: 0.061039846390485764 | MAE Test Loss: 0.17357519268989563 \n",
      "Epoch: 2640 | MAE Train Loss: 0.06077491492033005 | MAE Test Loss: 0.1728869378566742 \n",
      "Epoch: 2650 | MAE Train Loss: 0.060509972274303436 | MAE Test Loss: 0.17219865322113037 \n",
      "Epoch: 2660 | MAE Train Loss: 0.06024503707885742 | MAE Test Loss: 0.17151038348674774 \n",
      "Epoch: 2670 | MAE Train Loss: 0.05998010188341141 | MAE Test Loss: 0.1708221435546875 \n",
      "Epoch: 2680 | MAE Train Loss: 0.0597151517868042 | MAE Test Loss: 0.17013385891914368 \n",
      "Epoch: 2690 | MAE Train Loss: 0.05946909636259079 | MAE Test Loss: 0.16947592794895172 \n",
      "Epoch: 2700 | MAE Train Loss: 0.05924928933382034 | MAE Test Loss: 0.16884835064411163 \n",
      "Epoch: 2710 | MAE Train Loss: 0.059029471129179 | MAE Test Loss: 0.16822075843811035 \n",
      "Epoch: 2720 | MAE Train Loss: 0.05880966782569885 | MAE Test Loss: 0.16759316623210907 \n",
      "Epoch: 2730 | MAE Train Loss: 0.05858985707163811 | MAE Test Loss: 0.16696560382843018 \n",
      "Epoch: 2740 | MAE Train Loss: 0.05837004631757736 | MAE Test Loss: 0.1663379967212677 \n",
      "Epoch: 2750 | MAE Train Loss: 0.05815023183822632 | MAE Test Loss: 0.1657104194164276 \n",
      "Epoch: 2760 | MAE Train Loss: 0.05793040990829468 | MAE Test Loss: 0.16508284211158752 \n",
      "Epoch: 2770 | MAE Train Loss: 0.05771061033010483 | MAE Test Loss: 0.16445522010326385 \n",
      "Epoch: 2780 | MAE Train Loss: 0.05749080330133438 | MAE Test Loss: 0.16382765769958496 \n",
      "Epoch: 2790 | MAE Train Loss: 0.057270992547273636 | MAE Test Loss: 0.16320006549358368 \n",
      "Epoch: 2800 | MAE Train Loss: 0.057051174342632294 | MAE Test Loss: 0.1625724881887436 \n",
      "Epoch: 2810 | MAE Train Loss: 0.0568438284099102 | MAE Test Loss: 0.16196948289871216 \n",
      "Epoch: 2820 | MAE Train Loss: 0.056664418429136276 | MAE Test Loss: 0.1614033430814743 \n",
      "Epoch: 2830 | MAE Train Loss: 0.05648501589894295 | MAE Test Loss: 0.16083717346191406 \n",
      "Epoch: 2840 | MAE Train Loss: 0.05630560591816902 | MAE Test Loss: 0.1602710485458374 \n",
      "Epoch: 2850 | MAE Train Loss: 0.0561261884868145 | MAE Test Loss: 0.15970489382743835 \n",
      "Epoch: 2860 | MAE Train Loss: 0.05594678595662117 | MAE Test Loss: 0.1591387540102005 \n",
      "Epoch: 2870 | MAE Train Loss: 0.05576737970113754 | MAE Test Loss: 0.15857258439064026 \n",
      "Epoch: 2880 | MAE Train Loss: 0.05558796972036362 | MAE Test Loss: 0.1580064594745636 \n",
      "Epoch: 2890 | MAE Train Loss: 0.05540855973958969 | MAE Test Loss: 0.15744030475616455 \n",
      "Epoch: 2900 | MAE Train Loss: 0.055229149758815765 | MAE Test Loss: 0.1568741500377655 \n",
      "Epoch: 2910 | MAE Train Loss: 0.05504973977804184 | MAE Test Loss: 0.15630802512168884 \n",
      "Epoch: 2920 | MAE Train Loss: 0.054870329797267914 | MAE Test Loss: 0.155741885304451 \n",
      "Epoch: 2930 | MAE Train Loss: 0.05469091981649399 | MAE Test Loss: 0.15517573058605194 \n",
      "Epoch: 2940 | MAE Train Loss: 0.05451151728630066 | MAE Test Loss: 0.1546095907688141 \n",
      "Epoch: 2950 | MAE Train Loss: 0.05436427518725395 | MAE Test Loss: 0.15410597622394562 \n",
      "Epoch: 2960 | MAE Train Loss: 0.05422055721282959 | MAE Test Loss: 0.15360236167907715 \n",
      "Epoch: 2970 | MAE Train Loss: 0.05407685041427612 | MAE Test Loss: 0.15309874713420868 \n",
      "Epoch: 2980 | MAE Train Loss: 0.05393313616514206 | MAE Test Loss: 0.1525951325893402 \n",
      "Epoch: 2990 | MAE Train Loss: 0.05378942936658859 | MAE Test Loss: 0.15209153294563293 \n",
      "Epoch: 3000 | MAE Train Loss: 0.05364571884274483 | MAE Test Loss: 0.15158791840076447 \n",
      "Epoch: 3010 | MAE Train Loss: 0.053502004593610764 | MAE Test Loss: 0.1510842889547348 \n",
      "Epoch: 3020 | MAE Train Loss: 0.053358305245637894 | MAE Test Loss: 0.15058067440986633 \n",
      "Epoch: 3030 | MAE Train Loss: 0.05321459099650383 | MAE Test Loss: 0.15007705986499786 \n",
      "Epoch: 3040 | MAE Train Loss: 0.05307087302207947 | MAE Test Loss: 0.14957347512245178 \n",
      "Epoch: 3050 | MAE Train Loss: 0.0529271736741066 | MAE Test Loss: 0.1490698605775833 \n",
      "Epoch: 3060 | MAE Train Loss: 0.052783459424972534 | MAE Test Loss: 0.14856624603271484 \n",
      "Epoch: 3070 | MAE Train Loss: 0.05263974517583847 | MAE Test Loss: 0.14806261658668518 \n",
      "Epoch: 3080 | MAE Train Loss: 0.052496038377285004 | MAE Test Loss: 0.1475590169429779 \n",
      "Epoch: 3090 | MAE Train Loss: 0.05235233157873154 | MAE Test Loss: 0.14705541729927063 \n",
      "Epoch: 3100 | MAE Train Loss: 0.05223175883293152 | MAE Test Loss: 0.14660246670246124 \n",
      "Epoch: 3110 | MAE Train Loss: 0.05211885645985603 | MAE Test Loss: 0.14616218209266663 \n",
      "Epoch: 3120 | MAE Train Loss: 0.052005965262651443 | MAE Test Loss: 0.14572188258171082 \n",
      "Epoch: 3130 | MAE Train Loss: 0.05189306288957596 | MAE Test Loss: 0.1452815979719162 \n",
      "Epoch: 3140 | MAE Train Loss: 0.05178016424179077 | MAE Test Loss: 0.14484134316444397 \n",
      "Epoch: 3150 | MAE Train Loss: 0.051667265594005585 | MAE Test Loss: 0.14440104365348816 \n",
      "Epoch: 3160 | MAE Train Loss: 0.051554370671510696 | MAE Test Loss: 0.14396075904369354 \n",
      "Epoch: 3170 | MAE Train Loss: 0.05144147202372551 | MAE Test Loss: 0.14352047443389893 \n",
      "Epoch: 3180 | MAE Train Loss: 0.05132858082652092 | MAE Test Loss: 0.1430802047252655 \n",
      "Epoch: 3190 | MAE Train Loss: 0.051215678453445435 | MAE Test Loss: 0.1426399201154709 \n",
      "Epoch: 3200 | MAE Train Loss: 0.051102787256240845 | MAE Test Loss: 0.14219963550567627 \n",
      "Epoch: 3210 | MAE Train Loss: 0.05098988488316536 | MAE Test Loss: 0.14175935089588165 \n",
      "Epoch: 3220 | MAE Train Loss: 0.05087698623538017 | MAE Test Loss: 0.14131906628608704 \n",
      "Epoch: 3230 | MAE Train Loss: 0.05076408386230469 | MAE Test Loss: 0.14087876677513123 \n",
      "Epoch: 3240 | MAE Train Loss: 0.0506511926651001 | MAE Test Loss: 0.140438511967659 \n",
      "Epoch: 3250 | MAE Train Loss: 0.05053829401731491 | MAE Test Loss: 0.13999824225902557 \n",
      "Epoch: 3260 | MAE Train Loss: 0.05042539909482002 | MAE Test Loss: 0.13955795764923096 \n",
      "Epoch: 3270 | MAE Train Loss: 0.050323016941547394 | MAE Test Loss: 0.13914987444877625 \n",
      "Epoch: 3280 | MAE Train Loss: 0.0502360537648201 | MAE Test Loss: 0.13877396285533905 \n",
      "Epoch: 3290 | MAE Train Loss: 0.050149060785770416 | MAE Test Loss: 0.13839808106422424 \n",
      "Epoch: 3300 | MAE Train Loss: 0.05006207898259163 | MAE Test Loss: 0.13802221417427063 \n",
      "Epoch: 3310 | MAE Train Loss: 0.04997509717941284 | MAE Test Loss: 0.13764628767967224 \n",
      "Epoch: 3320 | MAE Train Loss: 0.04988812282681465 | MAE Test Loss: 0.13727042078971863 \n",
      "Epoch: 3330 | MAE Train Loss: 0.04980113357305527 | MAE Test Loss: 0.13689450919628143 \n",
      "Epoch: 3340 | MAE Train Loss: 0.04971415922045708 | MAE Test Loss: 0.13651862740516663 \n",
      "Epoch: 3350 | MAE Train Loss: 0.04962717741727829 | MAE Test Loss: 0.13614273071289062 \n",
      "Epoch: 3360 | MAE Train Loss: 0.0495401993393898 | MAE Test Loss: 0.135766863822937 \n",
      "Epoch: 3370 | MAE Train Loss: 0.049453213810920715 | MAE Test Loss: 0.13539095222949982 \n",
      "Epoch: 3380 | MAE Train Loss: 0.04936624690890312 | MAE Test Loss: 0.13501505553722382 \n",
      "Epoch: 3390 | MAE Train Loss: 0.04927925392985344 | MAE Test Loss: 0.134639173746109 \n",
      "Epoch: 3400 | MAE Train Loss: 0.04919227212667465 | MAE Test Loss: 0.1342633068561554 \n",
      "Epoch: 3410 | MAE Train Loss: 0.04910529404878616 | MAE Test Loss: 0.133887380361557 \n",
      "Epoch: 3420 | MAE Train Loss: 0.049018315970897675 | MAE Test Loss: 0.1335115134716034 \n",
      "Epoch: 3430 | MAE Train Loss: 0.04893132671713829 | MAE Test Loss: 0.1331356018781662 \n",
      "Epoch: 3440 | MAE Train Loss: 0.0488443486392498 | MAE Test Loss: 0.1327597200870514 \n",
      "Epoch: 3450 | MAE Train Loss: 0.04875737428665161 | MAE Test Loss: 0.1323838233947754 \n",
      "Epoch: 3460 | MAE Train Loss: 0.048670392483472824 | MAE Test Loss: 0.13200794160366058 \n",
      "Epoch: 3470 | MAE Train Loss: 0.04858340695500374 | MAE Test Loss: 0.13163205981254578 \n",
      "Epoch: 3480 | MAE Train Loss: 0.04851120337843895 | MAE Test Loss: 0.13130804896354675 \n",
      "Epoch: 3490 | MAE Train Loss: 0.04844503849744797 | MAE Test Loss: 0.13099706172943115 \n",
      "Epoch: 3500 | MAE Train Loss: 0.04837886989116669 | MAE Test Loss: 0.13068607449531555 \n",
      "Epoch: 3510 | MAE Train Loss: 0.048312705010175705 | MAE Test Loss: 0.13037505745887756 \n",
      "Epoch: 3520 | MAE Train Loss: 0.04824654385447502 | MAE Test Loss: 0.13006405532360077 \n",
      "Epoch: 3530 | MAE Train Loss: 0.04818037897348404 | MAE Test Loss: 0.12975306808948517 \n",
      "Epoch: 3540 | MAE Train Loss: 0.04811421036720276 | MAE Test Loss: 0.12944205105304718 \n",
      "Epoch: 3550 | MAE Train Loss: 0.04804804176092148 | MAE Test Loss: 0.12913104891777039 \n",
      "Epoch: 3560 | MAE Train Loss: 0.047981880605220795 | MAE Test Loss: 0.1288200318813324 \n",
      "Epoch: 3570 | MAE Train Loss: 0.047915711998939514 | MAE Test Loss: 0.1285090446472168 \n",
      "Epoch: 3580 | MAE Train Loss: 0.047849543392658234 | MAE Test Loss: 0.1281980574131012 \n",
      "Epoch: 3590 | MAE Train Loss: 0.04778338223695755 | MAE Test Loss: 0.1278870403766632 \n",
      "Epoch: 3600 | MAE Train Loss: 0.047717221081256866 | MAE Test Loss: 0.1275760382413864 \n",
      "Epoch: 3610 | MAE Train Loss: 0.047651052474975586 | MAE Test Loss: 0.1272650510072708 \n",
      "Epoch: 3620 | MAE Train Loss: 0.04758488014340401 | MAE Test Loss: 0.12695403397083282 \n",
      "Epoch: 3630 | MAE Train Loss: 0.04751871898770332 | MAE Test Loss: 0.12664303183555603 \n",
      "Epoch: 3640 | MAE Train Loss: 0.04745255410671234 | MAE Test Loss: 0.12633201479911804 \n",
      "Epoch: 3650 | MAE Train Loss: 0.04738638550043106 | MAE Test Loss: 0.12602102756500244 \n",
      "Epoch: 3660 | MAE Train Loss: 0.04732022061944008 | MAE Test Loss: 0.12571004033088684 \n",
      "Epoch: 3670 | MAE Train Loss: 0.0472540557384491 | MAE Test Loss: 0.12539902329444885 \n",
      "Epoch: 3680 | MAE Train Loss: 0.04718789458274841 | MAE Test Loss: 0.12508802115917206 \n",
      "Epoch: 3690 | MAE Train Loss: 0.04712172597646713 | MAE Test Loss: 0.12477703392505646 \n",
      "Epoch: 3700 | MAE Train Loss: 0.047055553644895554 | MAE Test Loss: 0.12446601688861847 \n",
      "Epoch: 3710 | MAE Train Loss: 0.04698939248919487 | MAE Test Loss: 0.12415502220392227 \n",
      "Epoch: 3720 | MAE Train Loss: 0.04692322760820389 | MAE Test Loss: 0.12384400516748428 \n",
      "Epoch: 3730 | MAE Train Loss: 0.046857062727212906 | MAE Test Loss: 0.12353301048278809 \n",
      "Epoch: 3740 | MAE Train Loss: 0.04680521786212921 | MAE Test Loss: 0.12328799068927765 \n",
      "Epoch: 3750 | MAE Train Loss: 0.04675474762916565 | MAE Test Loss: 0.12304297834634781 \n",
      "Epoch: 3760 | MAE Train Loss: 0.04670426994562149 | MAE Test Loss: 0.12279794365167618 \n",
      "Epoch: 3770 | MAE Train Loss: 0.04665379226207733 | MAE Test Loss: 0.12255294620990753 \n",
      "Epoch: 3780 | MAE Train Loss: 0.04660331457853317 | MAE Test Loss: 0.1223079189658165 \n",
      "Epoch: 3790 | MAE Train Loss: 0.04655285179615021 | MAE Test Loss: 0.12206289917230606 \n",
      "Epoch: 3800 | MAE Train Loss: 0.04650237038731575 | MAE Test Loss: 0.12181787192821503 \n",
      "Epoch: 3810 | MAE Train Loss: 0.04645188897848129 | MAE Test Loss: 0.12157285213470459 \n",
      "Epoch: 3820 | MAE Train Loss: 0.04640141874551773 | MAE Test Loss: 0.12132783234119415 \n",
      "Epoch: 3830 | MAE Train Loss: 0.04635094851255417 | MAE Test Loss: 0.12108281999826431 \n",
      "Epoch: 3840 | MAE Train Loss: 0.04630047455430031 | MAE Test Loss: 0.12083778530359268 \n",
      "Epoch: 3850 | MAE Train Loss: 0.04624999314546585 | MAE Test Loss: 0.12059278786182404 \n",
      "Epoch: 3860 | MAE Train Loss: 0.04619951918721199 | MAE Test Loss: 0.120347760617733 \n",
      "Epoch: 3870 | MAE Train Loss: 0.04614905267953873 | MAE Test Loss: 0.12010274082422256 \n",
      "Epoch: 3880 | MAE Train Loss: 0.04609857127070427 | MAE Test Loss: 0.11985771358013153 \n",
      "Epoch: 3890 | MAE Train Loss: 0.04604809358716011 | MAE Test Loss: 0.1196126937866211 \n",
      "Epoch: 3900 | MAE Train Loss: 0.04599762335419655 | MAE Test Loss: 0.11936767399311066 \n",
      "Epoch: 3910 | MAE Train Loss: 0.045947153121232986 | MAE Test Loss: 0.11912266165018082 \n",
      "Epoch: 3920 | MAE Train Loss: 0.04589667543768883 | MAE Test Loss: 0.11887762695550919 \n",
      "Epoch: 3930 | MAE Train Loss: 0.04584619775414467 | MAE Test Loss: 0.11863262951374054 \n",
      "Epoch: 3940 | MAE Train Loss: 0.04579572007060051 | MAE Test Loss: 0.1183876022696495 \n",
      "Epoch: 3950 | MAE Train Loss: 0.045745257288217545 | MAE Test Loss: 0.11814258247613907 \n",
      "Epoch: 3960 | MAE Train Loss: 0.04569477587938309 | MAE Test Loss: 0.11789755523204803 \n",
      "Epoch: 3970 | MAE Train Loss: 0.04564429447054863 | MAE Test Loss: 0.1176525354385376 \n",
      "Epoch: 3980 | MAE Train Loss: 0.04559382423758507 | MAE Test Loss: 0.11740751564502716 \n",
      "Epoch: 3990 | MAE Train Loss: 0.045543354004621506 | MAE Test Loss: 0.11716250330209732 \n",
      "Epoch: 4000 | MAE Train Loss: 0.045492880046367645 | MAE Test Loss: 0.11691746860742569 \n",
      "Epoch: 4010 | MAE Train Loss: 0.04544239863753319 | MAE Test Loss: 0.11667247116565704 \n",
      "Epoch: 4020 | MAE Train Loss: 0.04539192467927933 | MAE Test Loss: 0.11642744392156601 \n",
      "Epoch: 4030 | MAE Train Loss: 0.045341458171606064 | MAE Test Loss: 0.11618242412805557 \n",
      "Epoch: 4040 | MAE Train Loss: 0.045290976762771606 | MAE Test Loss: 0.11593739688396454 \n",
      "Epoch: 4050 | MAE Train Loss: 0.04524049907922745 | MAE Test Loss: 0.1156923770904541 \n",
      "Epoch: 4060 | MAE Train Loss: 0.045190028846263885 | MAE Test Loss: 0.11544735729694366 \n",
      "Epoch: 4070 | MAE Train Loss: 0.045139558613300323 | MAE Test Loss: 0.11520234495401382 \n",
      "Epoch: 4080 | MAE Train Loss: 0.045089080929756165 | MAE Test Loss: 0.1149573102593422 \n",
      "Epoch: 4090 | MAE Train Loss: 0.045048438012599945 | MAE Test Loss: 0.11477935314178467 \n",
      "Epoch: 4100 | MAE Train Loss: 0.04500844329595566 | MAE Test Loss: 0.11460139602422714 \n",
      "Epoch: 4110 | MAE Train Loss: 0.04496845230460167 | MAE Test Loss: 0.11442339420318604 \n",
      "Epoch: 4120 | MAE Train Loss: 0.044928453862667084 | MAE Test Loss: 0.11424541473388672 \n",
      "Epoch: 4130 | MAE Train Loss: 0.0448884591460228 | MAE Test Loss: 0.1140674352645874 \n",
      "Epoch: 4140 | MAE Train Loss: 0.04484846070408821 | MAE Test Loss: 0.11388945579528809 \n",
      "Epoch: 4150 | MAE Train Loss: 0.04480846971273422 | MAE Test Loss: 0.11371149122714996 \n",
      "Epoch: 4160 | MAE Train Loss: 0.04476846754550934 | MAE Test Loss: 0.11353351920843124 \n",
      "Epoch: 4170 | MAE Train Loss: 0.04472848027944565 | MAE Test Loss: 0.11335553973913193 \n",
      "Epoch: 4180 | MAE Train Loss: 0.04468848556280136 | MAE Test Loss: 0.11317756026983261 \n",
      "Epoch: 4190 | MAE Train Loss: 0.044648490846157074 | MAE Test Loss: 0.1129995808005333 \n",
      "Epoch: 4200 | MAE Train Loss: 0.04460849612951279 | MAE Test Loss: 0.11282160133123398 \n",
      "Epoch: 4210 | MAE Train Loss: 0.0445685014128685 | MAE Test Loss: 0.11264362186193466 \n",
      "Epoch: 4220 | MAE Train Loss: 0.04452850669622421 | MAE Test Loss: 0.11246565729379654 \n",
      "Epoch: 4230 | MAE Train Loss: 0.04448850825428963 | MAE Test Loss: 0.11228767782449722 \n",
      "Epoch: 4240 | MAE Train Loss: 0.04444851726293564 | MAE Test Loss: 0.1121096983551979 \n",
      "Epoch: 4250 | MAE Train Loss: 0.04440852254629135 | MAE Test Loss: 0.11193172633647919 \n",
      "Epoch: 4260 | MAE Train Loss: 0.044368527829647064 | MAE Test Loss: 0.11175373941659927 \n",
      "Epoch: 4270 | MAE Train Loss: 0.04432853311300278 | MAE Test Loss: 0.11157576739788055 \n",
      "Epoch: 4280 | MAE Train Loss: 0.04428853839635849 | MAE Test Loss: 0.11139778047800064 \n",
      "Epoch: 4290 | MAE Train Loss: 0.0442485436797142 | MAE Test Loss: 0.11121980845928192 \n",
      "Epoch: 4300 | MAE Train Loss: 0.044208552688360214 | MAE Test Loss: 0.11104185879230499 \n",
      "Epoch: 4310 | MAE Train Loss: 0.04416855797171593 | MAE Test Loss: 0.11086386442184448 \n",
      "Epoch: 4320 | MAE Train Loss: 0.04412855952978134 | MAE Test Loss: 0.11068589985370636 \n",
      "Epoch: 4330 | MAE Train Loss: 0.044088564813137054 | MAE Test Loss: 0.11050790548324585 \n",
      "Epoch: 4340 | MAE Train Loss: 0.04404856264591217 | MAE Test Loss: 0.11032994091510773 \n",
      "Epoch: 4350 | MAE Train Loss: 0.04400857537984848 | MAE Test Loss: 0.11015196144580841 \n",
      "Epoch: 4360 | MAE Train Loss: 0.043968576937913895 | MAE Test Loss: 0.1099739819765091 \n",
      "Epoch: 4370 | MAE Train Loss: 0.043928585946559906 | MAE Test Loss: 0.10979600250720978 \n",
      "Epoch: 4380 | MAE Train Loss: 0.04388859122991562 | MAE Test Loss: 0.10961802303791046 \n",
      "Epoch: 4390 | MAE Train Loss: 0.04384859651327133 | MAE Test Loss: 0.10944006592035294 \n",
      "Epoch: 4400 | MAE Train Loss: 0.04380860924720764 | MAE Test Loss: 0.10926208645105362 \n",
      "Epoch: 4410 | MAE Train Loss: 0.04376860707998276 | MAE Test Loss: 0.10908409208059311 \n",
      "Epoch: 4420 | MAE Train Loss: 0.04372861608862877 | MAE Test Loss: 0.10890612751245499 \n",
      "Epoch: 4430 | MAE Train Loss: 0.043688613921403885 | MAE Test Loss: 0.10872814804315567 \n",
      "Epoch: 4440 | MAE Train Loss: 0.043648622930049896 | MAE Test Loss: 0.10855016857385635 \n",
      "Epoch: 4450 | MAE Train Loss: 0.04360862821340561 | MAE Test Loss: 0.10837218910455704 \n",
      "Epoch: 4460 | MAE Train Loss: 0.04356863722205162 | MAE Test Loss: 0.10819420963525772 \n",
      "Epoch: 4470 | MAE Train Loss: 0.043528638780117035 | MAE Test Loss: 0.1080162525177002 \n",
      "Epoch: 4480 | MAE Train Loss: 0.04348864406347275 | MAE Test Loss: 0.10783825069665909 \n",
      "Epoch: 4490 | MAE Train Loss: 0.04344864934682846 | MAE Test Loss: 0.10766029357910156 \n",
      "Epoch: 4500 | MAE Train Loss: 0.043408654630184174 | MAE Test Loss: 0.10748233646154404 \n",
      "Epoch: 4510 | MAE Train Loss: 0.043368663638830185 | MAE Test Loss: 0.10730433464050293 \n",
      "Epoch: 4520 | MAE Train Loss: 0.0433286651968956 | MAE Test Loss: 0.10712635517120361 \n",
      "Epoch: 4530 | MAE Train Loss: 0.04328867048025131 | MAE Test Loss: 0.1069483757019043 \n",
      "Epoch: 4540 | MAE Train Loss: 0.04324867203831673 | MAE Test Loss: 0.10677039623260498 \n",
      "Epoch: 4550 | MAE Train Loss: 0.04320868104696274 | MAE Test Loss: 0.10659243911504745 \n",
      "Epoch: 4560 | MAE Train Loss: 0.043168678879737854 | MAE Test Loss: 0.10641445964574814 \n",
      "Epoch: 4570 | MAE Train Loss: 0.043128691613674164 | MAE Test Loss: 0.10623648017644882 \n",
      "Epoch: 4580 | MAE Train Loss: 0.04308869689702988 | MAE Test Loss: 0.1060585007071495 \n",
      "Epoch: 4590 | MAE Train Loss: 0.04304870218038559 | MAE Test Loss: 0.10588052123785019 \n",
      "Epoch: 4600 | MAE Train Loss: 0.0430087074637413 | MAE Test Loss: 0.10570255666971207 \n",
      "Epoch: 4610 | MAE Train Loss: 0.042968712747097015 | MAE Test Loss: 0.10552456229925156 \n",
      "Epoch: 4620 | MAE Train Loss: 0.04292871803045273 | MAE Test Loss: 0.10534659773111343 \n",
      "Epoch: 4630 | MAE Train Loss: 0.04288871958851814 | MAE Test Loss: 0.10516861826181412 \n",
      "Epoch: 4640 | MAE Train Loss: 0.042848728597164154 | MAE Test Loss: 0.1049906387925148 \n",
      "Epoch: 4650 | MAE Train Loss: 0.042811933904886246 | MAE Test Loss: 0.10486016422510147 \n",
      "Epoch: 4660 | MAE Train Loss: 0.04277702793478966 | MAE Test Loss: 0.10475001484155655 \n",
      "Epoch: 4670 | MAE Train Loss: 0.04274212196469307 | MAE Test Loss: 0.10463988780975342 \n",
      "Epoch: 4680 | MAE Train Loss: 0.04270721971988678 | MAE Test Loss: 0.1045297384262085 \n",
      "Epoch: 4690 | MAE Train Loss: 0.04267231374979019 | MAE Test Loss: 0.10441961139440536 \n",
      "Epoch: 4700 | MAE Train Loss: 0.0426374115049839 | MAE Test Loss: 0.10430946201086044 \n",
      "Epoch: 4710 | MAE Train Loss: 0.042602505534887314 | MAE Test Loss: 0.10419933497905731 \n",
      "Epoch: 4720 | MAE Train Loss: 0.042567599564790726 | MAE Test Loss: 0.10408918559551239 \n",
      "Epoch: 4730 | MAE Train Loss: 0.042532697319984436 | MAE Test Loss: 0.10397906601428986 \n",
      "Epoch: 4740 | MAE Train Loss: 0.04249779134988785 | MAE Test Loss: 0.10386891663074493 \n",
      "Epoch: 4750 | MAE Train Loss: 0.04246288910508156 | MAE Test Loss: 0.1037587895989418 \n",
      "Epoch: 4760 | MAE Train Loss: 0.04242798313498497 | MAE Test Loss: 0.10364864021539688 \n",
      "Epoch: 4770 | MAE Train Loss: 0.04239307716488838 | MAE Test Loss: 0.10353851318359375 \n",
      "Epoch: 4780 | MAE Train Loss: 0.04235817492008209 | MAE Test Loss: 0.10342836380004883 \n",
      "Epoch: 4790 | MAE Train Loss: 0.042323268949985504 | MAE Test Loss: 0.1033182367682457 \n",
      "Epoch: 4800 | MAE Train Loss: 0.042288366705179214 | MAE Test Loss: 0.10320808738470078 \n",
      "Epoch: 4810 | MAE Train Loss: 0.042253460735082626 | MAE Test Loss: 0.10309796035289764 \n",
      "Epoch: 4820 | MAE Train Loss: 0.04221855476498604 | MAE Test Loss: 0.10298781096935272 \n",
      "Epoch: 4830 | MAE Train Loss: 0.04218365252017975 | MAE Test Loss: 0.10287769138813019 \n",
      "Epoch: 4840 | MAE Train Loss: 0.04214874655008316 | MAE Test Loss: 0.10276754200458527 \n",
      "Epoch: 4850 | MAE Train Loss: 0.04211384430527687 | MAE Test Loss: 0.10265741497278214 \n",
      "Epoch: 4860 | MAE Train Loss: 0.04207893833518028 | MAE Test Loss: 0.10254726558923721 \n",
      "Epoch: 4870 | MAE Train Loss: 0.042044032365083694 | MAE Test Loss: 0.10243713855743408 \n",
      "Epoch: 4880 | MAE Train Loss: 0.042009130120277405 | MAE Test Loss: 0.10232698917388916 \n",
      "Epoch: 4890 | MAE Train Loss: 0.04197422415018082 | MAE Test Loss: 0.10221686214208603 \n",
      "Epoch: 4900 | MAE Train Loss: 0.04193932190537453 | MAE Test Loss: 0.10210671275854111 \n",
      "Epoch: 4910 | MAE Train Loss: 0.04190441593527794 | MAE Test Loss: 0.10199658572673798 \n",
      "Epoch: 4920 | MAE Train Loss: 0.04186950996518135 | MAE Test Loss: 0.10188643634319305 \n",
      "Epoch: 4930 | MAE Train Loss: 0.04183460772037506 | MAE Test Loss: 0.10177631676197052 \n",
      "Epoch: 4940 | MAE Train Loss: 0.04179970175027847 | MAE Test Loss: 0.1016661673784256 \n",
      "Epoch: 4950 | MAE Train Loss: 0.04176479950547218 | MAE Test Loss: 0.10155604034662247 \n",
      "Epoch: 4960 | MAE Train Loss: 0.041729893535375595 | MAE Test Loss: 0.10144589096307755 \n",
      "Epoch: 4970 | MAE Train Loss: 0.04169498756527901 | MAE Test Loss: 0.10133576393127441 \n",
      "Epoch: 4980 | MAE Train Loss: 0.04166008532047272 | MAE Test Loss: 0.10122561454772949 \n",
      "Epoch: 4990 | MAE Train Loss: 0.04162517935037613 | MAE Test Loss: 0.10111548751592636 \n",
      "Epoch: 5000 | MAE Train Loss: 0.04159027710556984 | MAE Test Loss: 0.10100533813238144 \n",
      "Epoch: 5010 | MAE Train Loss: 0.04155537113547325 | MAE Test Loss: 0.10089521110057831 \n",
      "Epoch: 5020 | MAE Train Loss: 0.04152046516537666 | MAE Test Loss: 0.10078506171703339 \n",
      "Epoch: 5030 | MAE Train Loss: 0.041485562920570374 | MAE Test Loss: 0.10067494213581085 \n",
      "Epoch: 5040 | MAE Train Loss: 0.041450656950473785 | MAE Test Loss: 0.10056479275226593 \n",
      "Epoch: 5050 | MAE Train Loss: 0.041415754705667496 | MAE Test Loss: 0.1004546657204628 \n",
      "Epoch: 5060 | MAE Train Loss: 0.04138084873557091 | MAE Test Loss: 0.10034451633691788 \n",
      "Epoch: 5070 | MAE Train Loss: 0.04134594276547432 | MAE Test Loss: 0.10023438930511475 \n",
      "Epoch: 5080 | MAE Train Loss: 0.04131104052066803 | MAE Test Loss: 0.10012423992156982 \n",
      "Epoch: 5090 | MAE Train Loss: 0.04127613455057144 | MAE Test Loss: 0.1000141128897667 \n",
      "Epoch: 5100 | MAE Train Loss: 0.04124123230576515 | MAE Test Loss: 0.09990397095680237 \n",
      "Epoch: 5110 | MAE Train Loss: 0.041206326335668564 | MAE Test Loss: 0.09979383647441864 \n",
      "Epoch: 5120 | MAE Train Loss: 0.041171420365571976 | MAE Test Loss: 0.09968369454145432 \n",
      "Epoch: 5130 | MAE Train Loss: 0.041136518120765686 | MAE Test Loss: 0.09957356005907059 \n",
      "Epoch: 5140 | MAE Train Loss: 0.0411016121506691 | MAE Test Loss: 0.09946341812610626 \n",
      "Epoch: 5150 | MAE Train Loss: 0.04106670990586281 | MAE Test Loss: 0.09935328364372253 \n",
      "Epoch: 5160 | MAE Train Loss: 0.04103180393576622 | MAE Test Loss: 0.0992431491613388 \n",
      "Epoch: 5170 | MAE Train Loss: 0.04099689796566963 | MAE Test Loss: 0.09913300722837448 \n",
      "Epoch: 5180 | MAE Train Loss: 0.04096199572086334 | MAE Test Loss: 0.09902287274599075 \n",
      "Epoch: 5190 | MAE Train Loss: 0.040927089750766754 | MAE Test Loss: 0.09891273081302643 \n",
      "Epoch: 5200 | MAE Train Loss: 0.040892187505960464 | MAE Test Loss: 0.0988025963306427 \n",
      "Epoch: 5210 | MAE Train Loss: 0.040857281535863876 | MAE Test Loss: 0.09869246184825897 \n",
      "Epoch: 5220 | MAE Train Loss: 0.04082237556576729 | MAE Test Loss: 0.09858231991529465 \n",
      "Epoch: 5230 | MAE Train Loss: 0.040787473320961 | MAE Test Loss: 0.09847218543291092 \n",
      "Epoch: 5240 | MAE Train Loss: 0.04075256735086441 | MAE Test Loss: 0.0983620434999466 \n",
      "Epoch: 5250 | MAE Train Loss: 0.04071766510605812 | MAE Test Loss: 0.09825190901756287 \n",
      "Epoch: 5260 | MAE Train Loss: 0.04068275913596153 | MAE Test Loss: 0.09814177453517914 \n",
      "Epoch: 5270 | MAE Train Loss: 0.040647853165864944 | MAE Test Loss: 0.09803163260221481 \n",
      "Epoch: 5280 | MAE Train Loss: 0.040612950921058655 | MAE Test Loss: 0.09792149811983109 \n",
      "Epoch: 5290 | MAE Train Loss: 0.04057804495096207 | MAE Test Loss: 0.09781135618686676 \n",
      "Epoch: 5300 | MAE Train Loss: 0.04054314270615578 | MAE Test Loss: 0.09770122170448303 \n",
      "Epoch: 5310 | MAE Train Loss: 0.04050823673605919 | MAE Test Loss: 0.0975910872220993 \n",
      "Epoch: 5320 | MAE Train Loss: 0.0404733307659626 | MAE Test Loss: 0.09748094528913498 \n",
      "Epoch: 5330 | MAE Train Loss: 0.04043842852115631 | MAE Test Loss: 0.09737081080675125 \n",
      "Epoch: 5340 | MAE Train Loss: 0.04040352255105972 | MAE Test Loss: 0.09726066887378693 \n",
      "Epoch: 5350 | MAE Train Loss: 0.04036862030625343 | MAE Test Loss: 0.0971505343914032 \n",
      "Epoch: 5360 | MAE Train Loss: 0.040333714336156845 | MAE Test Loss: 0.09704039990901947 \n",
      "Epoch: 5370 | MAE Train Loss: 0.04029880836606026 | MAE Test Loss: 0.09693025797605515 \n",
      "Epoch: 5380 | MAE Train Loss: 0.04026390612125397 | MAE Test Loss: 0.09682012349367142 \n",
      "Epoch: 5390 | MAE Train Loss: 0.04022900015115738 | MAE Test Loss: 0.09670998156070709 \n",
      "Epoch: 5400 | MAE Train Loss: 0.04019409790635109 | MAE Test Loss: 0.09659984707832336 \n",
      "Epoch: 5410 | MAE Train Loss: 0.0401591919362545 | MAE Test Loss: 0.09648971259593964 \n",
      "Epoch: 5420 | MAE Train Loss: 0.04012428596615791 | MAE Test Loss: 0.09637957066297531 \n",
      "Epoch: 5430 | MAE Train Loss: 0.040089383721351624 | MAE Test Loss: 0.09626946598291397 \n",
      "Epoch: 5440 | MAE Train Loss: 0.040054481476545334 | MAE Test Loss: 0.09615931659936905 \n",
      "Epoch: 5450 | MAE Train Loss: 0.040019579231739044 | MAE Test Loss: 0.09604916721582413 \n",
      "Epoch: 5460 | MAE Train Loss: 0.03998466953635216 | MAE Test Loss: 0.09593904763460159 \n",
      "Epoch: 5470 | MAE Train Loss: 0.03994976729154587 | MAE Test Loss: 0.09582890570163727 \n",
      "Epoch: 5480 | MAE Train Loss: 0.03991486877202988 | MAE Test Loss: 0.09571877866983414 \n",
      "Epoch: 5490 | MAE Train Loss: 0.03987995907664299 | MAE Test Loss: 0.09560862928628922 \n",
      "Epoch: 5500 | MAE Train Loss: 0.039845060557127 | MAE Test Loss: 0.0954984799027443 \n",
      "Epoch: 5510 | MAE Train Loss: 0.039810147136449814 | MAE Test Loss: 0.09538836032152176 \n",
      "Epoch: 5520 | MAE Train Loss: 0.039775244891643524 | MAE Test Loss: 0.09527821838855743 \n",
      "Epoch: 5530 | MAE Train Loss: 0.03974034637212753 | MAE Test Loss: 0.0951680913567543 \n",
      "Epoch: 5540 | MAE Train Loss: 0.039705436676740646 | MAE Test Loss: 0.09505794197320938 \n",
      "Epoch: 5550 | MAE Train Loss: 0.03967053443193436 | MAE Test Loss: 0.09494779258966446 \n",
      "Epoch: 5560 | MAE Train Loss: 0.03963562846183777 | MAE Test Loss: 0.09483767300844193 \n",
      "Epoch: 5570 | MAE Train Loss: 0.03960072249174118 | MAE Test Loss: 0.0947275310754776 \n",
      "Epoch: 5580 | MAE Train Loss: 0.03956582397222519 | MAE Test Loss: 0.09461740404367447 \n",
      "Epoch: 5590 | MAE Train Loss: 0.0395309142768383 | MAE Test Loss: 0.09450725466012955 \n",
      "Epoch: 5600 | MAE Train Loss: 0.03949601575732231 | MAE Test Loss: 0.09439710527658463 \n",
      "Epoch: 5610 | MAE Train Loss: 0.039461106061935425 | MAE Test Loss: 0.09428698569536209 \n",
      "Epoch: 5620 | MAE Train Loss: 0.03942620009183884 | MAE Test Loss: 0.09417684376239777 \n",
      "Epoch: 5630 | MAE Train Loss: 0.039391301572322845 | MAE Test Loss: 0.09406671673059464 \n",
      "Epoch: 5640 | MAE Train Loss: 0.03935639187693596 | MAE Test Loss: 0.09395656734704971 \n",
      "Epoch: 5650 | MAE Train Loss: 0.03932148963212967 | MAE Test Loss: 0.09384641796350479 \n",
      "Epoch: 5660 | MAE Train Loss: 0.03928658366203308 | MAE Test Loss: 0.09373629838228226 \n",
      "Epoch: 5670 | MAE Train Loss: 0.03925167769193649 | MAE Test Loss: 0.09362615644931793 \n",
      "Epoch: 5680 | MAE Train Loss: 0.0392167791724205 | MAE Test Loss: 0.0935160294175148 \n",
      "Epoch: 5690 | MAE Train Loss: 0.039181869477033615 | MAE Test Loss: 0.09340588003396988 \n",
      "Epoch: 5700 | MAE Train Loss: 0.039146970957517624 | MAE Test Loss: 0.09329573065042496 \n",
      "Epoch: 5710 | MAE Train Loss: 0.03911206126213074 | MAE Test Loss: 0.09318561106920242 \n",
      "Epoch: 5720 | MAE Train Loss: 0.03907715529203415 | MAE Test Loss: 0.0930754691362381 \n",
      "Epoch: 5730 | MAE Train Loss: 0.03904225677251816 | MAE Test Loss: 0.09296534210443497 \n",
      "Epoch: 5740 | MAE Train Loss: 0.03900734707713127 | MAE Test Loss: 0.09285519272089005 \n",
      "Epoch: 5750 | MAE Train Loss: 0.03897244483232498 | MAE Test Loss: 0.09274504333734512 \n",
      "Epoch: 5760 | MAE Train Loss: 0.038937538862228394 | MAE Test Loss: 0.09263492375612259 \n",
      "Epoch: 5770 | MAE Train Loss: 0.038902632892131805 | MAE Test Loss: 0.09252478182315826 \n",
      "Epoch: 5780 | MAE Train Loss: 0.038867734372615814 | MAE Test Loss: 0.09241465479135513 \n",
      "Epoch: 5790 | MAE Train Loss: 0.03883282467722893 | MAE Test Loss: 0.09230450540781021 \n",
      "Epoch: 5800 | MAE Train Loss: 0.038797926157712936 | MAE Test Loss: 0.09219435602426529 \n",
      "Epoch: 5810 | MAE Train Loss: 0.03876301646232605 | MAE Test Loss: 0.09208423644304276 \n",
      "Epoch: 5820 | MAE Train Loss: 0.03872811049222946 | MAE Test Loss: 0.09197409451007843 \n",
      "Epoch: 5830 | MAE Train Loss: 0.03869321197271347 | MAE Test Loss: 0.0918639674782753 \n",
      "Epoch: 5840 | MAE Train Loss: 0.038658302277326584 | MAE Test Loss: 0.09175381809473038 \n",
      "Epoch: 5850 | MAE Train Loss: 0.038623400032520294 | MAE Test Loss: 0.09164366871118546 \n",
      "Epoch: 5860 | MAE Train Loss: 0.038588494062423706 | MAE Test Loss: 0.09153354912996292 \n",
      "Epoch: 5870 | MAE Train Loss: 0.03855358809232712 | MAE Test Loss: 0.0914234071969986 \n",
      "Epoch: 5880 | MAE Train Loss: 0.03851868957281113 | MAE Test Loss: 0.09131328016519547 \n",
      "Epoch: 5890 | MAE Train Loss: 0.03848377987742424 | MAE Test Loss: 0.09120313078165054 \n",
      "Epoch: 5900 | MAE Train Loss: 0.03844888135790825 | MAE Test Loss: 0.09109298139810562 \n",
      "Epoch: 5910 | MAE Train Loss: 0.03841397166252136 | MAE Test Loss: 0.09098286181688309 \n",
      "Epoch: 5920 | MAE Train Loss: 0.038379065692424774 | MAE Test Loss: 0.09087271988391876 \n",
      "Epoch: 5930 | MAE Train Loss: 0.03834416717290878 | MAE Test Loss: 0.09076259285211563 \n",
      "Epoch: 5940 | MAE Train Loss: 0.038309257477521896 | MAE Test Loss: 0.09065244346857071 \n",
      "Epoch: 5950 | MAE Train Loss: 0.03827435523271561 | MAE Test Loss: 0.09054229408502579 \n",
      "Epoch: 5960 | MAE Train Loss: 0.03823944926261902 | MAE Test Loss: 0.09043217450380325 \n",
      "Epoch: 5970 | MAE Train Loss: 0.03820454329252243 | MAE Test Loss: 0.09032203257083893 \n",
      "Epoch: 5980 | MAE Train Loss: 0.03816964477300644 | MAE Test Loss: 0.0902119055390358 \n",
      "Epoch: 5990 | MAE Train Loss: 0.03813473507761955 | MAE Test Loss: 0.09010175615549088 \n",
      "Epoch: 6000 | MAE Train Loss: 0.03809983655810356 | MAE Test Loss: 0.08999161422252655 \n",
      "Epoch: 6010 | MAE Train Loss: 0.038064926862716675 | MAE Test Loss: 0.08988148719072342 \n",
      "Epoch: 6020 | MAE Train Loss: 0.03803002089262009 | MAE Test Loss: 0.0897713452577591 \n",
      "Epoch: 6030 | MAE Train Loss: 0.037995122373104095 | MAE Test Loss: 0.08966121822595596 \n",
      "Epoch: 6040 | MAE Train Loss: 0.03796021267771721 | MAE Test Loss: 0.08955106884241104 \n",
      "Epoch: 6050 | MAE Train Loss: 0.03792531043291092 | MAE Test Loss: 0.08944092690944672 \n",
      "Epoch: 6060 | MAE Train Loss: 0.03789040446281433 | MAE Test Loss: 0.08933079987764359 \n",
      "Epoch: 6070 | MAE Train Loss: 0.03785549849271774 | MAE Test Loss: 0.08922065794467926 \n",
      "Epoch: 6080 | MAE Train Loss: 0.03782059997320175 | MAE Test Loss: 0.08911053091287613 \n",
      "Epoch: 6090 | MAE Train Loss: 0.037785690277814865 | MAE Test Loss: 0.08900038152933121 \n",
      "Epoch: 6100 | MAE Train Loss: 0.037750791758298874 | MAE Test Loss: 0.08889023959636688 \n",
      "Epoch: 6110 | MAE Train Loss: 0.03771588206291199 | MAE Test Loss: 0.08878011256456375 \n",
      "Epoch: 6120 | MAE Train Loss: 0.0376809760928154 | MAE Test Loss: 0.08866997063159943 \n",
      "Epoch: 6130 | MAE Train Loss: 0.03764607757329941 | MAE Test Loss: 0.0885598435997963 \n",
      "Epoch: 6140 | MAE Train Loss: 0.03761116787791252 | MAE Test Loss: 0.08844969421625137 \n",
      "Epoch: 6150 | MAE Train Loss: 0.03757626563310623 | MAE Test Loss: 0.08833955228328705 \n",
      "Epoch: 6160 | MAE Train Loss: 0.037541359663009644 | MAE Test Loss: 0.08822942525148392 \n",
      "Epoch: 6170 | MAE Train Loss: 0.037506453692913055 | MAE Test Loss: 0.08811928331851959 \n",
      "Epoch: 6180 | MAE Train Loss: 0.037471555173397064 | MAE Test Loss: 0.08800915628671646 \n",
      "Epoch: 6190 | MAE Train Loss: 0.03743664547801018 | MAE Test Loss: 0.08789900690317154 \n",
      "Epoch: 6200 | MAE Train Loss: 0.037401746958494186 | MAE Test Loss: 0.08778886497020721 \n",
      "Epoch: 6210 | MAE Train Loss: 0.0373668372631073 | MAE Test Loss: 0.08767873793840408 \n",
      "Epoch: 6220 | MAE Train Loss: 0.03733193129301071 | MAE Test Loss: 0.08756859600543976 \n",
      "Epoch: 6230 | MAE Train Loss: 0.03729703277349472 | MAE Test Loss: 0.08745846897363663 \n",
      "Epoch: 6240 | MAE Train Loss: 0.037262123078107834 | MAE Test Loss: 0.0873483195900917 \n",
      "Epoch: 6250 | MAE Train Loss: 0.037227220833301544 | MAE Test Loss: 0.08723817765712738 \n",
      "Epoch: 6260 | MAE Train Loss: 0.037192314863204956 | MAE Test Loss: 0.08712805062532425 \n",
      "Epoch: 6270 | MAE Train Loss: 0.03715740889310837 | MAE Test Loss: 0.08701790869235992 \n",
      "Epoch: 6280 | MAE Train Loss: 0.03712251037359238 | MAE Test Loss: 0.0869077816605568 \n",
      "Epoch: 6290 | MAE Train Loss: 0.03708760067820549 | MAE Test Loss: 0.08679763227701187 \n",
      "Epoch: 6300 | MAE Train Loss: 0.0370527021586895 | MAE Test Loss: 0.08668749034404755 \n",
      "Epoch: 6310 | MAE Train Loss: 0.03701779246330261 | MAE Test Loss: 0.08657736331224442 \n",
      "Epoch: 6320 | MAE Train Loss: 0.036982886493206024 | MAE Test Loss: 0.08646722137928009 \n",
      "Epoch: 6330 | MAE Train Loss: 0.0369485467672348 | MAE Test Loss: 0.0863914042711258 \n",
      "Epoch: 6340 | MAE Train Loss: 0.03691420704126358 | MAE Test Loss: 0.08630871772766113 \n",
      "Epoch: 6350 | MAE Train Loss: 0.036879800260066986 | MAE Test Loss: 0.08622604608535767 \n",
      "Epoch: 6360 | MAE Train Loss: 0.03684546798467636 | MAE Test Loss: 0.08615021407604218 \n",
      "Epoch: 6370 | MAE Train Loss: 0.03681112080812454 | MAE Test Loss: 0.08606753498315811 \n",
      "Epoch: 6380 | MAE Train Loss: 0.03677671402692795 | MAE Test Loss: 0.08598484098911285 \n",
      "Epoch: 6390 | MAE Train Loss: 0.03674238920211792 | MAE Test Loss: 0.08590902388095856 \n",
      "Epoch: 6400 | MAE Train Loss: 0.036708004772663116 | MAE Test Loss: 0.08582980185747147 \n",
      "Epoch: 6410 | MAE Train Loss: 0.036673642694950104 | MAE Test Loss: 0.08574371039867401 \n",
      "Epoch: 6420 | MAE Train Loss: 0.036639317870140076 | MAE Test Loss: 0.08566790074110031 \n",
      "Epoch: 6430 | MAE Train Loss: 0.03660495951771736 | MAE Test Loss: 0.08558520674705505 \n",
      "Epoch: 6440 | MAE Train Loss: 0.036570556461811066 | MAE Test Loss: 0.0855025202035904 \n",
      "Epoch: 6450 | MAE Train Loss: 0.03653622418642044 | MAE Test Loss: 0.0854233056306839 \n",
      "Epoch: 6460 | MAE Train Loss: 0.03650186210870743 | MAE Test Loss: 0.085347481071949 \n",
      "Epoch: 6470 | MAE Train Loss: 0.036467473953962326 | MAE Test Loss: 0.08526138961315155 \n",
      "Epoch: 6480 | MAE Train Loss: 0.03643317148089409 | MAE Test Loss: 0.08518558740615845 \n",
      "Epoch: 6490 | MAE Train Loss: 0.03639879450201988 | MAE Test Loss: 0.08510288596153259 \n",
      "Epoch: 6500 | MAE Train Loss: 0.036364395171403885 | MAE Test Loss: 0.0850236564874649 \n",
      "Epoch: 6510 | MAE Train Loss: 0.03633005544543266 | MAE Test Loss: 0.08494096994400024 \n",
      "Epoch: 6520 | MAE Train Loss: 0.03629571944475174 | MAE Test Loss: 0.08486174792051315 \n",
      "Epoch: 6530 | MAE Train Loss: 0.03626132756471634 | MAE Test Loss: 0.08478593081235886 \n",
      "Epoch: 6540 | MAE Train Loss: 0.036227013915777206 | MAE Test Loss: 0.08470325171947479 \n",
      "Epoch: 6550 | MAE Train Loss: 0.0361926332116127 | MAE Test Loss: 0.08462056517601013 \n",
      "Epoch: 6560 | MAE Train Loss: 0.03615829348564148 | MAE Test Loss: 0.08454133570194244 \n",
      "Epoch: 6570 | MAE Train Loss: 0.03612395003437996 | MAE Test Loss: 0.08446212112903595 \n",
      "Epoch: 6580 | MAE Train Loss: 0.03608956187963486 | MAE Test Loss: 0.08437944948673248 \n",
      "Epoch: 6590 | MAE Train Loss: 0.03605516999959946 | MAE Test Loss: 0.08430361747741699 \n",
      "Epoch: 6600 | MAE Train Loss: 0.03602086380124092 | MAE Test Loss: 0.08422093093395233 \n",
      "Epoch: 6610 | MAE Train Loss: 0.035986486822366714 | MAE Test Loss: 0.08414170891046524 \n",
      "Epoch: 6620 | MAE Train Loss: 0.0359521359205246 | MAE Test Loss: 0.08405902236700058 \n",
      "Epoch: 6630 | MAE Train Loss: 0.035917796194553375 | MAE Test Loss: 0.0839797854423523 \n",
      "Epoch: 6640 | MAE Train Loss: 0.03588339313864708 | MAE Test Loss: 0.08389712870121002 \n",
      "Epoch: 6650 | MAE Train Loss: 0.03584901988506317 | MAE Test Loss: 0.08382128924131393 \n",
      "Epoch: 6660 | MAE Train Loss: 0.03581465408205986 | MAE Test Loss: 0.08373520523309708 \n",
      "Epoch: 6670 | MAE Train Loss: 0.03578033298254013 | MAE Test Loss: 0.08365938067436218 \n",
      "Epoch: 6680 | MAE Train Loss: 0.035745952278375626 | MAE Test Loss: 0.0835801512002945 \n",
      "Epoch: 6690 | MAE Train Loss: 0.03571164980530739 | MAE Test Loss: 0.08349746465682983 \n",
      "Epoch: 6700 | MAE Train Loss: 0.0356772355735302 | MAE Test Loss: 0.08341478556394577 \n",
      "Epoch: 6710 | MAE Train Loss: 0.035642869770526886 | MAE Test Loss: 0.08333896100521088 \n",
      "Epoch: 6720 | MAE Train Loss: 0.03560849279165268 | MAE Test Loss: 0.08325288444757462 \n",
      "Epoch: 6730 | MAE Train Loss: 0.03557416424155235 | MAE Test Loss: 0.08317366242408752 \n",
      "Epoch: 6740 | MAE Train Loss: 0.035539790987968445 | MAE Test Loss: 0.08309783786535263 \n",
      "Epoch: 6750 | MAE Train Loss: 0.03550548106431961 | MAE Test Loss: 0.08301515877246857 \n",
      "Epoch: 6760 | MAE Train Loss: 0.035471074283123016 | MAE Test Loss: 0.08293245732784271 \n",
      "Epoch: 6770 | MAE Train Loss: 0.03543673828244209 | MAE Test Loss: 0.08285324275493622 \n",
      "Epoch: 6780 | MAE Train Loss: 0.0354023352265358 | MAE Test Loss: 0.08277402073144913 \n",
      "Epoch: 6790 | MAE Train Loss: 0.03536800295114517 | MAE Test Loss: 0.08269132673740387 \n",
      "Epoch: 6800 | MAE Train Loss: 0.035333652049303055 | MAE Test Loss: 0.08261550962924957 \n",
      "Epoch: 6810 | MAE Train Loss: 0.03529931977391243 | MAE Test Loss: 0.08253283053636551 \n",
      "Epoch: 6820 | MAE Train Loss: 0.035264961421489716 | MAE Test Loss: 0.08245360106229782 \n",
      "Epoch: 6830 | MAE Train Loss: 0.03523057699203491 | MAE Test Loss: 0.08237092196941376 \n",
      "Epoch: 6840 | MAE Train Loss: 0.03519623726606369 | MAE Test Loss: 0.08229169994592667 \n",
      "Epoch: 6850 | MAE Train Loss: 0.03516183793544769 | MAE Test Loss: 0.082209013402462 \n",
      "Epoch: 6860 | MAE Train Loss: 0.03512750193476677 | MAE Test Loss: 0.08213319629430771 \n",
      "Epoch: 6870 | MAE Train Loss: 0.03509315848350525 | MAE Test Loss: 0.08205050975084305 \n",
      "Epoch: 6880 | MAE Train Loss: 0.03505881130695343 | MAE Test Loss: 0.08197127282619476 \n",
      "Epoch: 6890 | MAE Train Loss: 0.03502442687749863 | MAE Test Loss: 0.08189205825328827 \n",
      "Epoch: 6900 | MAE Train Loss: 0.03499007970094681 | MAE Test Loss: 0.0818093791604042 \n",
      "Epoch: 6910 | MAE Train Loss: 0.034955672919750214 | MAE Test Loss: 0.08172668516635895 \n",
      "Epoch: 6920 | MAE Train Loss: 0.034921348094940186 | MAE Test Loss: 0.08165086805820465 \n",
      "Epoch: 6930 | MAE Train Loss: 0.03488696366548538 | MAE Test Loss: 0.08157164603471756 \n",
      "Epoch: 6940 | MAE Train Loss: 0.03485260158777237 | MAE Test Loss: 0.0814855545759201 \n",
      "Epoch: 6950 | MAE Train Loss: 0.03481827676296234 | MAE Test Loss: 0.08140973746776581 \n",
      "Epoch: 6960 | MAE Train Loss: 0.03478391841053963 | MAE Test Loss: 0.08132705092430115 \n",
      "Epoch: 6970 | MAE Train Loss: 0.03474951535463333 | MAE Test Loss: 0.08124436438083649 \n",
      "Epoch: 6980 | MAE Train Loss: 0.034715183079242706 | MAE Test Loss: 0.08116514980792999 \n",
      "Epoch: 6990 | MAE Train Loss: 0.034680821001529694 | MAE Test Loss: 0.0810893252491951 \n",
      "Epoch: 7000 | MAE Train Loss: 0.03464643657207489 | MAE Test Loss: 0.08100324124097824 \n",
      "Epoch: 7010 | MAE Train Loss: 0.034612126648426056 | MAE Test Loss: 0.08092742413282394 \n",
      "Epoch: 7020 | MAE Train Loss: 0.034577757120132446 | MAE Test Loss: 0.08084473758935928 \n",
      "Epoch: 7030 | MAE Train Loss: 0.03454335033893585 | MAE Test Loss: 0.080765500664711 \n",
      "Epoch: 7040 | MAE Train Loss: 0.03450901433825493 | MAE Test Loss: 0.08068281412124634 \n",
      "Epoch: 7050 | MAE Train Loss: 0.034474678337574005 | MAE Test Loss: 0.08060359954833984 \n",
      "Epoch: 7060 | MAE Train Loss: 0.034440286457538605 | MAE Test Loss: 0.08052776753902435 \n",
      "Epoch: 7070 | MAE Train Loss: 0.03440597280859947 | MAE Test Loss: 0.08044509589672089 \n",
      "Epoch: 7080 | MAE Train Loss: 0.03437159210443497 | MAE Test Loss: 0.08036240935325623 \n",
      "Epoch: 7090 | MAE Train Loss: 0.034337252378463745 | MAE Test Loss: 0.08028317987918854 \n",
      "Epoch: 7100 | MAE Train Loss: 0.034302908927202225 | MAE Test Loss: 0.08020396530628204 \n",
      "Epoch: 7110 | MAE Train Loss: 0.03426852077245712 | MAE Test Loss: 0.08012129366397858 \n",
      "Epoch: 7120 | MAE Train Loss: 0.03423412889242172 | MAE Test Loss: 0.08004546165466309 \n",
      "Epoch: 7130 | MAE Train Loss: 0.03419982269406319 | MAE Test Loss: 0.07996277511119843 \n",
      "Epoch: 7140 | MAE Train Loss: 0.03416544571518898 | MAE Test Loss: 0.07988355308771133 \n",
      "Epoch: 7150 | MAE Train Loss: 0.03413109481334686 | MAE Test Loss: 0.07980086654424667 \n",
      "Epoch: 7160 | MAE Train Loss: 0.03409675508737564 | MAE Test Loss: 0.07972162961959839 \n",
      "Epoch: 7170 | MAE Train Loss: 0.034062352031469345 | MAE Test Loss: 0.07963897287845612 \n",
      "Epoch: 7180 | MAE Train Loss: 0.03402797877788544 | MAE Test Loss: 0.07956313341856003 \n",
      "Epoch: 7190 | MAE Train Loss: 0.033993612974882126 | MAE Test Loss: 0.07947704941034317 \n",
      "Epoch: 7200 | MAE Train Loss: 0.033959291875362396 | MAE Test Loss: 0.07940122485160828 \n",
      "Epoch: 7210 | MAE Train Loss: 0.03392491117119789 | MAE Test Loss: 0.07932199537754059 \n",
      "Epoch: 7220 | MAE Train Loss: 0.033890608698129654 | MAE Test Loss: 0.07923930883407593 \n",
      "Epoch: 7230 | MAE Train Loss: 0.03385619446635246 | MAE Test Loss: 0.07915662974119186 \n",
      "Epoch: 7240 | MAE Train Loss: 0.03382182866334915 | MAE Test Loss: 0.07908080518245697 \n",
      "Epoch: 7250 | MAE Train Loss: 0.033787451684474945 | MAE Test Loss: 0.07899472117424011 \n",
      "Epoch: 7260 | MAE Train Loss: 0.03375312313437462 | MAE Test Loss: 0.07891550660133362 \n",
      "Epoch: 7270 | MAE Train Loss: 0.03371874988079071 | MAE Test Loss: 0.07883968204259872 \n",
      "Epoch: 7280 | MAE Train Loss: 0.033684439957141876 | MAE Test Loss: 0.07875700294971466 \n",
      "Epoch: 7290 | MAE Train Loss: 0.03365003317594528 | MAE Test Loss: 0.0786743015050888 \n",
      "Epoch: 7300 | MAE Train Loss: 0.03361569717526436 | MAE Test Loss: 0.07859508693218231 \n",
      "Epoch: 7310 | MAE Train Loss: 0.03358129411935806 | MAE Test Loss: 0.07851586490869522 \n",
      "Epoch: 7320 | MAE Train Loss: 0.03354696184396744 | MAE Test Loss: 0.07843317091464996 \n",
      "Epoch: 7330 | MAE Train Loss: 0.03351261094212532 | MAE Test Loss: 0.07835735380649567 \n",
      "Epoch: 7340 | MAE Train Loss: 0.033478278666734695 | MAE Test Loss: 0.0782746747136116 \n",
      "Epoch: 7350 | MAE Train Loss: 0.03344392031431198 | MAE Test Loss: 0.07819544523954391 \n",
      "Epoch: 7360 | MAE Train Loss: 0.03340953588485718 | MAE Test Loss: 0.07811276614665985 \n",
      "Epoch: 7370 | MAE Train Loss: 0.033375196158885956 | MAE Test Loss: 0.07803353667259216 \n",
      "Epoch: 7380 | MAE Train Loss: 0.03334079682826996 | MAE Test Loss: 0.0779508575797081 \n",
      "Epoch: 7390 | MAE Train Loss: 0.033306460827589035 | MAE Test Loss: 0.0778750404715538 \n",
      "Epoch: 7400 | MAE Train Loss: 0.033272117376327515 | MAE Test Loss: 0.07779236137866974 \n",
      "Epoch: 7410 | MAE Train Loss: 0.033237770199775696 | MAE Test Loss: 0.07771311700344086 \n",
      "Epoch: 7420 | MAE Train Loss: 0.03320338577032089 | MAE Test Loss: 0.07763390243053436 \n",
      "Epoch: 7430 | MAE Train Loss: 0.033169038593769073 | MAE Test Loss: 0.0775512233376503 \n",
      "Epoch: 7440 | MAE Train Loss: 0.03313463181257248 | MAE Test Loss: 0.07746852934360504 \n",
      "Epoch: 7450 | MAE Train Loss: 0.03310030698776245 | MAE Test Loss: 0.07739271223545074 \n",
      "Epoch: 7460 | MAE Train Loss: 0.03306592255830765 | MAE Test Loss: 0.07731349021196365 \n",
      "Epoch: 7470 | MAE Train Loss: 0.033031560480594635 | MAE Test Loss: 0.0772273987531662 \n",
      "Epoch: 7480 | MAE Train Loss: 0.03299723565578461 | MAE Test Loss: 0.0771515816450119 \n",
      "Epoch: 7490 | MAE Train Loss: 0.03296287730336189 | MAE Test Loss: 0.07706889510154724 \n",
      "Epoch: 7500 | MAE Train Loss: 0.0329284742474556 | MAE Test Loss: 0.07698620855808258 \n",
      "Epoch: 7510 | MAE Train Loss: 0.03289414197206497 | MAE Test Loss: 0.07690699398517609 \n",
      "Epoch: 7520 | MAE Train Loss: 0.03285977989435196 | MAE Test Loss: 0.07683117687702179 \n",
      "Epoch: 7530 | MAE Train Loss: 0.032825395464897156 | MAE Test Loss: 0.07674508541822433 \n",
      "Epoch: 7540 | MAE Train Loss: 0.03279108554124832 | MAE Test Loss: 0.07666926831007004 \n",
      "Epoch: 7550 | MAE Train Loss: 0.03275671601295471 | MAE Test Loss: 0.07658658176660538 \n",
      "Epoch: 7560 | MAE Train Loss: 0.032722312957048416 | MAE Test Loss: 0.07650734484195709 \n",
      "Epoch: 7570 | MAE Train Loss: 0.032687973231077194 | MAE Test Loss: 0.07642466574907303 \n",
      "Epoch: 7580 | MAE Train Loss: 0.03265363723039627 | MAE Test Loss: 0.07634544372558594 \n",
      "Epoch: 7590 | MAE Train Loss: 0.03261924535036087 | MAE Test Loss: 0.07626961171627045 \n",
      "Epoch: 7600 | MAE Train Loss: 0.03258493170142174 | MAE Test Loss: 0.07618694752454758 \n",
      "Epoch: 7610 | MAE Train Loss: 0.03255055472254753 | MAE Test Loss: 0.07610425353050232 \n",
      "Epoch: 7620 | MAE Train Loss: 0.03251621127128601 | MAE Test Loss: 0.07602502405643463 \n",
      "Epoch: 7630 | MAE Train Loss: 0.03248186782002449 | MAE Test Loss: 0.07594580948352814 \n",
      "Epoch: 7640 | MAE Train Loss: 0.03244747966527939 | MAE Test Loss: 0.07586313784122467 \n",
      "Epoch: 7650 | MAE Train Loss: 0.03241308778524399 | MAE Test Loss: 0.07578729838132858 \n",
      "Epoch: 7660 | MAE Train Loss: 0.03237878158688545 | MAE Test Loss: 0.07570461928844452 \n",
      "Epoch: 7670 | MAE Train Loss: 0.032344404608011246 | MAE Test Loss: 0.07562539726495743 \n",
      "Epoch: 7680 | MAE Train Loss: 0.03231005370616913 | MAE Test Loss: 0.07554271072149277 \n",
      "Epoch: 7690 | MAE Train Loss: 0.032275713980197906 | MAE Test Loss: 0.07546348124742508 \n",
      "Epoch: 7700 | MAE Train Loss: 0.03224131092429161 | MAE Test Loss: 0.07538080215454102 \n",
      "Epoch: 7710 | MAE Train Loss: 0.0322069376707077 | MAE Test Loss: 0.07530497759580612 \n",
      "Epoch: 7720 | MAE Train Loss: 0.03217257186770439 | MAE Test Loss: 0.07521889358758926 \n",
      "Epoch: 7730 | MAE Train Loss: 0.03213825076818466 | MAE Test Loss: 0.07514306902885437 \n",
      "Epoch: 7740 | MAE Train Loss: 0.03210387006402016 | MAE Test Loss: 0.07506383955478668 \n",
      "Epoch: 7750 | MAE Train Loss: 0.03206956386566162 | MAE Test Loss: 0.07498115301132202 \n",
      "Epoch: 7760 | MAE Train Loss: 0.03203515335917473 | MAE Test Loss: 0.07489847391843796 \n",
      "Epoch: 7770 | MAE Train Loss: 0.03200078755617142 | MAE Test Loss: 0.07482265681028366 \n",
      "Epoch: 7780 | MAE Train Loss: 0.03196641057729721 | MAE Test Loss: 0.0747365653514862 \n",
      "Epoch: 7790 | MAE Train Loss: 0.031932078301906586 | MAE Test Loss: 0.07465735077857971 \n",
      "Epoch: 7800 | MAE Train Loss: 0.031897708773612976 | MAE Test Loss: 0.07458152621984482 \n",
      "Epoch: 7810 | MAE Train Loss: 0.03186339884996414 | MAE Test Loss: 0.07449884712696075 \n",
      "Epoch: 7820 | MAE Train Loss: 0.03182899206876755 | MAE Test Loss: 0.0744161456823349 \n",
      "Epoch: 7830 | MAE Train Loss: 0.031794656068086624 | MAE Test Loss: 0.0743369311094284 \n",
      "Epoch: 7840 | MAE Train Loss: 0.03176025301218033 | MAE Test Loss: 0.07425770908594131 \n",
      "Epoch: 7850 | MAE Train Loss: 0.0317259207367897 | MAE Test Loss: 0.07417501509189606 \n",
      "Epoch: 7860 | MAE Train Loss: 0.031691569834947586 | MAE Test Loss: 0.07409919798374176 \n",
      "Epoch: 7870 | MAE Train Loss: 0.03165723755955696 | MAE Test Loss: 0.0740165188908577 \n",
      "Epoch: 7880 | MAE Train Loss: 0.03162287920713425 | MAE Test Loss: 0.07393728941679001 \n",
      "Epoch: 7890 | MAE Train Loss: 0.03158849850296974 | MAE Test Loss: 0.07385461032390594 \n",
      "Epoch: 7900 | MAE Train Loss: 0.03155415505170822 | MAE Test Loss: 0.07377538084983826 \n",
      "Epoch: 7910 | MAE Train Loss: 0.031519755721092224 | MAE Test Loss: 0.0736927017569542 \n",
      "Epoch: 7920 | MAE Train Loss: 0.0314854197204113 | MAE Test Loss: 0.0736168846487999 \n",
      "Epoch: 7930 | MAE Train Loss: 0.03145107626914978 | MAE Test Loss: 0.07353420555591583 \n",
      "Epoch: 7940 | MAE Train Loss: 0.03141672909259796 | MAE Test Loss: 0.07345496863126755 \n",
      "Epoch: 7950 | MAE Train Loss: 0.03138234466314316 | MAE Test Loss: 0.07337574660778046 \n",
      "Epoch: 7960 | MAE Train Loss: 0.03134799748659134 | MAE Test Loss: 0.07329306751489639 \n",
      "Epoch: 7970 | MAE Train Loss: 0.031313590705394745 | MAE Test Loss: 0.07321037352085114 \n",
      "Epoch: 7980 | MAE Train Loss: 0.03127926588058472 | MAE Test Loss: 0.07313455641269684 \n",
      "Epoch: 7990 | MAE Train Loss: 0.031244879588484764 | MAE Test Loss: 0.07305533438920975 \n",
      "Epoch: 8000 | MAE Train Loss: 0.03121051751077175 | MAE Test Loss: 0.07296924293041229 \n",
      "Epoch: 8010 | MAE Train Loss: 0.031176194548606873 | MAE Test Loss: 0.072893425822258 \n",
      "Epoch: 8020 | MAE Train Loss: 0.03114183619618416 | MAE Test Loss: 0.07281073927879333 \n",
      "Epoch: 8030 | MAE Train Loss: 0.031107431277632713 | MAE Test Loss: 0.07272805273532867 \n",
      "Epoch: 8040 | MAE Train Loss: 0.03107309900224209 | MAE Test Loss: 0.07264883816242218 \n",
      "Epoch: 8050 | MAE Train Loss: 0.031038736924529076 | MAE Test Loss: 0.07257302105426788 \n",
      "Epoch: 8060 | MAE Train Loss: 0.03100435435771942 | MAE Test Loss: 0.07248692959547043 \n",
      "Epoch: 8070 | MAE Train Loss: 0.030970042571425438 | MAE Test Loss: 0.07241111248731613 \n",
      "Epoch: 8080 | MAE Train Loss: 0.030935674905776978 | MAE Test Loss: 0.07232841849327087 \n",
      "Epoch: 8090 | MAE Train Loss: 0.030901271849870682 | MAE Test Loss: 0.07224918901920319 \n",
      "Epoch: 8100 | MAE Train Loss: 0.03086693212389946 | MAE Test Loss: 0.07216650992631912 \n",
      "Epoch: 8110 | MAE Train Loss: 0.030832597985863686 | MAE Test Loss: 0.07208728790283203 \n",
      "Epoch: 8120 | MAE Train Loss: 0.030798202380537987 | MAE Test Loss: 0.07201145589351654 \n",
      "Epoch: 8130 | MAE Train Loss: 0.030763890594244003 | MAE Test Loss: 0.07192879170179367 \n",
      "Epoch: 8140 | MAE Train Loss: 0.030729513615369797 | MAE Test Loss: 0.07184609025716782 \n",
      "Epoch: 8150 | MAE Train Loss: 0.030695170164108276 | MAE Test Loss: 0.07176686823368073 \n",
      "Epoch: 8160 | MAE Train Loss: 0.030660826712846756 | MAE Test Loss: 0.07168765366077423 \n",
      "Epoch: 8170 | MAE Train Loss: 0.030626440420746803 | MAE Test Loss: 0.07160498201847076 \n",
      "Epoch: 8180 | MAE Train Loss: 0.030592044815421104 | MAE Test Loss: 0.07152914255857468 \n",
      "Epoch: 8190 | MAE Train Loss: 0.030557742342352867 | MAE Test Loss: 0.07144646346569061 \n",
      "Epoch: 8200 | MAE Train Loss: 0.030523359775543213 | MAE Test Loss: 0.07136723399162292 \n",
      "Epoch: 8210 | MAE Train Loss: 0.030489012598991394 | MAE Test Loss: 0.07128455489873886 \n",
      "Epoch: 8220 | MAE Train Loss: 0.030454671010375023 | MAE Test Loss: 0.07120532542467117 \n",
      "Epoch: 8230 | MAE Train Loss: 0.030420269817113876 | MAE Test Loss: 0.07112264633178711 \n",
      "Epoch: 8240 | MAE Train Loss: 0.030385896563529968 | MAE Test Loss: 0.07104682177305222 \n",
      "Epoch: 8250 | MAE Train Loss: 0.030351530760526657 | MAE Test Loss: 0.07096074521541595 \n",
      "Epoch: 8260 | MAE Train Loss: 0.030317207798361778 | MAE Test Loss: 0.07088490575551987 \n",
      "Epoch: 8270 | MAE Train Loss: 0.030282828956842422 | MAE Test Loss: 0.07080568373203278 \n",
      "Epoch: 8280 | MAE Train Loss: 0.030248522758483887 | MAE Test Loss: 0.07072300463914871 \n",
      "Epoch: 8290 | MAE Train Loss: 0.030214110389351845 | MAE Test Loss: 0.07064031809568405 \n",
      "Epoch: 8300 | MAE Train Loss: 0.030179748311638832 | MAE Test Loss: 0.07056450098752975 \n",
      "Epoch: 8310 | MAE Train Loss: 0.030145373195409775 | MAE Test Loss: 0.0704784095287323 \n",
      "Epoch: 8320 | MAE Train Loss: 0.030111039057374 | MAE Test Loss: 0.07039918750524521 \n",
      "Epoch: 8330 | MAE Train Loss: 0.03007666766643524 | MAE Test Loss: 0.07032337039709091 \n",
      "Epoch: 8340 | MAE Train Loss: 0.030042355880141258 | MAE Test Loss: 0.07024069130420685 \n",
      "Epoch: 8350 | MAE Train Loss: 0.030007952824234962 | MAE Test Loss: 0.07015799731016159 \n",
      "Epoch: 8360 | MAE Train Loss: 0.02997361496090889 | MAE Test Loss: 0.0700787752866745 \n",
      "Epoch: 8370 | MAE Train Loss: 0.029939210042357445 | MAE Test Loss: 0.069999560713768 \n",
      "Epoch: 8380 | MAE Train Loss: 0.02990487776696682 | MAE Test Loss: 0.06991685926914215 \n",
      "Epoch: 8390 | MAE Train Loss: 0.02987052872776985 | MAE Test Loss: 0.06984104216098785 \n",
      "Epoch: 8400 | MAE Train Loss: 0.029836196452379227 | MAE Test Loss: 0.06975836306810379 \n",
      "Epoch: 8410 | MAE Train Loss: 0.02980183996260166 | MAE Test Loss: 0.0696791335940361 \n",
      "Epoch: 8420 | MAE Train Loss: 0.029767457395792007 | MAE Test Loss: 0.06959645450115204 \n",
      "Epoch: 8430 | MAE Train Loss: 0.029733117669820786 | MAE Test Loss: 0.06951722502708435 \n",
      "Epoch: 8440 | MAE Train Loss: 0.02969871461391449 | MAE Test Loss: 0.06943455338478088 \n",
      "Epoch: 8450 | MAE Train Loss: 0.029664378613233566 | MAE Test Loss: 0.0693587213754654 \n",
      "Epoch: 8460 | MAE Train Loss: 0.029630035161972046 | MAE Test Loss: 0.06927604973316193 \n",
      "Epoch: 8470 | MAE Train Loss: 0.029595687985420227 | MAE Test Loss: 0.06919681280851364 \n",
      "Epoch: 8480 | MAE Train Loss: 0.029561305418610573 | MAE Test Loss: 0.06911759078502655 \n",
      "Epoch: 8490 | MAE Train Loss: 0.029526954516768456 | MAE Test Loss: 0.06903491169214249 \n",
      "Epoch: 8500 | MAE Train Loss: 0.02949255146086216 | MAE Test Loss: 0.06895221769809723 \n",
      "Epoch: 8510 | MAE Train Loss: 0.029458224773406982 | MAE Test Loss: 0.06887640058994293 \n",
      "Epoch: 8520 | MAE Train Loss: 0.02942383848130703 | MAE Test Loss: 0.06879717856645584 \n",
      "Epoch: 8530 | MAE Train Loss: 0.029389476403594017 | MAE Test Loss: 0.06871108710765839 \n",
      "Epoch: 8540 | MAE Train Loss: 0.029355153441429138 | MAE Test Loss: 0.06863526999950409 \n",
      "Epoch: 8550 | MAE Train Loss: 0.029320795089006424 | MAE Test Loss: 0.06855258345603943 \n",
      "Epoch: 8560 | MAE Train Loss: 0.02928639017045498 | MAE Test Loss: 0.06846989691257477 \n",
      "Epoch: 8570 | MAE Train Loss: 0.029252057895064354 | MAE Test Loss: 0.06839068233966827 \n",
      "Epoch: 8580 | MAE Train Loss: 0.02921769581735134 | MAE Test Loss: 0.06831486523151398 \n",
      "Epoch: 8590 | MAE Train Loss: 0.029183313250541687 | MAE Test Loss: 0.06822877377271652 \n",
      "Epoch: 8600 | MAE Train Loss: 0.029149001464247704 | MAE Test Loss: 0.06815295666456223 \n",
      "Epoch: 8610 | MAE Train Loss: 0.029114633798599243 | MAE Test Loss: 0.06807026267051697 \n",
      "Epoch: 8620 | MAE Train Loss: 0.029080230742692947 | MAE Test Loss: 0.06799103319644928 \n",
      "Epoch: 8630 | MAE Train Loss: 0.029045891016721725 | MAE Test Loss: 0.06790835410356522 \n",
      "Epoch: 8640 | MAE Train Loss: 0.02901155687868595 | MAE Test Loss: 0.06782912462949753 \n",
      "Epoch: 8650 | MAE Train Loss: 0.028977161273360252 | MAE Test Loss: 0.06775330007076263 \n",
      "Epoch: 8660 | MAE Train Loss: 0.02894284948706627 | MAE Test Loss: 0.06767063587903976 \n",
      "Epoch: 8670 | MAE Train Loss: 0.028908472508192062 | MAE Test Loss: 0.06758793443441391 \n",
      "Epoch: 8680 | MAE Train Loss: 0.028874129056930542 | MAE Test Loss: 0.06750871241092682 \n",
      "Epoch: 8690 | MAE Train Loss: 0.02883978560566902 | MAE Test Loss: 0.06742949038743973 \n",
      "Epoch: 8700 | MAE Train Loss: 0.02880539931356907 | MAE Test Loss: 0.06734682619571686 \n",
      "Epoch: 8710 | MAE Train Loss: 0.02877100370824337 | MAE Test Loss: 0.06727097928524017 \n",
      "Epoch: 8720 | MAE Train Loss: 0.028736701235175133 | MAE Test Loss: 0.0671883076429367 \n",
      "Epoch: 8730 | MAE Train Loss: 0.02870231866836548 | MAE Test Loss: 0.06710907816886902 \n",
      "Epoch: 8740 | MAE Train Loss: 0.02866797149181366 | MAE Test Loss: 0.06702639907598495 \n",
      "Epoch: 8750 | MAE Train Loss: 0.02863362990319729 | MAE Test Loss: 0.06694716960191727 \n",
      "Epoch: 8760 | MAE Train Loss: 0.028599228709936142 | MAE Test Loss: 0.0668644905090332 \n",
      "Epoch: 8770 | MAE Train Loss: 0.028564855456352234 | MAE Test Loss: 0.0667886734008789 \n",
      "Epoch: 8780 | MAE Train Loss: 0.028530489653348923 | MAE Test Loss: 0.06670258194208145 \n",
      "Epoch: 8790 | MAE Train Loss: 0.028496166691184044 | MAE Test Loss: 0.06662674993276596 \n",
      "Epoch: 8800 | MAE Train Loss: 0.028461787849664688 | MAE Test Loss: 0.06654752790927887 \n",
      "Epoch: 8810 | MAE Train Loss: 0.028427477926015854 | MAE Test Loss: 0.0664648488163948 \n",
      "Epoch: 8820 | MAE Train Loss: 0.02839306928217411 | MAE Test Loss: 0.06638216227293015 \n",
      "Epoch: 8830 | MAE Train Loss: 0.028358707204461098 | MAE Test Loss: 0.06630635261535645 \n",
      "Epoch: 8840 | MAE Train Loss: 0.02832433208823204 | MAE Test Loss: 0.0662202462553978 \n",
      "Epoch: 8850 | MAE Train Loss: 0.028289997950196266 | MAE Test Loss: 0.0661410242319107 \n",
      "Epoch: 8860 | MAE Train Loss: 0.028255626559257507 | MAE Test Loss: 0.066065214574337 \n",
      "Epoch: 8870 | MAE Train Loss: 0.028221314772963524 | MAE Test Loss: 0.06598253548145294 \n",
      "Epoch: 8880 | MAE Train Loss: 0.028186911717057228 | MAE Test Loss: 0.06589984148740768 \n",
      "Epoch: 8890 | MAE Train Loss: 0.028152573853731155 | MAE Test Loss: 0.0658206194639206 \n",
      "Epoch: 8900 | MAE Train Loss: 0.02811816893517971 | MAE Test Loss: 0.0657413974404335 \n",
      "Epoch: 8910 | MAE Train Loss: 0.028083834797143936 | MAE Test Loss: 0.06565870344638824 \n",
      "Epoch: 8920 | MAE Train Loss: 0.028049487620592117 | MAE Test Loss: 0.06558288633823395 \n",
      "Epoch: 8930 | MAE Train Loss: 0.028015155345201492 | MAE Test Loss: 0.06550020724534988 \n",
      "Epoch: 8940 | MAE Train Loss: 0.027980798855423927 | MAE Test Loss: 0.0654209777712822 \n",
      "Epoch: 8950 | MAE Train Loss: 0.027946416288614273 | MAE Test Loss: 0.06533829867839813 \n",
      "Epoch: 8960 | MAE Train Loss: 0.02791207656264305 | MAE Test Loss: 0.06525906175374985 \n",
      "Epoch: 8970 | MAE Train Loss: 0.027877673506736755 | MAE Test Loss: 0.06517639011144638 \n",
      "Epoch: 8980 | MAE Train Loss: 0.027843337506055832 | MAE Test Loss: 0.06510056555271149 \n",
      "Epoch: 8990 | MAE Train Loss: 0.027808990329504013 | MAE Test Loss: 0.06501789391040802 \n",
      "Epoch: 9000 | MAE Train Loss: 0.027774646878242493 | MAE Test Loss: 0.06493865698575974 \n",
      "Epoch: 9010 | MAE Train Loss: 0.02774026431143284 | MAE Test Loss: 0.06485943496227264 \n",
      "Epoch: 9020 | MAE Train Loss: 0.02770591340959072 | MAE Test Loss: 0.06477675586938858 \n",
      "Epoch: 9030 | MAE Train Loss: 0.027671510353684425 | MAE Test Loss: 0.06469406187534332 \n",
      "Epoch: 9040 | MAE Train Loss: 0.027637183666229248 | MAE Test Loss: 0.06461824476718903 \n",
      "Epoch: 9050 | MAE Train Loss: 0.027602797374129295 | MAE Test Loss: 0.06453902274370193 \n",
      "Epoch: 9060 | MAE Train Loss: 0.027568435296416283 | MAE Test Loss: 0.06445293128490448 \n",
      "Epoch: 9070 | MAE Train Loss: 0.027534112334251404 | MAE Test Loss: 0.06437711417675018 \n",
      "Epoch: 9080 | MAE Train Loss: 0.02749975398182869 | MAE Test Loss: 0.06429442763328552 \n",
      "Epoch: 9090 | MAE Train Loss: 0.027465347200632095 | MAE Test Loss: 0.06421174108982086 \n",
      "Epoch: 9100 | MAE Train Loss: 0.02743101678788662 | MAE Test Loss: 0.06413251906633377 \n",
      "Epoch: 9110 | MAE Train Loss: 0.027396652847528458 | MAE Test Loss: 0.06405670940876007 \n",
      "Epoch: 9120 | MAE Train Loss: 0.027362272143363953 | MAE Test Loss: 0.06397061049938202 \n",
      "Epoch: 9130 | MAE Train Loss: 0.02732796035706997 | MAE Test Loss: 0.06389480084180832 \n",
      "Epoch: 9140 | MAE Train Loss: 0.02729359269142151 | MAE Test Loss: 0.06381210684776306 \n",
      "Epoch: 9150 | MAE Train Loss: 0.027259189635515213 | MAE Test Loss: 0.06373287737369537 \n",
      "Epoch: 9160 | MAE Train Loss: 0.02722484990954399 | MAE Test Loss: 0.06365019828081131 \n",
      "Epoch: 9170 | MAE Train Loss: 0.02719051204621792 | MAE Test Loss: 0.06357096880674362 \n",
      "Epoch: 9180 | MAE Train Loss: 0.027156120166182518 | MAE Test Loss: 0.06349514424800873 \n",
      "Epoch: 9190 | MAE Train Loss: 0.027121808379888535 | MAE Test Loss: 0.06341248005628586 \n",
      "Epoch: 9200 | MAE Train Loss: 0.027087431401014328 | MAE Test Loss: 0.06332977861166 \n",
      "Epoch: 9210 | MAE Train Loss: 0.027053091675043106 | MAE Test Loss: 0.06325055658817291 \n",
      "Epoch: 9220 | MAE Train Loss: 0.027018744498491287 | MAE Test Loss: 0.06317133456468582 \n",
      "Epoch: 9230 | MAE Train Loss: 0.026984358206391335 | MAE Test Loss: 0.06308867037296295 \n",
      "Epoch: 9240 | MAE Train Loss: 0.026949966326355934 | MAE Test Loss: 0.06301282346248627 \n",
      "Epoch: 9250 | MAE Train Loss: 0.0269156601279974 | MAE Test Loss: 0.0629301518201828 \n",
      "Epoch: 9260 | MAE Train Loss: 0.026881277561187744 | MAE Test Loss: 0.06285092234611511 \n",
      "Epoch: 9270 | MAE Train Loss: 0.026846934109926224 | MAE Test Loss: 0.06276824325323105 \n",
      "Epoch: 9280 | MAE Train Loss: 0.026812588796019554 | MAE Test Loss: 0.06268901377916336 \n",
      "Epoch: 9290 | MAE Train Loss: 0.026778187602758408 | MAE Test Loss: 0.0626063346862793 \n",
      "Epoch: 9300 | MAE Train Loss: 0.0267438143491745 | MAE Test Loss: 0.062530517578125 \n",
      "Epoch: 9310 | MAE Train Loss: 0.02670944854617119 | MAE Test Loss: 0.062444426119327545 \n",
      "Epoch: 9320 | MAE Train Loss: 0.02667512558400631 | MAE Test Loss: 0.062368594110012054 \n",
      "Epoch: 9330 | MAE Train Loss: 0.026640746742486954 | MAE Test Loss: 0.062289368361234665 \n",
      "Epoch: 9340 | MAE Train Loss: 0.02660643681883812 | MAE Test Loss: 0.0622066855430603 \n",
      "Epoch: 9350 | MAE Train Loss: 0.026572028174996376 | MAE Test Loss: 0.06212400645017624 \n",
      "Epoch: 9360 | MAE Train Loss: 0.026537666097283363 | MAE Test Loss: 0.06204819679260254 \n",
      "Epoch: 9370 | MAE Train Loss: 0.026503290981054306 | MAE Test Loss: 0.06196209043264389 \n",
      "Epoch: 9380 | MAE Train Loss: 0.026468956843018532 | MAE Test Loss: 0.0618828721344471 \n",
      "Epoch: 9390 | MAE Train Loss: 0.026434585452079773 | MAE Test Loss: 0.061807066202163696 \n",
      "Epoch: 9400 | MAE Train Loss: 0.02640027366578579 | MAE Test Loss: 0.061724383383989334 \n",
      "Epoch: 9410 | MAE Train Loss: 0.026365870609879494 | MAE Test Loss: 0.06164168566465378 \n",
      "Epoch: 9420 | MAE Train Loss: 0.02633153274655342 | MAE Test Loss: 0.061562467366456985 \n",
      "Epoch: 9430 | MAE Train Loss: 0.026297127828001976 | MAE Test Loss: 0.061483245342969894 \n",
      "Epoch: 9440 | MAE Train Loss: 0.026262793689966202 | MAE Test Loss: 0.06140054389834404 \n",
      "Epoch: 9450 | MAE Train Loss: 0.026228446513414383 | MAE Test Loss: 0.06132473424077034 \n",
      "Epoch: 9460 | MAE Train Loss: 0.026194114238023758 | MAE Test Loss: 0.06124205142259598 \n",
      "Epoch: 9470 | MAE Train Loss: 0.026159759610891342 | MAE Test Loss: 0.06116282194852829 \n",
      "Epoch: 9480 | MAE Train Loss: 0.02612537518143654 | MAE Test Loss: 0.06108013540506363 \n",
      "Epoch: 9490 | MAE Train Loss: 0.026091035455465317 | MAE Test Loss: 0.06100090593099594 \n",
      "Epoch: 9500 | MAE Train Loss: 0.02605663239955902 | MAE Test Loss: 0.060918234288692474 \n",
      "Epoch: 9510 | MAE Train Loss: 0.026022296398878098 | MAE Test Loss: 0.06084241345524788 \n",
      "Epoch: 9520 | MAE Train Loss: 0.025987952947616577 | MAE Test Loss: 0.060759734362363815 \n",
      "Epoch: 9530 | MAE Train Loss: 0.02595360577106476 | MAE Test Loss: 0.06068050116300583 \n",
      "Epoch: 9540 | MAE Train Loss: 0.025919223204255104 | MAE Test Loss: 0.060601282864809036 \n",
      "Epoch: 9550 | MAE Train Loss: 0.025884872302412987 | MAE Test Loss: 0.060518600046634674 \n",
      "Epoch: 9560 | MAE Train Loss: 0.02585046924650669 | MAE Test Loss: 0.060435909777879715 \n",
      "Epoch: 9570 | MAE Train Loss: 0.025816142559051514 | MAE Test Loss: 0.06036009266972542 \n",
      "Epoch: 9580 | MAE Train Loss: 0.02578175626695156 | MAE Test Loss: 0.06028086692094803 \n",
      "Epoch: 9590 | MAE Train Loss: 0.025747397914528847 | MAE Test Loss: 0.06019477918744087 \n",
      "Epoch: 9600 | MAE Train Loss: 0.02571307122707367 | MAE Test Loss: 0.06011895090341568 \n",
      "Epoch: 9610 | MAE Train Loss: 0.025678712874650955 | MAE Test Loss: 0.060036271810531616 \n",
      "Epoch: 9620 | MAE Train Loss: 0.02564430609345436 | MAE Test Loss: 0.059953588992357254 \n",
      "Epoch: 9630 | MAE Train Loss: 0.025609975680708885 | MAE Test Loss: 0.059874363243579865 \n",
      "Epoch: 9640 | MAE Train Loss: 0.025575608015060425 | MAE Test Loss: 0.059798549860715866 \n",
      "Epoch: 9650 | MAE Train Loss: 0.025541231036186218 | MAE Test Loss: 0.05971245840191841 \n",
      "Epoch: 9660 | MAE Train Loss: 0.025506919249892235 | MAE Test Loss: 0.059636641293764114 \n",
      "Epoch: 9670 | MAE Train Loss: 0.025472551584243774 | MAE Test Loss: 0.059553951025009155 \n",
      "Epoch: 9680 | MAE Train Loss: 0.02543814852833748 | MAE Test Loss: 0.059474725276231766 \n",
      "Epoch: 9690 | MAE Train Loss: 0.025403808802366257 | MAE Test Loss: 0.059392042458057404 \n",
      "Epoch: 9700 | MAE Train Loss: 0.025369470939040184 | MAE Test Loss: 0.05931280925869942 \n",
      "Epoch: 9710 | MAE Train Loss: 0.025335079059004784 | MAE Test Loss: 0.05923699215054512 \n",
      "Epoch: 9720 | MAE Train Loss: 0.0253007672727108 | MAE Test Loss: 0.05915432050824165 \n",
      "Epoch: 9730 | MAE Train Loss: 0.025266390293836594 | MAE Test Loss: 0.0590716227889061 \n",
      "Epoch: 9740 | MAE Train Loss: 0.02523205056786537 | MAE Test Loss: 0.058992404490709305 \n",
      "Epoch: 9750 | MAE Train Loss: 0.025197703391313553 | MAE Test Loss: 0.058913178741931915 \n",
      "Epoch: 9760 | MAE Train Loss: 0.0251633170992136 | MAE Test Loss: 0.05883051082491875 \n",
      "Epoch: 9770 | MAE Train Loss: 0.0251289252191782 | MAE Test Loss: 0.05875467136502266 \n",
      "Epoch: 9780 | MAE Train Loss: 0.025094619020819664 | MAE Test Loss: 0.05867199972271919 \n",
      "Epoch: 9790 | MAE Train Loss: 0.02506023645401001 | MAE Test Loss: 0.058592766523361206 \n",
      "Epoch: 9800 | MAE Train Loss: 0.02502589300274849 | MAE Test Loss: 0.05851009488105774 \n",
      "Epoch: 9810 | MAE Train Loss: 0.02499154955148697 | MAE Test Loss: 0.058430857956409454 \n",
      "Epoch: 9820 | MAE Train Loss: 0.024957144632935524 | MAE Test Loss: 0.05834817886352539 \n",
      "Epoch: 9830 | MAE Train Loss: 0.024922773241996765 | MAE Test Loss: 0.058272361755371094 \n",
      "Epoch: 9840 | MAE Train Loss: 0.024888407438993454 | MAE Test Loss: 0.05818627402186394 \n",
      "Epoch: 9850 | MAE Train Loss: 0.024854084476828575 | MAE Test Loss: 0.05811043828725815 \n",
      "Epoch: 9860 | MAE Train Loss: 0.02481970563530922 | MAE Test Loss: 0.058031219989061356 \n",
      "Epoch: 9870 | MAE Train Loss: 0.024785395711660385 | MAE Test Loss: 0.057948529720306396 \n",
      "Epoch: 9880 | MAE Train Loss: 0.02475098706781864 | MAE Test Loss: 0.05786585062742233 \n",
      "Epoch: 9890 | MAE Train Loss: 0.02471662499010563 | MAE Test Loss: 0.05779004096984863 \n",
      "Epoch: 9900 | MAE Train Loss: 0.02468224987387657 | MAE Test Loss: 0.057703934609889984 \n",
      "Epoch: 9910 | MAE Train Loss: 0.024647915735840797 | MAE Test Loss: 0.05762471631169319 \n",
      "Epoch: 9920 | MAE Train Loss: 0.02461354434490204 | MAE Test Loss: 0.05754891037940979 \n",
      "Epoch: 9930 | MAE Train Loss: 0.024579234421253204 | MAE Test Loss: 0.05746622756123543 \n",
      "Epoch: 9940 | MAE Train Loss: 0.02454482950270176 | MAE Test Loss: 0.05738352984189987 \n",
      "Epoch: 9950 | MAE Train Loss: 0.024510491639375687 | MAE Test Loss: 0.05730431154370308 \n",
      "Epoch: 9960 | MAE Train Loss: 0.024476084858179092 | MAE Test Loss: 0.05722508952021599 \n",
      "Epoch: 9970 | MAE Train Loss: 0.024441752582788467 | MAE Test Loss: 0.057142388075590134 \n",
      "Epoch: 9980 | MAE Train Loss: 0.02440740540623665 | MAE Test Loss: 0.057066578418016434 \n",
      "Epoch: 9990 | MAE Train Loss: 0.024373073130846024 | MAE Test Loss: 0.05698389559984207 \n",
      "Epoch: 10000 | MAE Train Loss: 0.024338718503713608 | MAE Test Loss: 0.056904666125774384 \n",
      "Epoch: 10010 | MAE Train Loss: 0.024304334074258804 | MAE Test Loss: 0.05682197958230972 \n",
      "Epoch: 10020 | MAE Train Loss: 0.024269994348287582 | MAE Test Loss: 0.056742750108242035 \n",
      "Epoch: 10030 | MAE Train Loss: 0.024235591292381287 | MAE Test Loss: 0.05666007846593857 \n",
      "Epoch: 10040 | MAE Train Loss: 0.024201255291700363 | MAE Test Loss: 0.05658425763249397 \n",
      "Epoch: 10050 | MAE Train Loss: 0.024166909977793694 | MAE Test Loss: 0.05650157853960991 \n",
      "Epoch: 10060 | MAE Train Loss: 0.024132560938596725 | MAE Test Loss: 0.05642234534025192 \n",
      "Epoch: 10070 | MAE Train Loss: 0.02409818209707737 | MAE Test Loss: 0.05634312704205513 \n",
      "Epoch: 10080 | MAE Train Loss: 0.024063829332590103 | MAE Test Loss: 0.05626044422388077 \n",
      "Epoch: 10090 | MAE Train Loss: 0.024029428139328957 | MAE Test Loss: 0.05617775395512581 \n",
      "Epoch: 10100 | MAE Train Loss: 0.02399510145187378 | MAE Test Loss: 0.05610193684697151 \n",
      "Epoch: 10110 | MAE Train Loss: 0.023960720747709274 | MAE Test Loss: 0.05602271109819412 \n",
      "Epoch: 10120 | MAE Train Loss: 0.023926356807351112 | MAE Test Loss: 0.055936623364686966 \n",
      "Epoch: 10130 | MAE Train Loss: 0.023892030119895935 | MAE Test Loss: 0.055860795080661774 \n",
      "Epoch: 10140 | MAE Train Loss: 0.02385767176747322 | MAE Test Loss: 0.05577811598777771 \n",
      "Epoch: 10150 | MAE Train Loss: 0.023823264986276627 | MAE Test Loss: 0.05569542571902275 \n",
      "Epoch: 10160 | MAE Train Loss: 0.02378893457353115 | MAE Test Loss: 0.05561620742082596 \n",
      "Epoch: 10170 | MAE Train Loss: 0.02375456877052784 | MAE Test Loss: 0.05554039031267166 \n",
      "Epoch: 10180 | MAE Train Loss: 0.023720186203718185 | MAE Test Loss: 0.055454302579164505 \n",
      "Epoch: 10190 | MAE Train Loss: 0.023685883730649948 | MAE Test Loss: 0.05537847802042961 \n",
      "Epoch: 10200 | MAE Train Loss: 0.02365151047706604 | MAE Test Loss: 0.05529579520225525 \n",
      "Epoch: 10210 | MAE Train Loss: 0.023617107421159744 | MAE Test Loss: 0.05521656945347786 \n",
      "Epoch: 10220 | MAE Train Loss: 0.023582767695188522 | MAE Test Loss: 0.0551338866353035 \n",
      "Epoch: 10230 | MAE Train Loss: 0.023548435419797897 | MAE Test Loss: 0.05505465343594551 \n",
      "Epoch: 10240 | MAE Train Loss: 0.0235140360891819 | MAE Test Loss: 0.054978836327791214 \n",
      "Epoch: 10250 | MAE Train Loss: 0.023479729890823364 | MAE Test Loss: 0.05489616468548775 \n",
      "Epoch: 10260 | MAE Train Loss: 0.02344534918665886 | MAE Test Loss: 0.05481347441673279 \n",
      "Epoch: 10270 | MAE Train Loss: 0.023411009460687637 | MAE Test Loss: 0.0547342412173748 \n",
      "Epoch: 10280 | MAE Train Loss: 0.02337666228413582 | MAE Test Loss: 0.05465502291917801 \n",
      "Epoch: 10290 | MAE Train Loss: 0.023342274129390717 | MAE Test Loss: 0.05457235127687454 \n",
      "Epoch: 10300 | MAE Train Loss: 0.023307884112000465 | MAE Test Loss: 0.05449651926755905 \n",
      "Epoch: 10310 | MAE Train Loss: 0.02327357791364193 | MAE Test Loss: 0.054413843899965286 \n",
      "Epoch: 10320 | MAE Train Loss: 0.023239195346832275 | MAE Test Loss: 0.0543346107006073 \n",
      "Epoch: 10330 | MAE Train Loss: 0.023204851895570755 | MAE Test Loss: 0.05425193905830383 \n",
      "Epoch: 10340 | MAE Train Loss: 0.023170508444309235 | MAE Test Loss: 0.05417270213365555 \n",
      "Epoch: 10350 | MAE Train Loss: 0.02313610538840294 | MAE Test Loss: 0.054090023040771484 \n",
      "Epoch: 10360 | MAE Train Loss: 0.02310173586010933 | MAE Test Loss: 0.05401420593261719 \n",
      "Epoch: 10370 | MAE Train Loss: 0.023067370057106018 | MAE Test Loss: 0.05392811447381973 \n",
      "Epoch: 10380 | MAE Train Loss: 0.02303304336965084 | MAE Test Loss: 0.05385228991508484 \n",
      "Epoch: 10390 | MAE Train Loss: 0.022998664528131485 | MAE Test Loss: 0.05377305671572685 \n",
      "Epoch: 10400 | MAE Train Loss: 0.02296435460448265 | MAE Test Loss: 0.05369038134813309 \n",
      "Epoch: 10410 | MAE Train Loss: 0.022929945960640907 | MAE Test Loss: 0.053607694804668427 \n",
      "Epoch: 10420 | MAE Train Loss: 0.022895583882927895 | MAE Test Loss: 0.05353188514709473 \n",
      "Epoch: 10430 | MAE Train Loss: 0.022861208766698837 | MAE Test Loss: 0.05344577878713608 \n",
      "Epoch: 10440 | MAE Train Loss: 0.022826874628663063 | MAE Test Loss: 0.053366560488939285 \n",
      "Epoch: 10450 | MAE Train Loss: 0.022792508825659752 | MAE Test Loss: 0.053290754556655884 \n",
      "Epoch: 10460 | MAE Train Loss: 0.02275819331407547 | MAE Test Loss: 0.05320807173848152 \n",
      "Epoch: 10470 | MAE Train Loss: 0.022723788395524025 | MAE Test Loss: 0.053125374019145966 \n",
      "Epoch: 10480 | MAE Train Loss: 0.0226894523948431 | MAE Test Loss: 0.05304615572094917 \n",
      "Epoch: 10490 | MAE Train Loss: 0.022655043751001358 | MAE Test Loss: 0.05296692997217178 \n",
      "Epoch: 10500 | MAE Train Loss: 0.022620711475610733 | MAE Test Loss: 0.052884239703416824 \n",
      "Epoch: 10510 | MAE Train Loss: 0.022586364299058914 | MAE Test Loss: 0.05280842259526253 \n",
      "Epoch: 10520 | MAE Train Loss: 0.02255203202366829 | MAE Test Loss: 0.052725739777088165 \n",
      "Epoch: 10530 | MAE Train Loss: 0.022517677396535873 | MAE Test Loss: 0.05264651030302048 \n",
      "Epoch: 10540 | MAE Train Loss: 0.02248329296708107 | MAE Test Loss: 0.05256382375955582 \n",
      "Epoch: 10550 | MAE Train Loss: 0.022448953241109848 | MAE Test Loss: 0.05248459428548813 \n",
      "Epoch: 10560 | MAE Train Loss: 0.022414550185203552 | MAE Test Loss: 0.05240192264318466 \n",
      "Epoch: 10570 | MAE Train Loss: 0.02238021418452263 | MAE Test Loss: 0.052326101809740067 \n",
      "Epoch: 10580 | MAE Train Loss: 0.02234586887061596 | MAE Test Loss: 0.052243418991565704 \n",
      "Epoch: 10590 | MAE Train Loss: 0.02231152169406414 | MAE Test Loss: 0.052164189517498016 \n",
      "Epoch: 10600 | MAE Train Loss: 0.022277140989899635 | MAE Test Loss: 0.052084971219301224 \n",
      "Epoch: 10610 | MAE Train Loss: 0.022242791950702667 | MAE Test Loss: 0.05200228840112686 \n",
      "Epoch: 10620 | MAE Train Loss: 0.022208387032151222 | MAE Test Loss: 0.0519195981323719 \n",
      "Epoch: 10630 | MAE Train Loss: 0.022174060344696045 | MAE Test Loss: 0.051843781024217606 \n",
      "Epoch: 10640 | MAE Train Loss: 0.02213967964053154 | MAE Test Loss: 0.051764555275440216 \n",
      "Epoch: 10650 | MAE Train Loss: 0.022105315700173378 | MAE Test Loss: 0.05167846754193306 \n",
      "Epoch: 10660 | MAE Train Loss: 0.0220709890127182 | MAE Test Loss: 0.05160263925790787 \n",
      "Epoch: 10670 | MAE Train Loss: 0.022036630660295486 | MAE Test Loss: 0.051519960165023804 \n",
      "Epoch: 10680 | MAE Train Loss: 0.022002223879098892 | MAE Test Loss: 0.051437269896268845 \n",
      "Epoch: 10690 | MAE Train Loss: 0.021967893466353416 | MAE Test Loss: 0.05135805159807205 \n",
      "Epoch: 10700 | MAE Train Loss: 0.021933527663350105 | MAE Test Loss: 0.051282234489917755 \n",
      "Epoch: 10710 | MAE Train Loss: 0.0218991469591856 | MAE Test Loss: 0.0511961467564106 \n",
      "Epoch: 10720 | MAE Train Loss: 0.021864842623472214 | MAE Test Loss: 0.051120322197675705 \n",
      "Epoch: 10730 | MAE Train Loss: 0.021830469369888306 | MAE Test Loss: 0.05103763937950134 \n",
      "Epoch: 10740 | MAE Train Loss: 0.02179606631398201 | MAE Test Loss: 0.05095841363072395 \n",
      "Epoch: 10750 | MAE Train Loss: 0.021761726588010788 | MAE Test Loss: 0.05087573081254959 \n",
      "Epoch: 10760 | MAE Train Loss: 0.021727394312620163 | MAE Test Loss: 0.050796497613191605 \n",
      "Epoch: 10770 | MAE Train Loss: 0.021692994982004166 | MAE Test Loss: 0.05072068050503731 \n",
      "Epoch: 10780 | MAE Train Loss: 0.02165868878364563 | MAE Test Loss: 0.05063800886273384 \n",
      "Epoch: 10790 | MAE Train Loss: 0.021624308079481125 | MAE Test Loss: 0.05055531859397888 \n",
      "Epoch: 10800 | MAE Train Loss: 0.021589968353509903 | MAE Test Loss: 0.050476085394620895 \n",
      "Epoch: 10810 | MAE Train Loss: 0.021555621176958084 | MAE Test Loss: 0.0503968670964241 \n",
      "Epoch: 10820 | MAE Train Loss: 0.021521233022212982 | MAE Test Loss: 0.050314195454120636 \n",
      "Epoch: 10830 | MAE Train Loss: 0.02148684300482273 | MAE Test Loss: 0.050238363444805145 \n",
      "Epoch: 10840 | MAE Train Loss: 0.021452536806464195 | MAE Test Loss: 0.05015568807721138 \n",
      "Epoch: 10850 | MAE Train Loss: 0.02141815423965454 | MAE Test Loss: 0.050076454877853394 \n",
      "Epoch: 10860 | MAE Train Loss: 0.02138381078839302 | MAE Test Loss: 0.04999377578496933 \n",
      "Epoch: 10870 | MAE Train Loss: 0.0213494673371315 | MAE Test Loss: 0.04991454631090164 \n",
      "Epoch: 10880 | MAE Train Loss: 0.021315064281225204 | MAE Test Loss: 0.04983186721801758 \n",
      "Epoch: 10890 | MAE Train Loss: 0.021280691027641296 | MAE Test Loss: 0.04975605010986328 \n",
      "Epoch: 10900 | MAE Train Loss: 0.021246328949928284 | MAE Test Loss: 0.049669958651065826 \n",
      "Epoch: 10910 | MAE Train Loss: 0.021212005987763405 | MAE Test Loss: 0.04959413409233093 \n",
      "Epoch: 10920 | MAE Train Loss: 0.02117762342095375 | MAE Test Loss: 0.049514900892972946 \n",
      "Epoch: 10930 | MAE Train Loss: 0.021143313497304916 | MAE Test Loss: 0.04943222552537918 \n",
      "Epoch: 10940 | MAE Train Loss: 0.021108904853463173 | MAE Test Loss: 0.04934953898191452 \n",
      "Epoch: 10950 | MAE Train Loss: 0.02107454277575016 | MAE Test Loss: 0.04927372932434082 \n",
      "Epoch: 10960 | MAE Train Loss: 0.021040167659521103 | MAE Test Loss: 0.04918763041496277 \n",
      "Epoch: 10970 | MAE Train Loss: 0.02100583352148533 | MAE Test Loss: 0.04910840839147568 \n",
      "Epoch: 10980 | MAE Train Loss: 0.020971467718482018 | MAE Test Loss: 0.04903259873390198 \n",
      "Epoch: 10990 | MAE Train Loss: 0.020937152206897736 | MAE Test Loss: 0.048949915915727615 \n",
      "Epoch: 11000 | MAE Train Loss: 0.02090274728834629 | MAE Test Loss: 0.04886721819639206 \n",
      "Epoch: 11010 | MAE Train Loss: 0.020868411287665367 | MAE Test Loss: 0.04878799989819527 \n",
      "Epoch: 11020 | MAE Train Loss: 0.020834006369113922 | MAE Test Loss: 0.04870877414941788 \n",
      "Epoch: 11030 | MAE Train Loss: 0.020799672231078148 | MAE Test Loss: 0.04862608388066292 \n",
      "Epoch: 11040 | MAE Train Loss: 0.02076532319188118 | MAE Test Loss: 0.04855026677250862 \n",
      "Epoch: 11050 | MAE Train Loss: 0.020730990916490555 | MAE Test Loss: 0.04846758395433426 \n",
      "Epoch: 11060 | MAE Train Loss: 0.02069663628935814 | MAE Test Loss: 0.04838835448026657 \n",
      "Epoch: 11070 | MAE Train Loss: 0.020662251859903336 | MAE Test Loss: 0.04830567166209221 \n",
      "Epoch: 11080 | MAE Train Loss: 0.020627912133932114 | MAE Test Loss: 0.04822644591331482 \n",
      "Epoch: 11090 | MAE Train Loss: 0.020593509078025818 | MAE Test Loss: 0.04814376309514046 \n",
      "Epoch: 11100 | MAE Train Loss: 0.020559173077344894 | MAE Test Loss: 0.04806794598698616 \n",
      "Epoch: 11110 | MAE Train Loss: 0.020524829626083374 | MAE Test Loss: 0.0479852631688118 \n",
      "Epoch: 11120 | MAE Train Loss: 0.020490480586886406 | MAE Test Loss: 0.04790603369474411 \n",
      "Epoch: 11130 | MAE Train Loss: 0.0204560998827219 | MAE Test Loss: 0.04782681539654732 \n",
      "Epoch: 11140 | MAE Train Loss: 0.020421750843524933 | MAE Test Loss: 0.047744132578372955 \n",
      "Epoch: 11150 | MAE Train Loss: 0.020387345924973488 | MAE Test Loss: 0.047661442309617996 \n",
      "Epoch: 11160 | MAE Train Loss: 0.02035301923751831 | MAE Test Loss: 0.0475856252014637 \n",
      "Epoch: 11170 | MAE Train Loss: 0.020318638533353806 | MAE Test Loss: 0.04750639945268631 \n",
      "Epoch: 11180 | MAE Train Loss: 0.020284274592995644 | MAE Test Loss: 0.04742031544446945 \n",
      "Epoch: 11190 | MAE Train Loss: 0.020249947905540466 | MAE Test Loss: 0.04734448716044426 \n",
      "Epoch: 11200 | MAE Train Loss: 0.020215589553117752 | MAE Test Loss: 0.0472618043422699 \n",
      "Epoch: 11210 | MAE Train Loss: 0.020181182771921158 | MAE Test Loss: 0.04717911407351494 \n",
      "Epoch: 11220 | MAE Train Loss: 0.020146852359175682 | MAE Test Loss: 0.047099895775318146 \n",
      "Epoch: 11230 | MAE Train Loss: 0.02011248655617237 | MAE Test Loss: 0.04702407866716385 \n",
      "Epoch: 11240 | MAE Train Loss: 0.020078105852007866 | MAE Test Loss: 0.04693799093365669 \n",
      "Epoch: 11250 | MAE Train Loss: 0.02004380151629448 | MAE Test Loss: 0.0468621663749218 \n",
      "Epoch: 11260 | MAE Train Loss: 0.02000942826271057 | MAE Test Loss: 0.046779483556747437 \n",
      "Epoch: 11270 | MAE Train Loss: 0.019975025206804276 | MAE Test Loss: 0.04670025780797005 \n",
      "Epoch: 11280 | MAE Train Loss: 0.019940685480833054 | MAE Test Loss: 0.04661757871508598 \n",
      "Epoch: 11290 | MAE Train Loss: 0.01990635320544243 | MAE Test Loss: 0.046538345515728 \n",
      "Epoch: 11300 | MAE Train Loss: 0.01987195387482643 | MAE Test Loss: 0.0464625246822834 \n",
      "Epoch: 11310 | MAE Train Loss: 0.019837647676467896 | MAE Test Loss: 0.046379853039979935 \n",
      "Epoch: 11320 | MAE Train Loss: 0.01980326697230339 | MAE Test Loss: 0.046297162771224976 \n",
      "Epoch: 11330 | MAE Train Loss: 0.01976892724633217 | MAE Test Loss: 0.04621792957186699 \n",
      "Epoch: 11340 | MAE Train Loss: 0.01973458006978035 | MAE Test Loss: 0.0461387112736702 \n",
      "Epoch: 11350 | MAE Train Loss: 0.0197001900523901 | MAE Test Loss: 0.04605603963136673 \n",
      "Epoch: 11360 | MAE Train Loss: 0.019665801897644997 | MAE Test Loss: 0.04598020762205124 \n",
      "Epoch: 11370 | MAE Train Loss: 0.01963149569928646 | MAE Test Loss: 0.045897532254457474 \n",
      "Epoch: 11380 | MAE Train Loss: 0.019597113132476807 | MAE Test Loss: 0.04581829905509949 \n",
      "Epoch: 11390 | MAE Train Loss: 0.019562769681215286 | MAE Test Loss: 0.04573562741279602 \n",
      "Epoch: 11400 | MAE Train Loss: 0.019528424367308617 | MAE Test Loss: 0.045656394213438034 \n",
      "Epoch: 11410 | MAE Train Loss: 0.01949402317404747 | MAE Test Loss: 0.045573703944683075 \n",
      "Epoch: 11420 | MAE Train Loss: 0.019459649920463562 | MAE Test Loss: 0.045497894287109375 \n",
      "Epoch: 11430 | MAE Train Loss: 0.01942528784275055 | MAE Test Loss: 0.04541180282831192 \n",
      "Epoch: 11440 | MAE Train Loss: 0.01939096488058567 | MAE Test Loss: 0.045335978269577026 \n",
      "Epoch: 11450 | MAE Train Loss: 0.019356582313776016 | MAE Test Loss: 0.04525674507021904 \n",
      "Epoch: 11460 | MAE Train Loss: 0.019322272390127182 | MAE Test Loss: 0.045174069702625275 \n",
      "Epoch: 11470 | MAE Train Loss: 0.01928786374628544 | MAE Test Loss: 0.045091383159160614 \n",
      "Epoch: 11480 | MAE Train Loss: 0.019253501668572426 | MAE Test Loss: 0.045015573501586914 \n",
      "Epoch: 11490 | MAE Train Loss: 0.01921912655234337 | MAE Test Loss: 0.04492947459220886 \n",
      "Epoch: 11500 | MAE Train Loss: 0.019184792414307594 | MAE Test Loss: 0.04485025256872177 \n",
      "Epoch: 11510 | MAE Train Loss: 0.019150426611304283 | MAE Test Loss: 0.04477444291114807 \n",
      "Epoch: 11520 | MAE Train Loss: 0.01911611109972 | MAE Test Loss: 0.04469176009297371 \n",
      "Epoch: 11530 | MAE Train Loss: 0.019081706181168556 | MAE Test Loss: 0.04460906237363815 \n",
      "Epoch: 11540 | MAE Train Loss: 0.019047370180487633 | MAE Test Loss: 0.04452984407544136 \n",
      "Epoch: 11550 | MAE Train Loss: 0.019012965261936188 | MAE Test Loss: 0.04445061832666397 \n",
      "Epoch: 11560 | MAE Train Loss: 0.018978631123900414 | MAE Test Loss: 0.04436792805790901 \n",
      "Epoch: 11570 | MAE Train Loss: 0.018944282084703445 | MAE Test Loss: 0.044292110949754715 \n",
      "Epoch: 11580 | MAE Train Loss: 0.01890994980931282 | MAE Test Loss: 0.04420942813158035 \n",
      "Epoch: 11590 | MAE Train Loss: 0.018875595182180405 | MAE Test Loss: 0.044130198657512665 \n",
      "Epoch: 11600 | MAE Train Loss: 0.0188412107527256 | MAE Test Loss: 0.0440475158393383 \n",
      "Epoch: 11610 | MAE Train Loss: 0.01880687102675438 | MAE Test Loss: 0.04396829009056091 \n",
      "Epoch: 11620 | MAE Train Loss: 0.018772467970848083 | MAE Test Loss: 0.04388560727238655 \n",
      "Epoch: 11630 | MAE Train Loss: 0.01873813197016716 | MAE Test Loss: 0.043809790164232254 \n",
      "Epoch: 11640 | MAE Train Loss: 0.01870378851890564 | MAE Test Loss: 0.04372710734605789 \n",
      "Epoch: 11650 | MAE Train Loss: 0.01866944134235382 | MAE Test Loss: 0.043647877871990204 \n",
      "Epoch: 11660 | MAE Train Loss: 0.018635058775544167 | MAE Test Loss: 0.04356865957379341 \n",
      "Epoch: 11670 | MAE Train Loss: 0.0186007097363472 | MAE Test Loss: 0.04348597675561905 \n",
      "Epoch: 11680 | MAE Train Loss: 0.018566306680440903 | MAE Test Loss: 0.04340328648686409 \n",
      "Epoch: 11690 | MAE Train Loss: 0.018531978130340576 | MAE Test Loss: 0.04332746937870979 \n",
      "Epoch: 11700 | MAE Train Loss: 0.018497595563530922 | MAE Test Loss: 0.043248243629932404 \n",
      "Epoch: 11710 | MAE Train Loss: 0.01846323348581791 | MAE Test Loss: 0.04316215589642525 \n",
      "Epoch: 11720 | MAE Train Loss: 0.018428906798362732 | MAE Test Loss: 0.04308633133769035 \n",
      "Epoch: 11730 | MAE Train Loss: 0.018394548445940018 | MAE Test Loss: 0.043003641068935394 \n",
      "Epoch: 11740 | MAE Train Loss: 0.018360141664743423 | MAE Test Loss: 0.04292095825076103 \n",
      "Epoch: 11750 | MAE Train Loss: 0.018325811251997948 | MAE Test Loss: 0.04284173995256424 \n",
      "Epoch: 11760 | MAE Train Loss: 0.018291447311639786 | MAE Test Loss: 0.04276592284440994 \n",
      "Epoch: 11770 | MAE Train Loss: 0.01825706660747528 | MAE Test Loss: 0.042679835110902786 \n",
      "Epoch: 11780 | MAE Train Loss: 0.018222760409116745 | MAE Test Loss: 0.04260401055216789 \n",
      "Epoch: 11790 | MAE Train Loss: 0.018188387155532837 | MAE Test Loss: 0.04252132773399353 \n",
      "Epoch: 11800 | MAE Train Loss: 0.01815398409962654 | MAE Test Loss: 0.04244210198521614 \n",
      "Epoch: 11810 | MAE Train Loss: 0.01811964437365532 | MAE Test Loss: 0.04235942289233208 \n",
      "Epoch: 11820 | MAE Train Loss: 0.018085310235619545 | MAE Test Loss: 0.04228019714355469 \n",
      "Epoch: 11830 | MAE Train Loss: 0.018050912767648697 | MAE Test Loss: 0.042204368859529495 \n",
      "Epoch: 11840 | MAE Train Loss: 0.01801660656929016 | MAE Test Loss: 0.04212169721722603 \n",
      "Epoch: 11850 | MAE Train Loss: 0.017982225865125656 | MAE Test Loss: 0.042039014399051666 \n",
      "Epoch: 11860 | MAE Train Loss: 0.017947886139154434 | MAE Test Loss: 0.04195977374911308 \n",
      "Epoch: 11870 | MAE Train Loss: 0.017913538962602615 | MAE Test Loss: 0.04188055545091629 \n",
      "Epoch: 11880 | MAE Train Loss: 0.017879148945212364 | MAE Test Loss: 0.04179787635803223 \n",
      "Epoch: 11890 | MAE Train Loss: 0.01784476265311241 | MAE Test Loss: 0.04172205179929733 \n",
      "Epoch: 11900 | MAE Train Loss: 0.017810454592108727 | MAE Test Loss: 0.04163937643170357 \n",
      "Epoch: 11910 | MAE Train Loss: 0.017776072025299072 | MAE Test Loss: 0.04156014323234558 \n",
      "Epoch: 11920 | MAE Train Loss: 0.017741728574037552 | MAE Test Loss: 0.041477471590042114 \n",
      "Epoch: 11930 | MAE Train Loss: 0.017707383260130882 | MAE Test Loss: 0.04139823839068413 \n",
      "Epoch: 11940 | MAE Train Loss: 0.017672982066869736 | MAE Test Loss: 0.04131554812192917 \n",
      "Epoch: 11950 | MAE Train Loss: 0.017638608813285828 | MAE Test Loss: 0.04123973846435547 \n",
      "Epoch: 11960 | MAE Train Loss: 0.017604246735572815 | MAE Test Loss: 0.041153647005558014 \n",
      "Epoch: 11970 | MAE Train Loss: 0.017569923773407936 | MAE Test Loss: 0.04107782989740372 \n",
      "Epoch: 11980 | MAE Train Loss: 0.017535541206598282 | MAE Test Loss: 0.040998589247465134 \n",
      "Epoch: 11990 | MAE Train Loss: 0.017501231282949448 | MAE Test Loss: 0.04091591387987137 \n",
      "Epoch: 12000 | MAE Train Loss: 0.017466822639107704 | MAE Test Loss: 0.040833234786987305 \n",
      "Epoch: 12010 | MAE Train Loss: 0.01743246056139469 | MAE Test Loss: 0.04075741767883301 \n",
      "Epoch: 12020 | MAE Train Loss: 0.017398085445165634 | MAE Test Loss: 0.040671318769454956 \n",
      "Epoch: 12030 | MAE Train Loss: 0.01736375130712986 | MAE Test Loss: 0.040592093020677567 \n",
      "Epoch: 12040 | MAE Train Loss: 0.01732938550412655 | MAE Test Loss: 0.040516287088394165 \n",
      "Epoch: 12050 | MAE Train Loss: 0.017295069992542267 | MAE Test Loss: 0.0404336042702198 \n",
      "Epoch: 12060 | MAE Train Loss: 0.017260665073990822 | MAE Test Loss: 0.04035090655088425 \n",
      "Epoch: 12070 | MAE Train Loss: 0.0172263290733099 | MAE Test Loss: 0.040271688252687454 \n",
      "Epoch: 12080 | MAE Train Loss: 0.017191924154758453 | MAE Test Loss: 0.040192462503910065 \n",
      "Epoch: 12090 | MAE Train Loss: 0.01715759001672268 | MAE Test Loss: 0.040109772235155106 \n",
      "Epoch: 12100 | MAE Train Loss: 0.01712324097752571 | MAE Test Loss: 0.04003395512700081 \n",
      "Epoch: 12110 | MAE Train Loss: 0.017088908702135086 | MAE Test Loss: 0.03995126485824585 \n",
      "Epoch: 12120 | MAE Train Loss: 0.01705455407500267 | MAE Test Loss: 0.039872050285339355 \n",
      "Epoch: 12130 | MAE Train Loss: 0.017020169645547867 | MAE Test Loss: 0.039789360016584396 \n",
      "Epoch: 12140 | MAE Train Loss: 0.016985829919576645 | MAE Test Loss: 0.03971013426780701 \n",
      "Epoch: 12150 | MAE Train Loss: 0.01695142686367035 | MAE Test Loss: 0.03962745517492294 \n",
      "Epoch: 12160 | MAE Train Loss: 0.016917090862989426 | MAE Test Loss: 0.03955163434147835 \n",
      "Epoch: 12170 | MAE Train Loss: 0.016882747411727905 | MAE Test Loss: 0.039468951523303986 \n",
      "Epoch: 12180 | MAE Train Loss: 0.016848400235176086 | MAE Test Loss: 0.0393897220492363 \n",
      "Epoch: 12190 | MAE Train Loss: 0.016814017668366432 | MAE Test Loss: 0.039310503751039505 \n",
      "Epoch: 12200 | MAE Train Loss: 0.016779668629169464 | MAE Test Loss: 0.03922782093286514 \n",
      "Epoch: 12210 | MAE Train Loss: 0.01674526557326317 | MAE Test Loss: 0.039145130664110184 \n",
      "Epoch: 12220 | MAE Train Loss: 0.016710937023162842 | MAE Test Loss: 0.03906931355595589 \n",
      "Epoch: 12230 | MAE Train Loss: 0.016676554456353188 | MAE Test Loss: 0.0389900803565979 \n",
      "Epoch: 12240 | MAE Train Loss: 0.016642192378640175 | MAE Test Loss: 0.03890400007367134 \n",
      "Epoch: 12250 | MAE Train Loss: 0.016607865691184998 | MAE Test Loss: 0.03882817551493645 \n",
      "Epoch: 12260 | MAE Train Loss: 0.016573509201407433 | MAE Test Loss: 0.03874548152089119 \n",
      "Epoch: 12270 | MAE Train Loss: 0.01653910055756569 | MAE Test Loss: 0.038662802428007126 \n",
      "Epoch: 12280 | MAE Train Loss: 0.016504770144820213 | MAE Test Loss: 0.03858358412981033 \n",
      "Epoch: 12290 | MAE Train Loss: 0.01647040620446205 | MAE Test Loss: 0.038507767021656036 \n",
      "Epoch: 12300 | MAE Train Loss: 0.016436023637652397 | MAE Test Loss: 0.03842168301343918 \n",
      "Epoch: 12310 | MAE Train Loss: 0.01640171930193901 | MAE Test Loss: 0.038345854729413986 \n",
      "Epoch: 12320 | MAE Train Loss: 0.016367346048355103 | MAE Test Loss: 0.038263171911239624 \n",
      "Epoch: 12330 | MAE Train Loss: 0.016332942992448807 | MAE Test Loss: 0.038183946162462234 \n",
      "Epoch: 12340 | MAE Train Loss: 0.016298603266477585 | MAE Test Loss: 0.03810126706957817 \n",
      "Epoch: 12350 | MAE Train Loss: 0.01626426912844181 | MAE Test Loss: 0.03802204132080078 \n",
      "Epoch: 12360 | MAE Train Loss: 0.016229871660470963 | MAE Test Loss: 0.03794621676206589 \n",
      "Epoch: 12370 | MAE Train Loss: 0.016195565462112427 | MAE Test Loss: 0.03786354139447212 \n",
      "Epoch: 12380 | MAE Train Loss: 0.016161184757947922 | MAE Test Loss: 0.03778085857629776 \n",
      "Epoch: 12390 | MAE Train Loss: 0.0161268450319767 | MAE Test Loss: 0.03770161792635918 \n",
      "Epoch: 12400 | MAE Train Loss: 0.01609249785542488 | MAE Test Loss: 0.037622399628162384 \n",
      "Epoch: 12410 | MAE Train Loss: 0.01605810783803463 | MAE Test Loss: 0.03753972053527832 \n",
      "Epoch: 12420 | MAE Train Loss: 0.016023719683289528 | MAE Test Loss: 0.037463895976543427 \n",
      "Epoch: 12430 | MAE Train Loss: 0.015989413484930992 | MAE Test Loss: 0.03738122060894966 \n",
      "Epoch: 12440 | MAE Train Loss: 0.015955032780766487 | MAE Test Loss: 0.037301987409591675 \n",
      "Epoch: 12450 | MAE Train Loss: 0.015920687466859818 | MAE Test Loss: 0.03721931576728821 \n",
      "Epoch: 12460 | MAE Train Loss: 0.015886342152953148 | MAE Test Loss: 0.03714008256793022 \n",
      "Epoch: 12470 | MAE Train Loss: 0.015851940959692 | MAE Test Loss: 0.03705739229917526 \n",
      "Epoch: 12480 | MAE Train Loss: 0.015817567706108093 | MAE Test Loss: 0.03698158264160156 \n",
      "Epoch: 12490 | MAE Train Loss: 0.01578320562839508 | MAE Test Loss: 0.03689549118280411 \n",
      "Epoch: 12500 | MAE Train Loss: 0.0157488826662302 | MAE Test Loss: 0.03681967407464981 \n",
      "Epoch: 12510 | MAE Train Loss: 0.015714500099420547 | MAE Test Loss: 0.03674043342471123 \n",
      "Epoch: 12520 | MAE Train Loss: 0.015680190175771713 | MAE Test Loss: 0.03665775805711746 \n",
      "Epoch: 12530 | MAE Train Loss: 0.01564578153192997 | MAE Test Loss: 0.0365750789642334 \n",
      "Epoch: 12540 | MAE Train Loss: 0.015611419454216957 | MAE Test Loss: 0.0364992618560791 \n",
      "Epoch: 12550 | MAE Train Loss: 0.015577045269310474 | MAE Test Loss: 0.03641316294670105 \n",
      "Epoch: 12560 | MAE Train Loss: 0.0155427111312747 | MAE Test Loss: 0.03633393719792366 \n",
      "Epoch: 12570 | MAE Train Loss: 0.01550834160298109 | MAE Test Loss: 0.03625813126564026 \n",
      "Epoch: 12580 | MAE Train Loss: 0.015474028885364532 | MAE Test Loss: 0.0361754484474659 \n",
      "Epoch: 12590 | MAE Train Loss: 0.015439623966813087 | MAE Test Loss: 0.03609275072813034 \n",
      "Epoch: 12600 | MAE Train Loss: 0.015405287966132164 | MAE Test Loss: 0.03601353242993355 \n",
      "Epoch: 12610 | MAE Train Loss: 0.015370883047580719 | MAE Test Loss: 0.03593430668115616 \n",
      "Epoch: 12620 | MAE Train Loss: 0.015336548909544945 | MAE Test Loss: 0.0358516164124012 \n",
      "Epoch: 12630 | MAE Train Loss: 0.015302200801670551 | MAE Test Loss: 0.0357757993042469 \n",
      "Epoch: 12640 | MAE Train Loss: 0.015267866663634777 | MAE Test Loss: 0.03569310903549194 \n",
      "Epoch: 12650 | MAE Train Loss: 0.01523351389914751 | MAE Test Loss: 0.03561389446258545 \n",
      "Epoch: 12660 | MAE Train Loss: 0.015199127607047558 | MAE Test Loss: 0.03553120419383049 \n",
      "Epoch: 12670 | MAE Train Loss: 0.015164789743721485 | MAE Test Loss: 0.0354519784450531 \n",
      "Epoch: 12680 | MAE Train Loss: 0.015130385756492615 | MAE Test Loss: 0.03536929935216904 \n",
      "Epoch: 12690 | MAE Train Loss: 0.015096050687134266 | MAE Test Loss: 0.03529347851872444 \n",
      "Epoch: 12700 | MAE Train Loss: 0.015061704441905022 | MAE Test Loss: 0.03521079570055008 \n",
      "Epoch: 12710 | MAE Train Loss: 0.015027357265353203 | MAE Test Loss: 0.03513156250119209 \n",
      "Epoch: 12720 | MAE Train Loss: 0.014992979355156422 | MAE Test Loss: 0.035052340477705 \n",
      "Epoch: 12730 | MAE Train Loss: 0.014958630315959454 | MAE Test Loss: 0.03496966511011124 \n",
      "Epoch: 12740 | MAE Train Loss: 0.014924225397408009 | MAE Test Loss: 0.03488697484135628 \n",
      "Epoch: 12750 | MAE Train Loss: 0.014889898709952831 | MAE Test Loss: 0.03481115773320198 \n",
      "Epoch: 12760 | MAE Train Loss: 0.014855511486530304 | MAE Test Loss: 0.034731924533843994 \n",
      "Epoch: 12770 | MAE Train Loss: 0.01482115127146244 | MAE Test Loss: 0.03464584797620773 \n",
      "Epoch: 12780 | MAE Train Loss: 0.014786824584007263 | MAE Test Loss: 0.03457002714276314 \n",
      "Epoch: 12790 | MAE Train Loss: 0.014752468094229698 | MAE Test Loss: 0.03448732942342758 \n",
      "Epoch: 12800 | MAE Train Loss: 0.01471805851906538 | MAE Test Loss: 0.034404654055833817 \n",
      "Epoch: 12810 | MAE Train Loss: 0.014683729037642479 | MAE Test Loss: 0.03432542830705643 \n",
      "Epoch: 12820 | MAE Train Loss: 0.014649364165961742 | MAE Test Loss: 0.03424961119890213 \n",
      "Epoch: 12830 | MAE Train Loss: 0.014614982530474663 | MAE Test Loss: 0.034163523465394974 \n",
      "Epoch: 12840 | MAE Train Loss: 0.014580677263438702 | MAE Test Loss: 0.03408769518136978 \n",
      "Epoch: 12850 | MAE Train Loss: 0.014546304941177368 | MAE Test Loss: 0.03400500863790512 \n",
      "Epoch: 12860 | MAE Train Loss: 0.014511900953948498 | MAE Test Loss: 0.03392579033970833 \n",
      "Epoch: 12870 | MAE Train Loss: 0.014477565884590149 | MAE Test Loss: 0.033843111246824265 \n",
      "Epoch: 12880 | MAE Train Loss: 0.014443226158618927 | MAE Test Loss: 0.033763885498046875 \n",
      "Epoch: 12890 | MAE Train Loss: 0.014408831484615803 | MAE Test Loss: 0.03368806093931198 \n",
      "Epoch: 12900 | MAE Train Loss: 0.014374524354934692 | MAE Test Loss: 0.033605385571718216 \n",
      "Epoch: 12910 | MAE Train Loss: 0.014340144582092762 | MAE Test Loss: 0.033522702753543854 \n",
      "Epoch: 12920 | MAE Train Loss: 0.01430580299347639 | MAE Test Loss: 0.03344346955418587 \n",
      "Epoch: 12930 | MAE Train Loss: 0.014271457679569721 | MAE Test Loss: 0.03336424380540848 \n",
      "Epoch: 12940 | MAE Train Loss: 0.014237066730856895 | MAE Test Loss: 0.033281564712524414 \n",
      "Epoch: 12950 | MAE Train Loss: 0.014202679507434368 | MAE Test Loss: 0.03320574015378952 \n",
      "Epoch: 12960 | MAE Train Loss: 0.014168371446430683 | MAE Test Loss: 0.033123064786195755 \n",
      "Epoch: 12970 | MAE Train Loss: 0.014133989810943604 | MAE Test Loss: 0.03304382413625717 \n",
      "Epoch: 12980 | MAE Train Loss: 0.014099645428359509 | MAE Test Loss: 0.032961152493953705 \n",
      "Epoch: 12990 | MAE Train Loss: 0.014065304771065712 | MAE Test Loss: 0.032881926745176315 \n",
      "Epoch: 13000 | MAE Train Loss: 0.014030903577804565 | MAE Test Loss: 0.032799236476421356 \n",
      "Epoch: 13010 | MAE Train Loss: 0.013996528461575508 | MAE Test Loss: 0.032723426818847656 \n",
      "Epoch: 13020 | MAE Train Loss: 0.013962164521217346 | MAE Test Loss: 0.0326373353600502 \n",
      "Epoch: 13030 | MAE Train Loss: 0.013927841559052467 | MAE Test Loss: 0.032561518251895905 \n",
      "Epoch: 13040 | MAE Train Loss: 0.013893458060920238 | MAE Test Loss: 0.03248228505253792 \n",
      "Epoch: 13050 | MAE Train Loss: 0.013859149999916553 | MAE Test Loss: 0.032399605959653854 \n",
      "Epoch: 13060 | MAE Train Loss: 0.013824740424752235 | MAE Test Loss: 0.03231693059206009 \n",
      "Epoch: 13070 | MAE Train Loss: 0.013790378347039223 | MAE Test Loss: 0.03224111348390579 \n",
      "Epoch: 13080 | MAE Train Loss: 0.01375600229948759 | MAE Test Loss: 0.032155007123947144 \n",
      "Epoch: 13090 | MAE Train Loss: 0.013721669092774391 | MAE Test Loss: 0.03207577392458916 \n",
      "Epoch: 13100 | MAE Train Loss: 0.013687300495803356 | MAE Test Loss: 0.031999967992305756 \n",
      "Epoch: 13110 | MAE Train Loss: 0.013652987778186798 | MAE Test Loss: 0.03191728517413139 \n",
      "Epoch: 13120 | MAE Train Loss: 0.013618582859635353 | MAE Test Loss: 0.031834591180086136 \n",
      "Epoch: 13130 | MAE Train Loss: 0.013584248721599579 | MAE Test Loss: 0.031755369156599045 \n",
      "Epoch: 13140 | MAE Train Loss: 0.013549843803048134 | MAE Test Loss: 0.03167615085840225 \n",
      "Epoch: 13150 | MAE Train Loss: 0.01351550780236721 | MAE Test Loss: 0.03159346058964729 \n",
      "Epoch: 13160 | MAE Train Loss: 0.013481159694492817 | MAE Test Loss: 0.031517643481492996 \n",
      "Epoch: 13170 | MAE Train Loss: 0.013446825556457043 | MAE Test Loss: 0.03143495321273804 \n",
      "Epoch: 13180 | MAE Train Loss: 0.013412472791969776 | MAE Test Loss: 0.03135574609041214 \n",
      "Epoch: 13190 | MAE Train Loss: 0.013378086499869823 | MAE Test Loss: 0.03127305582165718 \n",
      "Epoch: 13200 | MAE Train Loss: 0.013343746773898602 | MAE Test Loss: 0.031193822622299194 \n",
      "Epoch: 13210 | MAE Train Loss: 0.01330934464931488 | MAE Test Loss: 0.03111114539206028 \n",
      "Epoch: 13220 | MAE Train Loss: 0.013275009579956532 | MAE Test Loss: 0.031035322695970535 \n",
      "Epoch: 13230 | MAE Train Loss: 0.013240665197372437 | MAE Test Loss: 0.030952638015151024 \n",
      "Epoch: 13240 | MAE Train Loss: 0.013206318020820618 | MAE Test Loss: 0.030873406678438187 \n",
      "Epoch: 13250 | MAE Train Loss: 0.013171938247978687 | MAE Test Loss: 0.030794184654951096 \n",
      "Epoch: 13260 | MAE Train Loss: 0.013137588277459145 | MAE Test Loss: 0.03071150742471218 \n",
      "Epoch: 13270 | MAE Train Loss: 0.013103184290230274 | MAE Test Loss: 0.03062881901860237 \n",
      "Epoch: 13280 | MAE Train Loss: 0.013068857602775097 | MAE Test Loss: 0.030553001910448074 \n",
      "Epoch: 13290 | MAE Train Loss: 0.01303447037935257 | MAE Test Loss: 0.030473768711090088 \n",
      "Epoch: 13300 | MAE Train Loss: 0.013000110164284706 | MAE Test Loss: 0.030387694016098976 \n",
      "Epoch: 13310 | MAE Train Loss: 0.012965783476829529 | MAE Test Loss: 0.03031187132000923 \n",
      "Epoch: 13320 | MAE Train Loss: 0.012931426987051964 | MAE Test Loss: 0.030229175463318825 \n",
      "Epoch: 13330 | MAE Train Loss: 0.012897017411887646 | MAE Test Loss: 0.03014649823307991 \n",
      "Epoch: 13340 | MAE Train Loss: 0.012862687930464745 | MAE Test Loss: 0.03006727062165737 \n",
      "Epoch: 13350 | MAE Train Loss: 0.012828323058784008 | MAE Test Loss: 0.029991453513503075 \n",
      "Epoch: 13360 | MAE Train Loss: 0.012793943285942078 | MAE Test Loss: 0.029905367642641068 \n",
      "Epoch: 13370 | MAE Train Loss: 0.012759635224938393 | MAE Test Loss: 0.029829537495970726 \n",
      "Epoch: 13380 | MAE Train Loss: 0.012725263833999634 | MAE Test Loss: 0.029746854677796364 \n",
      "Epoch: 13390 | MAE Train Loss: 0.012690859846770763 | MAE Test Loss: 0.029667634516954422 \n",
      "Epoch: 13400 | MAE Train Loss: 0.012656524777412415 | MAE Test Loss: 0.02958495542407036 \n",
      "Epoch: 13410 | MAE Train Loss: 0.012622185051441193 | MAE Test Loss: 0.02950572967529297 \n",
      "Epoch: 13420 | MAE Train Loss: 0.012587790377438068 | MAE Test Loss: 0.029429906979203224 \n",
      "Epoch: 13430 | MAE Train Loss: 0.012553483247756958 | MAE Test Loss: 0.02934722974896431 \n",
      "Epoch: 13440 | MAE Train Loss: 0.012519103474915028 | MAE Test Loss: 0.0292645450681448 \n",
      "Epoch: 13450 | MAE Train Loss: 0.012484761886298656 | MAE Test Loss: 0.02918531373143196 \n",
      "Epoch: 13460 | MAE Train Loss: 0.012450416572391987 | MAE Test Loss: 0.029106086120009422 \n",
      "Epoch: 13470 | MAE Train Loss: 0.012416025623679161 | MAE Test Loss: 0.029023408889770508 \n",
      "Epoch: 13480 | MAE Train Loss: 0.012381638400256634 | MAE Test Loss: 0.028947586193680763 \n",
      "Epoch: 13490 | MAE Train Loss: 0.012347330339252949 | MAE Test Loss: 0.02886490896344185 \n",
      "Epoch: 13500 | MAE Train Loss: 0.012312949635088444 | MAE Test Loss: 0.028785670176148415 \n",
      "Epoch: 13510 | MAE Train Loss: 0.0122786033898592 | MAE Test Loss: 0.028702998533844948 \n",
      "Epoch: 13520 | MAE Train Loss: 0.012244263663887978 | MAE Test Loss: 0.02862377092242241 \n",
      "Epoch: 13530 | MAE Train Loss: 0.012209863401949406 | MAE Test Loss: 0.0285410825163126 \n",
      "Epoch: 13540 | MAE Train Loss: 0.012175487354397774 | MAE Test Loss: 0.02846527099609375 \n",
      "Epoch: 13550 | MAE Train Loss: 0.012141122482717037 | MAE Test Loss: 0.028379177674651146 \n",
      "Epoch: 13560 | MAE Train Loss: 0.012106799520552158 | MAE Test Loss: 0.02830336056649685 \n",
      "Epoch: 13570 | MAE Train Loss: 0.012072416953742504 | MAE Test Loss: 0.028224129229784012 \n",
      "Epoch: 13580 | MAE Train Loss: 0.012038109824061394 | MAE Test Loss: 0.028141450136899948 \n",
      "Epoch: 13590 | MAE Train Loss: 0.012003699317574501 | MAE Test Loss: 0.028058772906661034 \n",
      "Epoch: 13600 | MAE Train Loss: 0.011969337239861488 | MAE Test Loss: 0.027982955798506737 \n",
      "Epoch: 13610 | MAE Train Loss: 0.011934961192309856 | MAE Test Loss: 0.027896851301193237 \n",
      "Epoch: 13620 | MAE Train Loss: 0.011900627985596657 | MAE Test Loss: 0.02781761810183525 \n",
      "Epoch: 13630 | MAE Train Loss: 0.011866260319948196 | MAE Test Loss: 0.027741814032197 \n",
      "Epoch: 13640 | MAE Train Loss: 0.011831946671009064 | MAE Test Loss: 0.027659129351377487 \n",
      "Epoch: 13650 | MAE Train Loss: 0.011797541752457619 | MAE Test Loss: 0.02757643535733223 \n",
      "Epoch: 13660 | MAE Train Loss: 0.011763207614421844 | MAE Test Loss: 0.02749721333384514 \n",
      "Epoch: 13670 | MAE Train Loss: 0.011728804558515549 | MAE Test Loss: 0.027417993173003197 \n",
      "Epoch: 13680 | MAE Train Loss: 0.011694466695189476 | MAE Test Loss: 0.027335304766893387 \n",
      "Epoch: 13690 | MAE Train Loss: 0.011660118587315083 | MAE Test Loss: 0.02725948765873909 \n",
      "Epoch: 13700 | MAE Train Loss: 0.011625783517956734 | MAE Test Loss: 0.02717679738998413 \n",
      "Epoch: 13710 | MAE Train Loss: 0.011591430753469467 | MAE Test Loss: 0.027097588405013084 \n",
      "Epoch: 13720 | MAE Train Loss: 0.011557047255337238 | MAE Test Loss: 0.027014899998903275 \n",
      "Epoch: 13730 | MAE Train Loss: 0.011522707529366016 | MAE Test Loss: 0.026935666799545288 \n",
      "Epoch: 13740 | MAE Train Loss: 0.011488303542137146 | MAE Test Loss: 0.026852989569306374 \n",
      "Epoch: 13750 | MAE Train Loss: 0.011453966610133648 | MAE Test Loss: 0.02677716687321663 \n",
      "Epoch: 13760 | MAE Train Loss: 0.011419623158872128 | MAE Test Loss: 0.026694482192397118 \n",
      "Epoch: 13770 | MAE Train Loss: 0.011385277844965458 | MAE Test Loss: 0.02661525085568428 \n",
      "Epoch: 13780 | MAE Train Loss: 0.011350896209478378 | MAE Test Loss: 0.02653602883219719 \n",
      "Epoch: 13790 | MAE Train Loss: 0.01131654903292656 | MAE Test Loss: 0.026453351601958275 \n",
      "Epoch: 13800 | MAE Train Loss: 0.01128214318305254 | MAE Test Loss: 0.026370663195848465 \n",
      "Epoch: 13810 | MAE Train Loss: 0.011247815564274788 | MAE Test Loss: 0.026294846087694168 \n",
      "Epoch: 13820 | MAE Train Loss: 0.011213429272174835 | MAE Test Loss: 0.02621561288833618 \n",
      "Epoch: 13830 | MAE Train Loss: 0.011179068125784397 | MAE Test Loss: 0.02612953819334507 \n",
      "Epoch: 13840 | MAE Train Loss: 0.011144742369651794 | MAE Test Loss: 0.026053715497255325 \n",
      "Epoch: 13850 | MAE Train Loss: 0.01111038587987423 | MAE Test Loss: 0.02597101964056492 \n",
      "Epoch: 13860 | MAE Train Loss: 0.011075976304709911 | MAE Test Loss: 0.025888342410326004 \n",
      "Epoch: 13870 | MAE Train Loss: 0.011041645891964436 | MAE Test Loss: 0.025809114798903465 \n",
      "Epoch: 13880 | MAE Train Loss: 0.011007281951606274 | MAE Test Loss: 0.02573329769074917 \n",
      "Epoch: 13890 | MAE Train Loss: 0.010972903110086918 | MAE Test Loss: 0.02564721181988716 \n",
      "Epoch: 13900 | MAE Train Loss: 0.010938594117760658 | MAE Test Loss: 0.02557138167321682 \n",
      "Epoch: 13910 | MAE Train Loss: 0.010904221795499325 | MAE Test Loss: 0.025488698855042458 \n",
      "Epoch: 13920 | MAE Train Loss: 0.010869819670915604 | MAE Test Loss: 0.025409478694200516 \n",
      "Epoch: 13930 | MAE Train Loss: 0.010835482738912106 | MAE Test Loss: 0.025326799601316452 \n",
      "Epoch: 13940 | MAE Train Loss: 0.010801143944263458 | MAE Test Loss: 0.025247573852539062 \n",
      "Epoch: 13950 | MAE Train Loss: 0.010766749270260334 | MAE Test Loss: 0.025171751156449318 \n",
      "Epoch: 13960 | MAE Train Loss: 0.010732441209256649 | MAE Test Loss: 0.025089073926210403 \n",
      "Epoch: 13970 | MAE Train Loss: 0.010698061436414719 | MAE Test Loss: 0.025006389245390892 \n",
      "Epoch: 13980 | MAE Train Loss: 0.010663720779120922 | MAE Test Loss: 0.024927157908678055 \n",
      "Epoch: 13990 | MAE Train Loss: 0.010629375465214252 | MAE Test Loss: 0.024847930297255516 \n",
      "Epoch: 14000 | MAE Train Loss: 0.010594984516501427 | MAE Test Loss: 0.024765247479081154 \n",
      "Epoch: 14010 | MAE Train Loss: 0.010560599155724049 | MAE Test Loss: 0.024689430370926857 \n",
      "Epoch: 14020 | MAE Train Loss: 0.010526290163397789 | MAE Test Loss: 0.024606745690107346 \n",
      "Epoch: 14030 | MAE Train Loss: 0.01049190852791071 | MAE Test Loss: 0.02452751435339451 \n",
      "Epoch: 14040 | MAE Train Loss: 0.010457564145326614 | MAE Test Loss: 0.02444484271109104 \n",
      "Epoch: 14050 | MAE Train Loss: 0.010423222556710243 | MAE Test Loss: 0.024365615099668503 \n",
      "Epoch: 14060 | MAE Train Loss: 0.010388822294771671 | MAE Test Loss: 0.024282926693558693 \n",
      "Epoch: 14070 | MAE Train Loss: 0.01035444624722004 | MAE Test Loss: 0.024207115173339844 \n",
      "Epoch: 14080 | MAE Train Loss: 0.010320081375539303 | MAE Test Loss: 0.02412102185189724 \n",
      "Epoch: 14090 | MAE Train Loss: 0.010285758413374424 | MAE Test Loss: 0.024045204743742943 \n",
      "Epoch: 14100 | MAE Train Loss: 0.01025137584656477 | MAE Test Loss: 0.023965973407030106 \n",
      "Epoch: 14110 | MAE Train Loss: 0.01021706685423851 | MAE Test Loss: 0.023883294314146042 \n",
      "Epoch: 14120 | MAE Train Loss: 0.010182658210396767 | MAE Test Loss: 0.023800617083907127 \n",
      "Epoch: 14130 | MAE Train Loss: 0.010148297064006329 | MAE Test Loss: 0.02372479997575283 \n",
      "Epoch: 14140 | MAE Train Loss: 0.010113921947777271 | MAE Test Loss: 0.02363869547843933 \n",
      "Epoch: 14150 | MAE Train Loss: 0.010079586878418922 | MAE Test Loss: 0.023559462279081345 \n",
      "Epoch: 14160 | MAE Train Loss: 0.010045217350125313 | MAE Test Loss: 0.023483658209443092 \n",
      "Epoch: 14170 | MAE Train Loss: 0.01001090556383133 | MAE Test Loss: 0.02340097352862358 \n",
      "Epoch: 14180 | MAE Train Loss: 0.009976500645279884 | MAE Test Loss: 0.023318279534578323 \n",
      "Epoch: 14190 | MAE Train Loss: 0.00994216650724411 | MAE Test Loss: 0.023239057511091232 \n",
      "Epoch: 14200 | MAE Train Loss: 0.009907763451337814 | MAE Test Loss: 0.02315983735024929 \n",
      "Epoch: 14210 | MAE Train Loss: 0.009873425588011742 | MAE Test Loss: 0.02307714894413948 \n",
      "Epoch: 14220 | MAE Train Loss: 0.009839077480137348 | MAE Test Loss: 0.023001331835985184 \n",
      "Epoch: 14230 | MAE Train Loss: 0.009804742410779 | MAE Test Loss: 0.022918641567230225 \n",
      "Epoch: 14240 | MAE Train Loss: 0.009770389646291733 | MAE Test Loss: 0.022839432582259178 \n",
      "Epoch: 14250 | MAE Train Loss: 0.009736006148159504 | MAE Test Loss: 0.02275674417614937 \n",
      "Epoch: 14260 | MAE Train Loss: 0.009701666422188282 | MAE Test Loss: 0.022677510976791382 \n",
      "Epoch: 14270 | MAE Train Loss: 0.009667262434959412 | MAE Test Loss: 0.022594833746552467 \n",
      "Epoch: 14280 | MAE Train Loss: 0.009632925502955914 | MAE Test Loss: 0.022519011050462723 \n",
      "Epoch: 14290 | MAE Train Loss: 0.009598582051694393 | MAE Test Loss: 0.02243632636964321 \n",
      "Epoch: 14300 | MAE Train Loss: 0.009564236737787724 | MAE Test Loss: 0.022357095032930374 \n",
      "Epoch: 14310 | MAE Train Loss: 0.009529855102300644 | MAE Test Loss: 0.022277873009443283 \n",
      "Epoch: 14320 | MAE Train Loss: 0.009495507925748825 | MAE Test Loss: 0.02219519577920437 \n",
      "Epoch: 14330 | MAE Train Loss: 0.009461102075874805 | MAE Test Loss: 0.02211250737309456 \n",
      "Epoch: 14340 | MAE Train Loss: 0.009426774457097054 | MAE Test Loss: 0.022036690264940262 \n",
      "Epoch: 14350 | MAE Train Loss: 0.0093923881649971 | MAE Test Loss: 0.021957457065582275 \n",
      "Epoch: 14360 | MAE Train Loss: 0.009358027018606663 | MAE Test Loss: 0.021871382370591164 \n",
      "Epoch: 14370 | MAE Train Loss: 0.00932370126247406 | MAE Test Loss: 0.02179555967450142 \n",
      "Epoch: 14380 | MAE Train Loss: 0.009289344772696495 | MAE Test Loss: 0.021712863817811012 \n",
      "Epoch: 14390 | MAE Train Loss: 0.009254935197532177 | MAE Test Loss: 0.021630186587572098 \n",
      "Epoch: 14400 | MAE Train Loss: 0.009220604784786701 | MAE Test Loss: 0.02155095897614956 \n",
      "Epoch: 14410 | MAE Train Loss: 0.00918624084442854 | MAE Test Loss: 0.021475141867995262 \n",
      "Epoch: 14420 | MAE Train Loss: 0.009151862002909184 | MAE Test Loss: 0.021389055997133255 \n",
      "Epoch: 14430 | MAE Train Loss: 0.009117553010582924 | MAE Test Loss: 0.021313225850462914 \n",
      "Epoch: 14440 | MAE Train Loss: 0.00908318068832159 | MAE Test Loss: 0.02123054303228855 \n",
      "Epoch: 14450 | MAE Train Loss: 0.00904877856373787 | MAE Test Loss: 0.02115132287144661 \n",
      "Epoch: 14460 | MAE Train Loss: 0.009014441631734371 | MAE Test Loss: 0.021068643778562546 \n",
      "Epoch: 14470 | MAE Train Loss: 0.008980102837085724 | MAE Test Loss: 0.020989418029785156 \n",
      "Epoch: 14480 | MAE Train Loss: 0.0089457081630826 | MAE Test Loss: 0.02091359533369541 \n",
      "Epoch: 14490 | MAE Train Loss: 0.008911400102078915 | MAE Test Loss: 0.020830918103456497 \n",
      "Epoch: 14500 | MAE Train Loss: 0.008877020329236984 | MAE Test Loss: 0.020748233422636986 \n",
      "Epoch: 14510 | MAE Train Loss: 0.008842679671943188 | MAE Test Loss: 0.02066900208592415 \n",
      "Epoch: 14520 | MAE Train Loss: 0.008808334358036518 | MAE Test Loss: 0.02058977447450161 \n",
      "Epoch: 14530 | MAE Train Loss: 0.008773943409323692 | MAE Test Loss: 0.020507091656327248 \n",
      "Epoch: 14540 | MAE Train Loss: 0.008739558048546314 | MAE Test Loss: 0.02043127454817295 \n",
      "Epoch: 14550 | MAE Train Loss: 0.008705249056220055 | MAE Test Loss: 0.02034858986735344 \n",
      "Epoch: 14560 | MAE Train Loss: 0.008670867420732975 | MAE Test Loss: 0.020269358530640602 \n",
      "Epoch: 14570 | MAE Train Loss: 0.00863652303814888 | MAE Test Loss: 0.020186686888337135 \n",
      "Epoch: 14580 | MAE Train Loss: 0.008602181449532509 | MAE Test Loss: 0.020107459276914597 \n",
      "Epoch: 14590 | MAE Train Loss: 0.008567781187593937 | MAE Test Loss: 0.020024770870804787 \n",
      "Epoch: 14600 | MAE Train Loss: 0.008533405140042305 | MAE Test Loss: 0.019948959350585938 \n",
      "Epoch: 14610 | MAE Train Loss: 0.008499040268361568 | MAE Test Loss: 0.019862866029143333 \n",
      "Epoch: 14620 | MAE Train Loss: 0.00846471730619669 | MAE Test Loss: 0.019787048920989037 \n",
      "Epoch: 14630 | MAE Train Loss: 0.008430334739387035 | MAE Test Loss: 0.0197078175842762 \n",
      "Epoch: 14640 | MAE Train Loss: 0.008396025747060776 | MAE Test Loss: 0.019625138491392136 \n",
      "Epoch: 14650 | MAE Train Loss: 0.008361617103219032 | MAE Test Loss: 0.01954246126115322 \n",
      "Epoch: 14660 | MAE Train Loss: 0.008327255956828594 | MAE Test Loss: 0.019466644152998924 \n",
      "Epoch: 14670 | MAE Train Loss: 0.008292880840599537 | MAE Test Loss: 0.019380539655685425 \n",
      "Epoch: 14680 | MAE Train Loss: 0.008258545771241188 | MAE Test Loss: 0.01930130645632744 \n",
      "Epoch: 14690 | MAE Train Loss: 0.008224176242947578 | MAE Test Loss: 0.019225502386689186 \n",
      "Epoch: 14700 | MAE Train Loss: 0.008189864456653595 | MAE Test Loss: 0.019142817705869675 \n",
      "Epoch: 14710 | MAE Train Loss: 0.00815545953810215 | MAE Test Loss: 0.019060123711824417 \n",
      "Epoch: 14720 | MAE Train Loss: 0.008121125400066376 | MAE Test Loss: 0.018980901688337326 \n",
      "Epoch: 14730 | MAE Train Loss: 0.00808672234416008 | MAE Test Loss: 0.018901681527495384 \n",
      "Epoch: 14740 | MAE Train Loss: 0.008052384480834007 | MAE Test Loss: 0.018818993121385574 \n",
      "Epoch: 14750 | MAE Train Loss: 0.008018036372959614 | MAE Test Loss: 0.018743176013231277 \n",
      "Epoch: 14760 | MAE Train Loss: 0.007983701303601265 | MAE Test Loss: 0.01866048574447632 \n",
      "Epoch: 14770 | MAE Train Loss: 0.007949348539113998 | MAE Test Loss: 0.018581276759505272 \n",
      "Epoch: 14780 | MAE Train Loss: 0.00791496504098177 | MAE Test Loss: 0.018498588353395462 \n",
      "Epoch: 14790 | MAE Train Loss: 0.007880625315010548 | MAE Test Loss: 0.018419355154037476 \n",
      "Epoch: 14800 | MAE Train Loss: 0.007846221327781677 | MAE Test Loss: 0.01833667792379856 \n",
      "Epoch: 14810 | MAE Train Loss: 0.007811884395778179 | MAE Test Loss: 0.018260855227708817 \n",
      "Epoch: 14820 | MAE Train Loss: 0.007777539547532797 | MAE Test Loss: 0.018178170546889305 \n",
      "Epoch: 14830 | MAE Train Loss: 0.007743195630609989 | MAE Test Loss: 0.018098939210176468 \n",
      "Epoch: 14840 | MAE Train Loss: 0.0077088139951229095 | MAE Test Loss: 0.018019717186689377 \n",
      "Epoch: 14850 | MAE Train Loss: 0.007674466818571091 | MAE Test Loss: 0.017937039956450462 \n",
      "Epoch: 14860 | MAE Train Loss: 0.007640059106051922 | MAE Test Loss: 0.017854351550340652 \n",
      "Epoch: 14870 | MAE Train Loss: 0.0076057338155806065 | MAE Test Loss: 0.017778534442186356 \n",
      "Epoch: 14880 | MAE Train Loss: 0.0075713470578193665 | MAE Test Loss: 0.01769930124282837 \n",
      "Epoch: 14890 | MAE Train Loss: 0.007536985911428928 | MAE Test Loss: 0.017613226547837257 \n",
      "Epoch: 14900 | MAE Train Loss: 0.007502660155296326 | MAE Test Loss: 0.017537403851747513 \n",
      "Epoch: 14910 | MAE Train Loss: 0.007468304131180048 | MAE Test Loss: 0.017454707995057106 \n",
      "Epoch: 14920 | MAE Train Loss: 0.007433895952999592 | MAE Test Loss: 0.01737203076481819 \n",
      "Epoch: 14930 | MAE Train Loss: 0.007399563677608967 | MAE Test Loss: 0.017292803153395653 \n",
      "Epoch: 14940 | MAE Train Loss: 0.007365201599895954 | MAE Test Loss: 0.017216986045241356 \n",
      "Epoch: 14950 | MAE Train Loss: 0.007330820895731449 | MAE Test Loss: 0.01713090017437935 \n",
      "Epoch: 14960 | MAE Train Loss: 0.007296513766050339 | MAE Test Loss: 0.017055070027709007 \n",
      "Epoch: 14970 | MAE Train Loss: 0.007262139581143856 | MAE Test Loss: 0.016972387209534645 \n",
      "Epoch: 14980 | MAE Train Loss: 0.007227737456560135 | MAE Test Loss: 0.016893167048692703 \n",
      "Epoch: 14990 | MAE Train Loss: 0.007193400524556637 | MAE Test Loss: 0.01681048795580864 \n",
      "Epoch: 15000 | MAE Train Loss: 0.0071590617299079895 | MAE Test Loss: 0.01673126220703125 \n",
      "Epoch: 15010 | MAE Train Loss: 0.007124667055904865 | MAE Test Loss: 0.016655439510941505 \n",
      "Epoch: 15020 | MAE Train Loss: 0.00709035899490118 | MAE Test Loss: 0.01657276228070259 \n",
      "Epoch: 15030 | MAE Train Loss: 0.00705597922205925 | MAE Test Loss: 0.01649007759988308 \n",
      "Epoch: 15040 | MAE Train Loss: 0.007021640427410603 | MAE Test Loss: 0.016410846263170242 \n",
      "Epoch: 15050 | MAE Train Loss: 0.006987293250858784 | MAE Test Loss: 0.016331618651747704 \n",
      "Epoch: 15060 | MAE Train Loss: 0.006952904164791107 | MAE Test Loss: 0.01624893583357334 \n",
      "Epoch: 15070 | MAE Train Loss: 0.00691851694136858 | MAE Test Loss: 0.016173118725419044 \n",
      "Epoch: 15080 | MAE Train Loss: 0.0068842084147036076 | MAE Test Loss: 0.016090434044599533 \n",
      "Epoch: 15090 | MAE Train Loss: 0.006849826313555241 | MAE Test Loss: 0.016011202707886696 \n",
      "Epoch: 15100 | MAE Train Loss: 0.006815481930971146 | MAE Test Loss: 0.01592853106558323 \n",
      "Epoch: 15110 | MAE Train Loss: 0.006781139876693487 | MAE Test Loss: 0.01584930345416069 \n",
      "Epoch: 15120 | MAE Train Loss: 0.0067467400804162025 | MAE Test Loss: 0.01576661504805088 \n",
      "Epoch: 15130 | MAE Train Loss: 0.006712363567203283 | MAE Test Loss: 0.01569080352783203 \n",
      "Epoch: 15140 | MAE Train Loss: 0.006677999161183834 | MAE Test Loss: 0.015604710206389427 \n",
      "Epoch: 15150 | MAE Train Loss: 0.006643676199018955 | MAE Test Loss: 0.01552889309823513 \n",
      "Epoch: 15160 | MAE Train Loss: 0.006609293632209301 | MAE Test Loss: 0.015449660830199718 \n",
      "Epoch: 15170 | MAE Train Loss: 0.006574986036866903 | MAE Test Loss: 0.015366983599960804 \n",
      "Epoch: 15180 | MAE Train Loss: 0.006540576461702585 | MAE Test Loss: 0.015284305438399315 \n",
      "Epoch: 15190 | MAE Train Loss: 0.00650621484965086 | MAE Test Loss: 0.01520848274230957 \n",
      "Epoch: 15200 | MAE Train Loss: 0.0064718397334218025 | MAE Test Loss: 0.015122383832931519 \n",
      "Epoch: 15210 | MAE Train Loss: 0.006437505129724741 | MAE Test Loss: 0.015043151564896107 \n",
      "Epoch: 15220 | MAE Train Loss: 0.006403135601431131 | MAE Test Loss: 0.01496734656393528 \n",
      "Epoch: 15230 | MAE Train Loss: 0.006368823349475861 | MAE Test Loss: 0.014884662814438343 \n",
      "Epoch: 15240 | MAE Train Loss: 0.006334418896585703 | MAE Test Loss: 0.014801966957747936 \n",
      "Epoch: 15250 | MAE Train Loss: 0.006300084292888641 | MAE Test Loss: 0.014722746796905994 \n",
      "Epoch: 15260 | MAE Train Loss: 0.006265681236982346 | MAE Test Loss: 0.014643525704741478 \n",
      "Epoch: 15270 | MAE Train Loss: 0.006231342907994986 | MAE Test Loss: 0.014560836367309093 \n",
      "Epoch: 15280 | MAE Train Loss: 0.006196995265781879 | MAE Test Loss: 0.014485019259154797 \n",
      "Epoch: 15290 | MAE Train Loss: 0.006162659730762243 | MAE Test Loss: 0.014402329921722412 \n",
      "Epoch: 15300 | MAE Train Loss: 0.006128307431936264 | MAE Test Loss: 0.014323120936751366 \n",
      "Epoch: 15310 | MAE Train Loss: 0.006093923933804035 | MAE Test Loss: 0.014240431599318981 \n",
      "Epoch: 15320 | MAE Train Loss: 0.006059584207832813 | MAE Test Loss: 0.01416119933128357 \n",
      "Epoch: 15330 | MAE Train Loss: 0.006025180220603943 | MAE Test Loss: 0.014078522101044655 \n",
      "Epoch: 15340 | MAE Train Loss: 0.005990843288600445 | MAE Test Loss: 0.014002698473632336 \n",
      "Epoch: 15350 | MAE Train Loss: 0.0059564984403550625 | MAE Test Loss: 0.013920014724135399 \n",
      "Epoch: 15360 | MAE Train Loss: 0.005922154523432255 | MAE Test Loss: 0.013840782456099987 \n",
      "Epoch: 15370 | MAE Train Loss: 0.005887772887945175 | MAE Test Loss: 0.013761562295258045 \n",
      "Epoch: 15380 | MAE Train Loss: 0.005853425711393356 | MAE Test Loss: 0.013678884133696556 \n",
      "Epoch: 15390 | MAE Train Loss: 0.0058190179988741875 | MAE Test Loss: 0.013596194796264172 \n",
      "Epoch: 15400 | MAE Train Loss: 0.005784692708402872 | MAE Test Loss: 0.013520377688109875 \n",
      "Epoch: 15410 | MAE Train Loss: 0.005750305950641632 | MAE Test Loss: 0.013441145420074463 \n",
      "Epoch: 15420 | MAE Train Loss: 0.005715944804251194 | MAE Test Loss: 0.013355064205825329 \n",
      "Epoch: 15430 | MAE Train Loss: 0.005681618116796017 | MAE Test Loss: 0.013279247097671032 \n",
      "Epoch: 15440 | MAE Train Loss: 0.005647263024002314 | MAE Test Loss: 0.0131965521723032 \n",
      "Epoch: 15450 | MAE Train Loss: 0.005612855311483145 | MAE Test Loss: 0.01311387401074171 \n",
      "Epoch: 15460 | MAE Train Loss: 0.0055785225704312325 | MAE Test Loss: 0.013034647330641747 \n",
      "Epoch: 15470 | MAE Train Loss: 0.00554416049271822 | MAE Test Loss: 0.01295883022248745 \n",
      "Epoch: 15480 | MAE Train Loss: 0.005509779788553715 | MAE Test Loss: 0.012872743420302868 \n",
      "Epoch: 15490 | MAE Train Loss: 0.005475472658872604 | MAE Test Loss: 0.012796914204955101 \n",
      "Epoch: 15500 | MAE Train Loss: 0.005441098473966122 | MAE Test Loss: 0.012714231386780739 \n",
      "Epoch: 15510 | MAE Train Loss: 0.0054066963493824005 | MAE Test Loss: 0.012635010294616222 \n",
      "Epoch: 15520 | MAE Train Loss: 0.005372360348701477 | MAE Test Loss: 0.012552333064377308 \n",
      "Epoch: 15530 | MAE Train Loss: 0.005338020622730255 | MAE Test Loss: 0.012473106384277344 \n",
      "Epoch: 15540 | MAE Train Loss: 0.005303625948727131 | MAE Test Loss: 0.0123972836881876 \n",
      "Epoch: 15550 | MAE Train Loss: 0.0052693188190460205 | MAE Test Loss: 0.01231460552662611 \n",
      "Epoch: 15560 | MAE Train Loss: 0.0052349381148815155 | MAE Test Loss: 0.012231921777129173 \n",
      "Epoch: 15570 | MAE Train Loss: 0.0052005997858941555 | MAE Test Loss: 0.012152689509093761 \n",
      "Epoch: 15580 | MAE Train Loss: 0.005166252143681049 | MAE Test Loss: 0.012073462828993797 \n",
      "Epoch: 15590 | MAE Train Loss: 0.005131863057613373 | MAE Test Loss: 0.011990780010819435 \n",
      "Epoch: 15600 | MAE Train Loss: 0.0050974758341908455 | MAE Test Loss: 0.011914962902665138 \n",
      "Epoch: 15610 | MAE Train Loss: 0.005063167307525873 | MAE Test Loss: 0.011832279153168201 \n",
      "Epoch: 15620 | MAE Train Loss: 0.0050287856720387936 | MAE Test Loss: 0.01175304688513279 \n",
      "Epoch: 15630 | MAE Train Loss: 0.004994440823793411 | MAE Test Loss: 0.011670375242829323 \n",
      "Epoch: 15640 | MAE Train Loss: 0.004960098769515753 | MAE Test Loss: 0.011591148562729359 \n",
      "Epoch: 15650 | MAE Train Loss: 0.004925698973238468 | MAE Test Loss: 0.011508459225296974 \n",
      "Epoch: 15660 | MAE Train Loss: 0.004891322460025549 | MAE Test Loss: 0.011432647705078125 \n",
      "Epoch: 15670 | MAE Train Loss: 0.004856960382312536 | MAE Test Loss: 0.011346554383635521 \n",
      "Epoch: 15680 | MAE Train Loss: 0.004822633229196072 | MAE Test Loss: 0.011270737275481224 \n",
      "Epoch: 15690 | MAE Train Loss: 0.004788252525031567 | MAE Test Loss: 0.011191505007445812 \n",
      "Epoch: 15700 | MAE Train Loss: 0.004753944929689169 | MAE Test Loss: 0.011108827777206898 \n",
      "Epoch: 15710 | MAE Train Loss: 0.004719535354524851 | MAE Test Loss: 0.011026149615645409 \n",
      "Epoch: 15720 | MAE Train Loss: 0.004685175605118275 | MAE Test Loss: 0.010950326919555664 \n",
      "Epoch: 15730 | MAE Train Loss: 0.004650798626244068 | MAE Test Loss: 0.010864228010177612 \n",
      "Epoch: 15740 | MAE Train Loss: 0.004616464488208294 | MAE Test Loss: 0.0107849957421422 \n",
      "Epoch: 15750 | MAE Train Loss: 0.004582094494253397 | MAE Test Loss: 0.010709190741181374 \n",
      "Epoch: 15760 | MAE Train Loss: 0.004547781310975552 | MAE Test Loss: 0.010626506991684437 \n",
      "Epoch: 15770 | MAE Train Loss: 0.0045133777894079685 | MAE Test Loss: 0.01054381113499403 \n",
      "Epoch: 15780 | MAE Train Loss: 0.004479043185710907 | MAE Test Loss: 0.010464590974152088 \n",
      "Epoch: 15790 | MAE Train Loss: 0.004444638732820749 | MAE Test Loss: 0.010385369881987572 \n",
      "Epoch: 15800 | MAE Train Loss: 0.004410300403833389 | MAE Test Loss: 0.010302680544555187 \n",
      "Epoch: 15810 | MAE Train Loss: 0.004375954624265432 | MAE Test Loss: 0.01022686343640089 \n",
      "Epoch: 15820 | MAE Train Loss: 0.004341618623584509 | MAE Test Loss: 0.010144174098968506 \n",
      "Epoch: 15830 | MAE Train Loss: 0.00430726632475853 | MAE Test Loss: 0.01006496511399746 \n",
      "Epoch: 15840 | MAE Train Loss: 0.004272884223610163 | MAE Test Loss: 0.009982275776565075 \n",
      "Epoch: 15850 | MAE Train Loss: 0.004238543100655079 | MAE Test Loss: 0.009903043508529663 \n",
      "Epoch: 15860 | MAE Train Loss: 0.004204140044748783 | MAE Test Loss: 0.009820366278290749 \n",
      "Epoch: 15870 | MAE Train Loss: 0.00416980218142271 | MAE Test Loss: 0.00974454265087843 \n",
      "Epoch: 15880 | MAE Train Loss: 0.004135458264499903 | MAE Test Loss: 0.009661858901381493 \n",
      "Epoch: 15890 | MAE Train Loss: 0.00410111341625452 | MAE Test Loss: 0.00958262663334608 \n",
      "Epoch: 15900 | MAE Train Loss: 0.004066733177751303 | MAE Test Loss: 0.009503406472504139 \n",
      "Epoch: 15910 | MAE Train Loss: 0.00403238320723176 | MAE Test Loss: 0.00942072831094265 \n",
      "Epoch: 15920 | MAE Train Loss: 0.003997978754341602 | MAE Test Loss: 0.009338038973510265 \n",
      "Epoch: 15930 | MAE Train Loss: 0.003963652066886425 | MAE Test Loss: 0.009262221865355968 \n",
      "Epoch: 15940 | MAE Train Loss: 0.003929264843463898 | MAE Test Loss: 0.009182989597320557 \n",
      "Epoch: 15950 | MAE Train Loss: 0.003894903464242816 | MAE Test Loss: 0.009096908383071423 \n",
      "Epoch: 15960 | MAE Train Loss: 0.003860577242448926 | MAE Test Loss: 0.009021091274917126 \n",
      "Epoch: 15970 | MAE Train Loss: 0.003826223313808441 | MAE Test Loss: 0.008938396349549294 \n",
      "Epoch: 15980 | MAE Train Loss: 0.0037918128073215485 | MAE Test Loss: 0.008855718187987804 \n",
      "Epoch: 15990 | MAE Train Loss: 0.0037574812304228544 | MAE Test Loss: 0.00877649150788784 \n"
     ]
    }
   ],
   "source": [
    "# An epoch is one loop through the data ... (this is a hyperparameter because we've set it ourselves)\n",
    "\n",
    "epochs = 20000\n",
    "\n",
    "#track different values \n",
    "epoch_count = [] \n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    #set the model to training mode\n",
    "    model_0.train() # train mode in pytorch sets all parameters that require gradients to require gradient\n",
    "\n",
    "    #1. Forward pass\n",
    "    y_pred = model_0(X_train)  # The current pred res base on the current [params]\n",
    "    \n",
    "    #2. Calculate the loss\n",
    "    loss = loss_fn(y_pred, y_train) # use loss function to get how wrong the res is?\n",
    "    #3. Optimizer zero grad [zero the optimizer gradients] --> they accumulate every epoch, zero them to start fresh each forward pass\n",
    "    optimizer.zero_grad() # \n",
    "\n",
    "    #4. perform backpropagation on the loss with respect to the parameters of the model\n",
    "    loss.backward() # [ Compute the gradient of every parameter with requires_grad = True ]\n",
    "\n",
    "    #5. Step the optimizer (perform gradient descent)\n",
    "    optimizer.step()  # take the step here ? \n",
    "    model_0.eval() \n",
    "    with torch.inference_mode():\n",
    "      # 1. Forward pass on test data\n",
    "      test_pred = model_0(X_test)\n",
    "\n",
    "      # 2. Caculate loss on test data\n",
    "      test_loss = loss_fn(test_pred, y_test.type(torch.float)) # predictions come in torch.float datatype, so comparisons need to be done with tensors of the same type\n",
    "\n",
    "      # Print out what's happening\n",
    "      if epoch % 10 == 0:\n",
    "            epoch_count.append(epoch)\n",
    "            train_loss_values.append(loss.detach().numpy())\n",
    "            test_loss_values.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {loss} | MAE Test Loss: {test_loss} \")\n",
    "    # model_0.eval() # turns off gradient tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d1bb3be-dddf-44e9-b7b7-8142a27671e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.6815], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3078], requires_grad=True)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_0.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8961000-2191-4bd2-8f29-16de18ccde33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    y_preds = model_0(X_test)\n",
    "\n",
    "y_preds, y_test\n",
    "\n",
    "# To visuslize this res for now\n",
    "plot_predictions(predictions=y_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7e40cad-57d1-4777-b193-b6df3e30cf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create empty lists to keep track of model progress\n",
    "\n",
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, train_loss_values, label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Training and test loss curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18561fb4-d286-4c58-bf6e-f1d87ae099c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
